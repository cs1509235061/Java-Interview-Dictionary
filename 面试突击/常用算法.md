# 常用算法

## 1.二分查找

又叫折半查找，要求待查找的序列有序。每次取中间位置的值与待查关键字比较，如果中间位置的值比待查关键字大，则在前半部分循环这个查找的过程，如果中间位置的值比待查关键字小，则在后半部分循环这个查找的过程。直到查找到了为止，否则序列中没有待查的关键字。

二分查找算法要求要查找的集合是有序的，如果不是有序的集合，则先要通过排序算法排序后再进行查找。

```html
public static int biSearch(int []array,int a){ 
    int lo=0; 
    int hi=array.length-1; 
    int mid; 
    while(lo<=hi){ 
        mid=(lo+hi)/2;//中间位置 
        if(array[mid]==a){ 
            return mid+1; 
        }else if(array[mid]<a){ //向右查找 
            lo=mid+1; 
        }else{//向左查找 
            hi=mid-1; 
        } 
    } 
    return -1; 
}
```

在该方法中有3个变量low、mid和high，分别表示二分查找的最小、中间和最大的数据索引。在以上代码中，通过一个while循环在数组中查找传入的数据，在该数据大于中间位置的数据时向右查找，即最大索引位置不变，将最小索引设置为上次循环的中间索引加1；在该数据小于中间位置的数据时向左查找，即最小索引位置不变，然后将最大索引设置为上次循环的中间索引并减1。重复以上过程，直到中间索引位置的数据等于要查找的数据，说明找到了要查找的数据，将该数据对应的索引返回。如果遍历到low>high还没有找到要查找的数据，则说明该数据在列表中不存在，返回-1。

## 2.冒泡排序算法

（1）比较前后相邻的二个数据，如果前面数据大于后面的数据，就将这二个数据交换。

（2）这样对数组的第0个数据到N-1个数据进行一次遍历后，最大的一个数据就“沉”到数组第N-1个位置。

（3）N=N-1，如果N不为0就重复前面二步，否则排序完成。

该算法名称的由来是越大的元素会经过交换慢慢“浮”到数列的顶端（升序或降序排列），就如同水的气泡最终会上浮到顶端一样。

```html
public static void bubbleSort1(int [] a, int n){ 
    int i, j;
    for(i=0; i<n; i++){//表示n次排序过程。 
        for(j=1; j<n-i; j++){ 
            if(a[j-1] > a[j]){//前面的数字大于后面的数字就交换 
                //交换a[j-1]和a[j] 
                int temp; 
                temp = a[j-1]; 
                a[j-1] = a[j]; 
                a[j]=temp; 
            } 
        } 
    }
}
```

分为外层循环和内层循环，外层循环控制排序的次数，内层循环控制每一趟排序多少次。在内层循环中比较当前数据和下一个数据的大小，如果当前数据大于下一个数据，就交换二者的位置，这样重复进行判断，直至整个排序完成，最终返回排序后的数组。

## 3.插入排序算法

通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应的位置并插入。插入排序非常类似于整扑克牌。在开始摸牌时，左手是空的，牌面朝下放在桌上。接着，一次从桌上摸起一张牌，并将它插入到左手一把牌中的正确位置上。为了找到这张牌的正确位置，要将它与手中已有的牌从右到左地进行比较。无论什么时候，左手中的牌都是排好序的。

如果输入数组已经是排好序的话，插入排序出现最佳情况，其运行时间是输入规模的一个线性函数。如果输入数组是逆序排列的，将出现最坏情况。平均情况与最坏情况一样，其时间代价是(n2)。

```html
public void sort(int arr[]){
    for(int i =1; i<arr.length;i++) { 
        //插入的数 
        int insertVal = arr[i]; 
        //被插入的位置(准备和前一个数比较) 
        int index = i-1; 
        //如果插入的数比被插入的数小 
        while(index>=0&&insertVal<arr[index]) { 
            //将把arr[index] 向后移动 
            arr[index+1]=arr[index]; 
            //让index向前移动 
            index--; 
        } 
        //把插入的数放入合适位置 
        arr[index+1]=insertVal; 
    } 
}
```

## 4.快速排序算法

快速排序的原理：选择一个关键值作为基准值。比基准值小的都在左边序列（一般是无序的），比基准值大的都在右边（一般是无序的）。一般选择序列的第一个元素。

一次循环：从后往前比较，用基准值和最后一个值比较，如果比基准值小的交换位置，如果没有继续比较下一个，直到找到第一个比基准值小的值才交换。找到这个值之后，又从前往后开始比较，如果有比基准值大的，交换位置，如果没有继续比较下一个，直到找到第一个比基准值大的值才交换。直到从前往后的比较索引>从后往前比较的索引，结束第一次循环，此时，对于基准值来说，左右两边就是有序的了。

```html
public void sort(int[] a,int low,int high){ 
    int start = low; 
    int end = high;
    int key = a[low];  
    while(end>start){ 
        //从后往前比较 
        while(end>start&&a[end]>=key) 
            //如果没有比关键值小的，比较下一个，直到有比关键值小的交换位置，然后又从前往后比较 
            end--; 
        if(a[end]<=key){ 
            int temp = a[end]; 
            a[end] = a[start]; 
            a[start] = temp; 
        } 
        //从前往后比较 
        while(end>start&&a[start]<=key)
            //如果没有比关键值大的，比较下一个，直到有比关键值大的交换位置 
            start++; 
        if(a[start]>=key){ 
            int temp = a[start]; 
            a[start] = a[end]; 
            a[end] = temp; 
        } 
        //此时第一次循环比较结束，关键值的位置已经确定了。左边的值都比关键值小，右边的值都比关键值大，但是两边的顺序还有可能是不一样的，进行下面的递归调用
    } 
    //递归 
    if(start>low) 
        sort(a,low,start-1);
    //左边序列。第一个索引位置到关键值索引-1 
    if(end<high) 
        sort(a,end+1,high);//右边序列。从关键值索引+1到最后一个 
}
```

## 5.希尔排序算法

基本思想：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。

1.操作方法：选择一个增量序列t1，t2，…，tk，其中ti>tj，tk=1；

2.按增量序列个数k，对序列进行k 趟排序；

3.每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。

```html
private void shellSort(int[] a) {
    int dk = a.length/2; 
    while( dk >= 1 ){  
        ShellInsertSort(a, dk);  
        dk = dk/2;
    }
}
private void ShellInsertSort(int[] a, int dk) {
    //类似插入排序，只是插入排序增量是1，这里增量是dk,把1换成dk就可以了
    for(int i=dk;i<a.length;i++){
        if(a[i]<a[i-dk]){
            int j;
            int x=a[i];
            //x为待插入元素
            a[i]=a[i-dk];
            for(j=i-dk; j>=0 &&x<a[j];j=j-dk){
                //通过循环，逐个后移一位找到要插入的位置。
                a[j+dk]=a[j];
            }
            a[j+dk]=x;//插入
        }
    }
}
```

## 6.归并排序算法

归并（Merge）排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。

```html
public class MergeSortTest {  
    public static void main(String[] args) {  
        int[] data = new int[] { 5, 3, 6, 2, 1, 9, 4, 8, 7 };  
        print(data);  
        mergeSort(data);  
        System.out.println("排序后的数组：");  
        print(data);  
    }  
    public static void mergeSort(int[] data) {  
        sort(data, 0, data.length -1);  
    }  
    public static void sort(int[] data, int left, int right) {  
        if (left >= right)  
            return;  
        // 找出中间索引  
        int center = (left + right) / 2;  
        // 对左边数组进行递归  
        sort(data, left, center);  
        // 对右边数组进行递归  
        sort(data, center + 1, right);  
        // 合并  
        merge(data, left, center, right);  
        print(data);  
    }  
    /**  
     * 将两个数组进行归并，归并前面2个数组已有序，归并后依然有序
     *  
     * @param data  
     * 数组对象 
     * @param left  
     * 左数组的第一个元素的索引 
     * @param center  
     * 左数组的最后一个元素的索引，center+1是右数组第一个元素的索引 
     * @param right  
     * 右数组最后一个元素的索引 
    */  
    public static void merge(int[] data, int left, int center, int right) {  
        // 临时数组  
        int[] tmpArr = new int[data.length];  
        // 右数组第一个元素索引  
        int mid = center + 1;  
        // third 记录临时数组的索引  
        int third = left;  
        // 缓存左数组第一个元素的索引  
        int tmp = left;  
        while (left <= center && mid <= right) {  
            // 从两个数组中取出最小的放入临时数组  
            if (data[left] <= data[mid]) {  
                tmpArr[third++] = data[left++];  
            } else {  
                tmpArr[third++] = data[mid++];  
            }  
        }  
        // 剩余部分依次放入临时数组（实际上两个while只会执行其中一个）  
        while (mid <= right) {  
            tmpArr[third++] = data[mid++]; 
        }  
        while (left <= center) {  
            tmpArr[third++] = data[left++];  
        }  
        // 将临时数组中的内容拷贝回原数组中  
        // （原left-right范围的内容被复制回原数组）  
        while (tmp <= right) {  
            data[tmp] = tmpArr[tmp++];  
        }  
    }  
    public static void print(int[] data) {  
        for (int i = 0; i < data.length; i++) {  
            System.out.print(data[i] + "\t");  
        }  System.out.println();  
    }  
} 
```

## 7.桶排序算法

桶排序的基本思想是：把数组arr 划分为n个大小相同子区间（桶），每个子区间各自排序，最后合并。计数排序是桶排序的一种特殊情况，可以把计数排序当成每个桶里只有一个元素的情况。

1.找出待排序数组中的最大值max、最小值min

2.我们使用动态数组ArrayList 作为桶，桶里放的元素也用ArrayList 存储。桶的数量为(max�min)/arr.length+1

3.遍历数组arr，计算每个元素arr[i] 放的桶

4.每个桶各自排序

```html
public static void bucketSort(int[] arr){
    int max = Integer.MIN_VALUE;
    int min = Integer.MAX_VALUE;
    for(int i = 0; i < arr.length; i++){
        max = Math.max(max, arr[i]);
        min = Math.min(min, arr[i]);
    }
    //创建桶
    int bucketNum = (max -min) / arr.length + 1;
    ArrayList<ArrayList<Integer>> bucketArr = new ArrayList<>(bucketNum);
    for(int i = 0; i < bucketNum; i++){
        bucketArr.add(newArrayList<Integer>());
    }
    //将每个元素放入桶
    for(int i = 0; i < arr.length; i++){
        int num = (arr[i] -min) / (arr.length);
        bucketArr.get(num).add(arr[i]);
    }
    //对每个桶进行排序
    for(int i = 0; i < bucketArr.size(); i++){
        Collections.sort(bucketArr.get(i));
    }
}
```

## 8.基数排序算法

将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后,数列就变成一个有序序列。

```html
public class radixSort {
    int a[]={49,38,65,97,76,13,27,49,78,34,12,64,5,4,62,99,98,54,101,56,17,18,23,34,15,35,25,53,51};
    public radixSort(){
        sort(a);
        for(int i=0;i<a.length;i++){
            System.out.println(a[i]);
        }
    }
    public void sort(int[] array){
        //首先确定排序的趟数;
        int max=array[0];
        for(int i=1;i<array.length;i++){
            if(array[i]>max){
                max=array[i];
            }
        }
        int time=0;
        //判断位数;
        while(max>0){
            max/=10;
            time++;
        }
        //建立10个队列;
        List<ArrayList> queue=new ArrayList<ArrayList>();
        for(int i=0;i<10;i++){
            ArrayList<Integer> queue1=new ArrayList<Integer>();
            queue.add(queue1);
        }
        //进行time次分配和收集;
        for(int i=0;i<time;i++){
            //分配数组元素;
            for(int j=0;j<array.length;j++){
                //得到数字的第time+1位数;
                int x=array[j]%(int)Math.pow(10,i+1)/(int)Math.pow(10, i);
                ArrayList<Integer> queue2=queue.get(x);
                queue2.add(array[j]);
                queue.set(x, queue2);
            }
            int count=0;
            //元素计数器;
            //收集队列元素;
            for(int k=0;k<10;k++){
                while(queue.get(k).size()>0){
                    ArrayList<Integer>queue3=queue.get(k);
                    array[count]=queue3.get(0);
                    queue3.remove(0);
                    count++;
                }
            }
        }
    }
}
```

## 9.剪枝算法

在搜索算法中优化中，剪枝，就是通过某种判断，避免一些不必要的遍历过程，形象的说，就是剪去了搜索树中的某些“枝条”，故称剪枝。应用剪枝优化的核心问题是设计剪枝判断方法，即确定哪些枝条应当舍弃，哪些枝条应当保留的方法。

## 10.回溯算法

回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。

## 11.最短路径算法

从某顶点出发，沿图的边到达另一顶点所经过的路径中，各边上权值之和最小的一条路径叫做最短路径。解决最短路的问题有以下算法，Dijkstra算法，Bellman-Ford算法，Floyd算法和SPFA算法等。

最短路径算法的常见问题如下。

- 确定起点的最短路径问题：即已知起始节点，求最短路径的问题，适合使用Dijkstra算法。
- 确定终点的最短路径问题：已知终节点，求最短路径的问题。在无向图中，该问题与确定起点的问题等同；在有向图中，该问题与将所有路径方向反转以确定起点的问题等同。
- 确定起点和终点的最短路径问题：已知起点和终点，求两节点之间的最短路径。
- 全局最短路径问题：求图中所有的最短路径，适合使用Floyd�Warshall算法。

## 12.最大子数组算法

## 13.最长公共子序算法

## 14.最小生成树算法

现在假设有一个很实际的问题：我们要在n个城市中建立一个通信网络，则连通这n个城市需要布置n-1一条通信线路，这个时候我们需要考虑如何在成本最低的情况下建立这个通信网？

于是我们就可以引入连通图来解决我们遇到的问题，n个城市就是图上的n个顶点，然后，边表示两个城市的通信线路，每条边上的权重就是我们搭建这条线路所需要的成本，所以现在我们有n个顶点的连通网可以建立不同的生成树，每一颗生成树都可以作为一个通信网，当我们构造这个连通网所花的成本最小时，搭建该连通网的生成树，就称为最小生成树。

构造最小生成树有很多算法，但是他们都是利用了最小生成树的同一种性质：MST性质（假设N=(V,{E})是一个连通网，U是顶点集V的一个非空子集，如果（u，v）是一条具有最小权值的边，其中u属于U，v属于V-U，则必定存在一颗包含边（u，v）的最小生成树），下面就介绍两种使用MST性质生成最小生成树的算法：普里姆算法和克鲁斯卡尔算法。

# 加密算法

## 1.AES

高级加密标准(AES,Advanced Encryption Standard)为最常见的对称加密算法(微信小程序加密传输就是用这个加密算法的)。对称加密算法也就是加密和解密用相同的密钥。

## 2.RSA

RSA加密算法是一种典型的非对称加密算法，它基于大数的因式分解数学难题，它也是应用最广泛的非对称加密算法。

非对称加密是通过两个密钥（公钥-私钥）来实现对数据的加密和解密的。公钥用于加密，私钥用于解密。

## 3.CRC

循环冗余校验(Cyclic Redundancy Check, CRC)是一种根据网络数据包或电脑文件等数据产生简短固定位数校验码的一种散列函数，主要用来检测或校验数据传输或者保存后可能出现的错误。它是利用除法及余数的原理来作错误侦测的。

## 4.MD5

MD5常常作为文件的签名出现，我们在下载文件的时候，常常会看到文件页面上附带一个扩展名为.MD5的文本或者一行字符，这行字符就是就是把整个文件当作原数据通过MD5计算后的值，我们下载文件后，可以用检查文件MD5信息的软件对下载到的文件在进行一次计算。两次结果对比就可以确保下载到文件的准确性。另一种常见用途就是网站敏感信息加密，比如用户名密码，支付签名等等。随着https技术的普及，现在的网站广泛采用前台明文传输到后台，MD5加密（使用偏移量）的方式保护敏感数据保护站点和数据安全。

# 一致性算法

## 1.Paxos

Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。zookeeper 使用的zab算法是该算法的一个实现。在Paxos算法中，有三种角色：Proposer，Acceptor，Learners

Paxos三种角色：Proposer，Acceptor，Learners

### Proposer：

只要Proposer发的提案被半数以上Acceptor接受，Proposer就认为该提案里的value被选定了。

### Acceptor：

只要Acceptor接受了某个提案，Acceptor就认为该提案里的value被选定了。

### Learner：

Acceptor告诉Learner哪个value被选定，Learner就认为那个value被选定。

### Paxos算法分为两个阶段。具体如下：

阶段一（准leader确定）：

(a) Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。

(b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。

阶段二（leader确认）：

(a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。(b)如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。

## 2.Zab

ZAB( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议）协议包括两种基本的模式：崩溃恢复和消息广播

1.当整个服务框架在启动过程中，或是当Leader服务器出现网络中断崩溃退出与重启等异常情况时，ZAB就会进入恢复模式并选举产生新的Leader服务器。

2.当选举产生了新的Leader服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出崩溃恢复模式，进入消息广播模式。

3.当有新的服务器加入到集群中去，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加入的服务器会自动进入数据恢复模式，找到Leader服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。

以上其实大致经历了三个步骤：

1.崩溃恢复：主要就是Leader选举过程

2.数据同步：Leader服务器与其他服务器进行数据同步

3.消息广播：Leader服务器将数据发送给其他服务器

## 3.Raft

与Paxos不同Raft强调的是易懂（Understandability），Raft和Paxos一样只要保证n/2+1节点正常就能够提供服务；raft把算法流程分为三个子问题：选举（Leader election）、日志复制（Log replication）、安全性（Safety）三个子问题。

### 角色

Raft把集群中的节点分为三种状态：Leader、Follower 、Candidate，理所当然每种状态负责的任务也是不一样的，Raft运行时提供服务的时候只存在Leader与Follower两种状态；

Leader（领导者-日志管理）

负责日志的同步管理，处理来自客户端的请求，与Follower保持这heartBeat的联系；

Follower（追随者-日志同步）

刚启动时所有节点为Follower状态，响应Leader的日志同步请求，响应Candidate的请求，把请求到Follower的事务转发给Leader；

Candidate（候选者-负责选票）

负责选举投票，Raft刚启动时由一个节点从Follower转为Candidate发起选举，选举出Leader后从Candidate转为Leader状态；

### Term（任期）

在Raft中使用了一个可以理解为周期（第几届、任期）的概念，用Term作为一个周期，每个Term都是一个连续递增的编号，每一轮选举都是一个Term周期，在一个Term中只能产生一个Leader；当某节点收到的请求中Term比当前Term小时则拒绝该请求。

### 选举（Election）

选举定时器

Raft的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为Follower某个节点定时器触发选举后Term递增，状态由Follower转为Candidate，向其他节点发起RequestVote RPC请求，这时候有三种可能的情况发生：

1：该RequestVote请求接收到n/2+1（过半数）个节点的投票，从Candidate转为Leader，向其他节点发送heartBeat以保持Leader的正常运转。

2：在此期间如果收到其他节点发送过来的AppendEntries RPC请求，如该节点的Term大则当前节点转为Follower，否则保持Candidate拒绝该请求。

3：Election timeout发生则Term递增，重新发起选举

在一个Term期间每个节点只能投票一次，所以当有多个Candidate存在时就会出现每个Candidate发起的选举都存在接收到的投票数都不过半的问题，这时每个Candidate都将Term递增、重启定时器并重新发起选举，由于每个节点中定时器的时间都是随机的，所以就不会多次存在有多个Candidate同时发起投票的问题。

在Raft中当接收到客户端的日志（事务请求）后先把该日志追加到本地的Log中，然后通过heartbeat把该Entry同步给其他Follower，Follower接收到日志后记录日志然后向Leader发送ACK，当Leader收到大多数（n/2+1）Follower的ACK信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个heartbeat中Leader将通知所有的Follower将该日志存储在自己的本地磁盘中。

### 安全性（Safety）

安全性是用于保证每个节点都执行相同序列的安全机制如当某个Follower在当前Leader commit Log时变得不可用了，稍后可能该Follower又会倍选举为Leader，这时新Leader可能会用新的Log覆盖先前已committed的Log，这就是导致节点执行不同序列；Safety就是用于保证选举出来的Leader一定包含先前commited Log的机制；

选举安全性（Election Safety）：每个Term只能选举出一个Leader

Leader完整性（Leader Completeness）：这里所说的完整性是指Leader日志的完整性，Raft在选举阶段就使用Term的判断用于保证完整性：当请求投票的该Candidate的Term较大或Term相同Index更大则投票，该节点将容易变成leader。

## 4.raft协议和zab协议区别

### 相同点

- 采用quorum来确定整个系统的一致性,这个quorum一般实现是集群中半数以上的服务器,
- zookeeper里还提供了带权重的quorum实现.
- 都由leader来发起写操作.
- 都采用心跳检测存活性
- leader election都采用先到先得的投票方式

### 不同点

- zab用的是epoch和count的组合来唯一表示一个值, 而raft用的是term和index
- zab的follower在投票给一个leader之前必须和leader的日志达成一致,而raft的follower则简单地说是谁的term高就投票给谁
- raft协议的心跳是从leader到follower, 而zab协议则相反
- raft协议数据只有单向地从leader到follower(成为leader的条件之一就是拥有最新的log)

而zab协议在discovery阶段, 一个prospective leader需要将自己的log更新为quorum里面最新的log,然后才好在synchronization阶段将quorum里的其他机器的log都同步到一致

## 5.NWR

N：在分布式存储系统中，有多少份备份数据

W：代表一次成功的更新操作要求至少有w份数据写入成功

R：代表一次成功的读数据操作要求至少有R份数据成功读取

NWR值的不同组合会产生不同的一致性效果，当W+R>N的时候，整个系统对于客户端来讲能保证强一致性。而如果R+W<=N，则无法保证数据的强一致性。以常见的N=3、W=2、R=2为例：N=3，表示，任何一个对象都必须有三个副本（Replica），W=2表示，对数据的修改操作（Write）只需要在3个Replica中的2个上面完成就返回，R=2表示，从三个对象中要读取到2个数据对象，才能返回。

## 6.Gossip

Gossip算法又被称为反熵（Anti-Entropy），熵是物理学上的一个概念，代表杂乱无章，而反熵就是在杂乱无章中寻求一致，这充分说明了Gossip的特点：在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的，当然这也是疫情传播的特点。

## 7.一致性Hash

一致性哈希算法(Consistent Hashing Algorithm)是一种分布式算法，常用于负载均衡。Memcached client也选择这种算法，解决将key-value均匀分配到众多Memcached server上的问题。它可以取代传统的取模操作，解决了取模操作无法应对增删Memcached Server的问题(增删server会导致同一个key,在get操作时分配不到数据真正存储的server，命中率会急剧下降)。

### 一致性Hash特性

- 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。
- 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。容易看到，上面的简单求余算法hash(object)%N 难以满足单调性要求。
- 平滑性(Smoothness)：平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。

### 一致性Hash原理

1.建构环形hash 空间：

1.考虑通常的hash 算法都是将value 映射到一个32 为的key 值，也即是0~2^32-1 次方的数值空间；我们可以将这个空间想象成一个首（0 ）尾（2^32-1 ）相接的圆环。

2.把需要缓存的内容(对象)映射到hash 空间

2.接下来考虑4 个对象object1~object4 ，通过hash 函数计算出的hash 值key 在环上的分布

3.把服务器(节点)映射到hash 空间

3.Consistent hashing 的基本思想就是将对象和cache 都映射到同一个hash 数值空间中，并且使用相同的hash算法。一般的方法可以使用服务器(节点) 机器的IP 地址或者机器名作为hash输入。

4.把对象映射到服务节点

4.现在服务节点和对象都已经通过同一个hash 算法映射到hash 数值空间中了，首先确定对象hash值在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。

考察cache 的变动

5.通过hash 然后求余的方法带来的最大问题就在于不能满足单调性，当cache 有所变动时，cache会失效。

移除cache：考虑假设cache B 挂掉了，根据上面讲到的映射方法，这时受影响的将仅是那些沿cache B 逆时针遍历直到下一个cache （cache C ）之间的对象。

添加cache：再考虑添加一台新的cache D 的情况，这时受影响的将仅是那些沿cache D 逆时针遍历直到下一个cache 之间的对象，将这些对象重新映射到cache D 上即可。

虚拟节点

hash 算法并不是保证绝对的平衡，如果cache 较少的话，对象并不能被均匀的映射到cache 上，为了解决这种情况，consistent hashing 引入了“虚拟节点”的概念，它可以如下定义：

虚拟节点（virtual node ）是实际节点在hash 空间的复制品（replica ），一实际个节点对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在hash 空间中以hash 值排列。

仍以仅部署cache A 和cache C 的情况为例。现在我们引入虚拟节点，并设置“复制个数”为2 ，这就意味着一共会存在4 个“虚拟节点”，cache A1, cache A2 代表了cache A；cache C1, cache C2 代表了cache C 。此时，对象到“虚拟节点”的映射关系为：

objec1->cache A2 ；objec2->cache A1 ；objec3->cache C1 ；objec4->cache C2 ；

因此对象object1 和object2 都被映射到了cache A 上，而object3 和object4 映射到了cache C 上；平衡性有了很大提高。

引入“虚拟节点”后，映射关系就从{ 对象-> 节点} 转换到了{ 对象-> 虚拟节点} 。查询物体所在cache 时的映射关系如下图所示。

# 常见的限流算法

### 计数器算法

计数器算法采用计数器实现限流有点简单粗暴，一般我们会限制一秒钟的能够通过的请求数，比如限流qps为100，算法的实现思路就是从第一个请求进来开始计时，在接下去的1s内，每来一个请求，就把计数加1，如果累加的数字达到了100，那么后续的请求就会被全部拒绝。等到1s结束后，把计数恢复成0，重新开始计数。具体的实现可以是这样的：对于每次服务调用，可以通过AtomicLong#incrementAndGet()方法来给计数器加1并返回最新值，通过这个最新值和阈值进行比 较。这种实现方式，相信大家都知道有一个弊端：如果我在单位时间1s内的前10ms，已经通过了100 个请求，那后面的990ms，只能眼巴巴的把请求拒绝，我们把这种现象称为“突刺现象”

### 漏桶算法

漏桶算法为了消除"突刺现象"，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。不管服务调用方多么不稳定，通过漏桶算法进行限流，每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。 在算法实现方面，可以准备一个队列，用来保存请求，另外通过一个线程池（ScheduledExecutorService）来定期从队列中获取请求并执行，可以一次性获取多个并发执行。 这种算法，在使用过后也存在弊端：无法应对短时间的突发流量。

令牌桶算法

从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。

# 一致性**Hash**算法

具体在计算一致性hash时采用如下步骤：

1. 首先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。
2. 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
3. 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。

添加一台memcached服务器。余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在园（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响，

### 一致性**Hash**性质

考虑到分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的，尤其实在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其hash值（通常与系统中的节点数目有关），由于hash值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性hash就显得至关重要， 良好的分布式cahce系统中的一致性hash算法应该满足以下几个方面：

平衡性**(Balance)**

平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。

单调性(Monotonicity)

单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。简单的哈希算法往往不能满足单调性的要求，如最简单的线性哈希：x = (ax + b) mod (P)，在上式中，P表示全部缓冲的大小。不难看出，当缓冲大小发生变化时(从P1到P2)，原来所有的哈希结果均会发生变化，从而不满足单调性的要

求。哈希结果的变化意味着当缓冲空间发生变化时，所有的映射关系需要在系统内全部更

新。而在P2P系统内，缓冲的变化等价于Peer加入或退出系统，这一情况在P2P系统中会频繁发生，因此会带来极大计算和传输负荷。单调性就是要求哈希算法能够应对这种情况。

分散性**(Spread)**

在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效 率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。

负载**(Load)**

负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内 容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。

平滑性(Smoothness)

平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。

综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。

另外，一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。例如系统中只有两台服务器，其环分布如下，

此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：

同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node

A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。
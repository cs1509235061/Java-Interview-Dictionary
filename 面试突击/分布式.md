# 分布式

### 1.衡量分布式系统的指标

1. 性能：系统的吞吐能⼒，指系统在某⼀时间可以处理的数据总量，通常可以⽤系统每秒处理的总的数据量来衡量；系统的响 应延迟，指系统完成某⼀功能需要使⽤的时间；系统的并发能⼒，指系统可以同时完成某⼀功能的能⼒，通常也⽤ QPS(query per second)来衡量。上述三个性能指标往往会相互制约，追求⾼吞吐的系统，往往很难做到低延迟；系统平均 响应时间较⻓时，也很难提⾼QPS。
2. 可⽤性：系统的可⽤性(availability)指系统在⾯对各种异常时可以正确提供服务的能⼒。系统的可⽤性可以⽤系统停服务的 时间与正常服务的时间的⽐例来衡量，也可以⽤某功能的失败次数与成功次数的⽐例来衡量。可⽤性是分布式的重要指标， 衡量了系统的鲁棒性，是系统容错能⼒的体现。
3. 可扩展性：系统的可扩展性(scalability)指分布式系统通过扩展集群机器规模提⾼系统性能（吞吐、延迟、并发）、存储容 量、计算能⼒的特性。好的分布式系统总在追求“线性扩展性”，也就是使得系统的某⼀指标可以随着集群中的机器数量线 性增⻓。
4. ⼀致性：分布式系统为了提⾼可⽤性，总是不可避免的使⽤副本的机制，从⽽引发副本⼀致性的问题。越是强的⼀致的性模 型，对于⽤⼾使⽤来说使⽤起来越简单。



# 分布式缓存

### 1.常见的缓存技术

操作系统磁盘缓存->减少磁盘机械操作 数据库缓存->减少文件系统I/O 应用程序缓存->减少对数据库的查询 Web 服务器缓存->减少应用服务器请求 客户端浏览器缓存->减少对网站的访问

### 2.项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？

项目中缓存是如何使用的？

这个，需要结合自己项目的业务来。

为什么要用缓存？

用缓存，主要有两个用途：**高性能**、**高并发**。

高性能

对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。

高并发

mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 `2000QPS` 也开始容易报警了。

所以要是你有个系统，高峰期一秒钟过来的请求有 1万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 `key-value` 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。

> 缓存是走内存的，内存天然就支撑高并发。

用了缓存之后会有什么不良后果？

常见的缓存问题有以下几个：

- 缓存与数据库双写不一致
- 缓存雪崩、缓存穿透
- 缓存并发竞争

### 3.缓存

当我们查询一条数据时，先去查询缓存，如果缓存有就直接返回，如果没有就去查询数据库，然后返回 缓存穿透、缓存击穿、缓存雪崩、热点数据失效

缓存穿透

什么是缓存穿透

正常情况下，我们去查询数据都是存在。那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象我们称为缓存穿透。 穿透带来的问题 试想一下，如果有黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。

解决办法

缓存空值

之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。那么我们就可以为这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null 。 这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。

BloomFilter

BloomFilter 类似于一个hbase set 用来判断某个元素（key）是否存在于某个集合中。这种方式在大数据场景应用比较多，比如 Hbase 中使用它去判断数据是否在磁盘上。还有在爬虫场景判断url 是否已经被爬取过。 这种方案可以加在第一种方案中，在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -> 查 DB。

如何选择

针对于一些恶意攻击，攻击带过来的大量key 是不存在的，那么我们采用第一种方案就会缓存大量不存在key的数据。此时我们采用第一种方案就不合适了，我们完全可以先对使用第二种方案进行过滤掉这些key。针对这种key异常多、请求 重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。

缓存击穿

什么是击穿

缓存击穿是我们可能遇到的第二个使用缓存方案可能遇到的问题。在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。 会带来什么问题 会造成某一时刻数据库请求量过大，压力剧增。

如何解决

上面的现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。 其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。

缓存雪崩

什么是缓存雪崩

缓存雪崩的情况是说，当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。结果就是DB 称不住，挂掉。

解决办法

事前： 使用集群缓存，保证缓存服务的高可用，这种方案就是在发生雪崩前对缓存集群实现高可用，如果是使用 Redis，可以使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况。 事中： ehcache本地缓存 + Hystrix限流&降级,避免MySQL被打死 使用 ehcache 本地缓存的目的也是考虑在 Redis Cluster 完全不可用的时候，ehcache 本地缓存还能够支撑一阵。 使用 Hystrix进行限流 & 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。 然后去调用我们自己开发的降级组件（降级），比如设置的一些默认值呀之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。 事后： 开启Redis持久化机制，尽快恢复缓存集群 一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。

解决热点数据集中失效问题

我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效了。对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库去，从而可能导致数据库崩溃的情况。

解决办法

设置不同的失效时间

为了避免这些热点的数据集中失效，那么我们在设置缓存过期时间的时候，我们让他们失效的时间错开。比如在一个基础的时间上加上或者减去一个范围内的随机值。

互斥锁

结合上面的击穿的情况，在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。

### 4.如何保证缓存与数据库的双写一致性？

Cache Aside Pattern

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 更新的时候，先更新数据库，然后再删除缓存。 为什么是删除缓存，而不是更新缓存？ 原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。 比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。 另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这 样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题 在于，这个缓存到底会不会被频繁访问到？ 举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而 已，开销大幅度降低，用到缓存才去算缓存。 其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要 被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查 询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部 门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。

最初级的缓存不一致问题及解决方案

问题：先修改数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。

解决思路：先删除缓存，再修改数据库。如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因 为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中。

比较复杂的数据不一致问题分析

数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库， 查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。

更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存 中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓 存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队 列中，此时会在队列中积压，然后同步等待缓存更新完成。 这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓 存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。 待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据 库中读取最新的值，然后写入缓存中。 如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接 从数据库中读取当前的旧值。 高并发的场景下，该解决方案要注意的问题：

1、读请求长时阻塞 由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。

该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时， 最后导致大量的请求直接走数据库。务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。

2、读请求并发量过高 这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务 上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。 但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数 据对应的读请求过来，并发量应该也不会特别大。 3、多服务实例部署的请求路由 可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器路由到相 同的服务实例上。 比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。

4、热点商品的路由问题，导致请求的倾斜 万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。就是说，因为只有 在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问 题的影响并不是特别大，但是的确可能某些机器的负载会高一些。

### 5.说说缓存最关心的问题？有哪些类型？回收策略和算法？

缓存命中率

缓存命中率是从缓存中读取数据的次数与总读取次数的比率，命中率越高越好。缓存命中率=从缓存中读取次数 / (总读取次数 (从缓存中读取次数 + 从慢速设备上读取次数))。这是一个非常重要的监控指标，如果做缓存，则应通过监控这个指标来看缓存是否工作良好。

缓存类型

缓存类型总体上来看，可以分为：堆缓存、堆外缓存、磁盘缓存和分布式缓存。

堆内存

使用Java堆内存来存储对象。使用堆缓存的好处是没有序列化/反序列化，是最快的缓存。缺点也很明显，当缓存的数据量很大时，GC（垃圾回收）暂停时间会变长，存储容量受限于堆空间大小。一般通过软引用/弱引用来存储缓存对象。即当堆内存不足时，可以强制回收这部分内存释放堆内存空间。一般使用堆缓存存储较热的数据。可以使用Guava Cache、Ehcache 3.x、 MapDB实现。

堆外内存

即缓存数据存储在堆外内存，可以减少GC暂停时间（堆对象转移到堆外，GC扫描和移动的对象变少了），可以支持更多的缓存空间（只受机器内存大小限制，不受堆空间的影响）。但是，读取数据时需要序列化/反序列化。因此，会比堆缓存慢很多。可以使用Ehcache 3.x、 MapDB实现。

磁盘缓存

即缓存数据存储在磁盘上，在JVM重启时数据还存在，而堆/堆外缓存数据会丢失，需要重新加载。可以使用Ehcache 3.x、MapDB实现。

分布式缓存

分布式缓存可以使用ehcache-clustered(配合Terracotta server)实现Java进程间分布式缓存。也可以使用Memcached、Redis实现。 使用分布式缓存时，有两种模式如下： 单机模式：存储最热的数据到堆缓存，相对热的数据到堆外缓存，不热的数据到磁盘缓存。 集群模式：存储最热的数据到堆缓存，相对热的数据到对外缓存，全量数据到分布式缓存。

缓存回收策略

缓存的回收策略总体上来说包含：基于空间的回收策略、基于容量（空间）的回收策略、基于时间的回收策略和基于对象引用的回收策略。

基于空间

基于空间指缓存设置了存储空间，如设置为10MB，当达到存储空间上限时，按照一定的策略移除数据。

基于容量

基于容量指缓存设置了最大大小，当缓存的条目超过最大大小时，按照一定的策略移除旧数据。

基于时间

TTL(Time To Live):存活期，即缓存数据从创建开始直到到期的一个时间段（不管在这个时间段内有没有被访问，缓存数据都将过期）。TTI(Time To Idle)：空闲期，即缓存数据多久没被访问后移除缓存的时间。

基于对象引用

软引用：如果一个对象是软引用，则当JVM堆内存不足时，垃圾回收器可以回收这些对象。软引用适合用来做缓存，从而当JVM堆内存不足时，可以回收这些对象腾出一些空间供强引用对象使用，从而避免OOM。弱引用：当垃圾回收器回收内存时，如果发现弱引用，则将它立即回收。相对于软引用，弱引用有更短的生命周期。

注意：只有在没有其他强引用对象引用弱引用/软引用对象时，垃圾回收时才回收该引用。即如果有一个对象（不是弱引用/软引用对象）引用了弱引用/软引用对象，那么垃圾回收时不会回收该弱引用/软引用对象。

回收算法

使用基于空间和基于容量的缓存会使用一定的策略移除旧数据，通常包含：FIFO算法、LRU算法和LFU算法。

- FIFO(First In First Out)：先进先出算法，即先放入缓存的先被移除。
- LRU(Least Recently Used)：最近最少使用算法，时间时间距离现在最久的那个被移除。
- LFU(Least Frequently Used)：最不常用算法，一定时间段内使用次数（频率）最少的那个被移除。

实际应用中基于LRU的缓存居多。

### 6.讲讲什么是缓存穿透？击穿？雪崩？如何解决？

缓存穿透

首先，我们来说说缓存穿透。什么是缓存穿透呢？缓存穿透问题在一定程度上与缓存命中率有关。如果我们的缓存设计的不合理，缓存的命中率非常低，那么，数据访问的绝大部分压力都会集中在后端数据库层面。

什么是缓存穿透？

如果在请求数据时，在缓存层和数据库层都没有找到符合条件的数据，也就是说，在缓存层和数据库层都没有命中数据，那么，这种情况就叫作缓存穿透。

造成缓存穿透的主要原因就是：查询某个Key对应的数据，Redis缓存中没有相应的数据，则直接到数据库中查询。数据库中也不存在要查询的数据，则数据库会返回空，而Redis也不会缓存这个空结果。这就造成每次通过这样的Key去查询数据都会直接到数据库中查询，Redis不会缓存空结果。这就造成了缓存穿透的问题。

如何解决缓存穿透问题？

既然我们知道了造成缓存穿透的主要原因就是缓存中不存在相应的数据，直接到数据库查询，数据库返回空结果，缓存中不存储空结果。 那我们就自然而然的想到了第一种解决方案：就是把空对象缓存起来。当第一次从数据库中查询出来的结果为空时，我们就将这个空对象加载到缓存，并设置合理的过期时间，这样，就能够在一定程度上保障后端数据库的安全。 第二种解决缓存穿透问题的解决方案：就是使用布隆过滤器，布隆过滤器可以针对大数据量的、有规律的键值进行处理。一条记录是不是存在，本质上是一个Bool值，只需要使用 1bit 就可以存储。我们可以使用布隆过滤器将这种表示是、否等操作，压缩到一个数据结构中。比如，我们最熟悉的用户性别这种数据，就非常适合使用布隆过滤器来处理。

缓存击穿

如果我们为缓存中的大部分数据设置了相同的过期时间，则到了某一时刻，缓存中的数据就会批量过期。

什么是缓存击穿？

如果缓存中的数据在某个时刻批量过期，导致大部分用户的请求都会直接落在数据库上，这种现象就叫作缓存击穿。

造成缓存击穿的主要原因就是：我们为缓存中的数据设置了过期时间。如果在某个时刻从数据库获取了大量的数据，并设置了相同的过期时间，这些缓存的数据就会在同一时刻失效，造成缓存击穿问题。

如何解决缓存击穿问题？

对于比较热点的数据，我们可以在缓存中设置这些数据永不过期；也可以在访问数据的时候，在缓存中更新这些数据的过期时间；如果是批量入库的缓存项，我们可以为这些缓存项分配比较合理的过期时间，避免同一时刻失效。 还有一种解决方案就是：使用分布式锁，保证对于每个Key同时只有一个线程去查询后端的服务，某个线程在查询后端服务的同时，其他线程没有获得分布式锁的权限，需要进行等待。不过在高并发场景下，这种解决方案对于分布式锁的访问压力比较大。

缓存雪崩

如果缓存系统出现故障，所有的并发流量就会直接到达数据库。

什么是缓存雪崩？

如果在某一时刻缓存集中失效，或者缓存系统出现故障，所有的并发流量就会直接到达数据库。数据存储层的调用量就会暴增，用不了多长时间，数据库就会被大流量压垮，这种级联式的服务故障，就叫作缓存雪崩。

造成缓存雪崩的主要原因就是缓存集中失效，或者缓存服务发生故障，瞬间的大并发流量压垮了数据库。

如何解决缓存雪崩问题？

解决缓存雪崩问题最常用的一种方案就是保证Redis的高可用，将Redis缓存部署成高可用集群（必要时候做成异地多活），可以有效的防止缓存雪崩问题的发生。 为了缓解大并发流量，我们也可以使用限流降级的方式防止缓存雪崩。例如，在缓存失效后，通过加锁或者使用队列来控制读数据库写缓存的线程数量。具体点就是设置某些Key只允许一个线程查询数据和写缓存，其他线程等待。则能够有效的缓解大并发流量对数据库带来的巨大冲击。 另外，我们也可以通过数据预热的方式将可能大量访问的数据加载到缓存，在即将发生大并发访问的时候，提前手动触发加载不同的数据到缓存中，并为数据设置不同的过期时间，让缓存失效的时间点尽量均匀，不至于在同一时刻全部失效。

# 分布式事务

## 1.事务

事务是Web应用中不可缺少的组件模型，它保证了用户操作的原子性（Atomicity)、一 致性（Consistency ）、隔离性（Isolation ）和持久性（Durability)。事务分本地事务和分布式事务两种。

### 本地事务

本地事务基于数据库资源实现，事务串行地在JDBC连接上执行，本地事务将事务处理局限在当前事务资源内。其特点是使用灵活但无法支持多数源事务操作。在数据库连接中使用本地事务的代码示例如下：

```html
try{
    //将自动提交设置为false
    //若设置为true，则数据库将会把每一次数据更新认定为一个事务并自动提交
    conn.setAutoCommit(false); 
    //提交事务
    conn.commit();
} catch(SQLException sqle) { 
    //异常回滚：发生异常，回滚在本事务中的操作  
    conn.rollback(); 
```

在上述代码中，首先通conn.seAutoCommit(false）设置数据库连接为非自动提交，然后分别提交了两条更新语句，最后通过conn.commit（）提交事务。如果数据库操作成功，则事务完成；如果操作失败，则通过conn.rollback（）回滚事务。

### 分布式事务

分布式事务（Distributed Transaction ）提供了跨数据库的分布式事务操作的数据一致性，跨数据库的一致性包含同一类型数据库的多个数据库实例服务的一致性（例如多个MySQL的事务一致性）和多个不同类型数据库的数据一致性（例如MySQL和Oracle之间的事务一致性）两种情况。

Java事务编程接口（Java Transaction API, JTA ）和Java事务服务(Java Transaction Service, JTS)为 J2EE平台提供了分布式事务服务。分布式事务包括一个事务管理器( Transaction Manager)和一个或多个支恃XA协议（XA协议是由X/Open组织提出的分布式事务的规范，XA规范主要定义了事务管理器和资源管理器之间的接口）的资源管理器（Resource Manager）。 其中，事务管理器负责所有事务参与单元的协调与控制，资源管理器负责不同的数据库具体的事务执行操作。具体使用代码如下：

```html
public void transferAccount() {     
    UserTransacton userTx = null; 
    //step1 ：定义a.b数据库连接
    Connection connA = null; 
    Statement stmtA = null; 
    Connection connB = null; 
    Statement stmtB = null; 
    try{}
        //step2 ：获得Transaction管理对象
        userTx = （UserTransaction)getCoηtext () .lookup (”java:comp/UserTransaction"); 
        connA = getDataSourceA() .getConnection() ;//step 3.1：从数据库中取得数据库连接
        connB = getDataSourceB() .getConnection();//step 3.2：从数据库中取得数据库连接
        userTx.begin (); //step 4：启动事务
        stmtA = connA.createStatement();//step 5.1：操作库数据：将A账户中的金额减少500
        stmtA.execute (”update t_account set amount = amount -500 where account_id =’A’”); 
        //step 5.2：操作B库数据：将B账户中的金额增加500
        stmtB = connB.createStatement();    
        stmtB.execute (”update t_account set amount = amount + 500 where account_id =’B’”) ; 
        userTx.commit();//step6： 提交事务
        //提交事务：转账的两步操作同时执行（数据库A和数据库B中的数据被同时更新）
    } catch(SQLException sqle) { 
        //step 7：回滚事务，发生异常，回滚在本事务中的操作
        userTx.rollback(); //数据库A和数据库B中的数据更新被同时撤销
```

在上述代码中，首先定义了一个分布式事务管理器UserTransacton，然后定义了2个连接池connA和connB，接着通过userTx.begin（）启动事务并向两个数据库连接提交2个更新请求，最后通过userTx.commit（）统一提交事务。如果执行成功，则事务完成；如果失败，则通过userTx.rollback（）回滚事务。

## 2.分布式事务

### 传统事务

传统事务遵循ACID原则，即原子性、一致性、隔离性和持久性。

- 原子性：事务是包含一系列操作的原子操作，事务的原子性确保这些操作全部完成或者全部失败。
- 一致性：事务执行的结果必须使数据库从不一致性状态转为一致性状态。保证数据库的一致性指在事务完成时，必须使所有数据都有一致的状态。
- 隔离性：因为可能在相同的数据集上同时有许多事务要处理，所以每个事务都应该与其他事务隔离，避免数据被破坏。
- 持久性：一旦事务完成，其结果就应该能够承受任何系统的错误，比如在事务提交过程中服务器的电源被切断等。在通常情况下，事务的结果被写入持续性存储中。

### 柔性事务

在分布式数据库领域，基于CAP理论及BASE理论，阿里巴巴提出了柔性事务的概念。BASE理论是CAP理论的延伸，包括基本可用（BasicallyAvailable）、柔性状态（Soft State）、最终一致性（EventualConsistency）三个原则，并基于这三个原则设计出了柔性事务。

我们通常所说的柔性事务分为：两阶段型、补偿型、异步确保型、最大努力通知型。

两阶段型事务指分布式事务的两阶段提交，对应技术上的XA和JTA/JTS，是分布式环境下事务处理的典型模式。

TCC型事务（Try、Confirm、Cancel）为补偿型事务，是一种基于补偿的事务处理模型。如图 7-10所示，服务器A发起事务，服务器B参与事务，如果服务器A的事务和服务器B的事务都顺利执行完成并提交，则整个事务执行完成。但是，如果事务B执行失败，事务B本身就回滚，这时事务A已被提交，所以需要执行一个补偿操作，将已经提交的事务A执行的操作进行反操作，恢复到未执行前事务A的状态。需要注意的是，发起提交的一般是主业务服务，而状态补偿的一般是业务活动管理者，因为活动日志被存储在业务活动管理中，补偿需要依靠日志进行恢复。TCC事务模型牺牲了一定的隔离性和一致性，但是提高了事务的可用性。

异步确保型事务指将一系列同步的事务操作修改为基于消息队列异步执行的操作，来避免分布式事务中同步阻塞带来的数据操作性能下降。

（1）业务A的模块在数据库A上执行数据更新操作。

（2）业务A调用写消息数据模块。

（3）写消息日志模块将数据库的写操作状态写入数据库A中。

（4）写消息日志模块将写操作日志发送给消息服务器。

（5）读消息日志模块接收操作日志。

（6）读消息数据调用写业务B的模块。

（7）写业务B更新数据到数据库B。

（8）写业务数据B的模块发送异步消息更新数据库A中的写消息日志状态，说明自己已经完成了异步数据更新操作。

最大努力通知型事务也是通过消息中间件实现的，与前面异步确保型操作不同的是：在消息由MQ服务器发送到消费者之后，允许在达到最大重试次数之后正常结束事务，因此无法保障数据的最终一致性。比如，写业务数据A在更新数据库后调用写消息日志将数据操作以异步消息的形式发送给读消息日志模块；读消息日志模块在接收到数据操作后调用写业务B写数据库。和异步确保型不同的是，数据库B在写完之后将不再通知写状态到数据库A，如果因为网络或其他原因，第4步没有接收到消息，则消息服务器将不断重试发送消息到读消息日志，如果经过 N次重试后读消息日志还是没有接收到日志，则消息不再发送，这时会出现数据库A和数据库B数据不一致的情况。最大努力型通知事务通过消息服务使分布式事务异步解耦，并且模块简单、高效，但是牺牲了数据的一致性，在金融等对事务要求高的业务中不建议使用，但在日志记录类等对数据一致性要求不是很高的应用上执行效率很高。

## 3.CAP

CAP原则又称CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）和分区容错性（Partitiontolerance）三者不可兼得。

- 一致性：在分布式系统的所有数据备份中，在同一时刻是否有同样的值（等同于所有节点都访问同一份最新的数据副本）。
- 可用性：在集群中一部分节点发生故障后，集群整体能否响应客户端的读写请求（对数据更新具备高可用性）。
- 分区容错性：系统如果不能在时限内达成数据的一致性，就意味着发生了分区，必须就当前操作在C和A 之间做出选择。以实际效果而言，分区相当于对通信的时限要求。

## 4.两阶段提交协议

分布式事务指涉及操作多个数据库的事务，在分布式系统中，各个节点之间在物理上相互独立，通过网络进行沟通和协调。

二阶段提交（Two-Phase Commit）指在计算机网络及数据库领域内，为了使分布式数据库的所有节点在进行事务提交时都保持一致性而设计的一种算法。在分布式系统中，每个节点虽然都可以知道自己的操作是否成功，却无法知道其他节点的操作是否成功。

在一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点（称作参与者）的操作结果，并最终指示这些节点是否真正提交操作结果（比如将更新后的数据写入磁盘等）。因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈决定各参与者是提交操作还是中止操作。

### Prepare（准备阶段）

事务协调者（事务管理器）给每个参与者（源管理器）都发送Prepare消息，每个参与者要么直接返回失败（如权限验证失败），要么在本地执行事务，写本地的redo和undo日志但不提交，是一种“万事俱备，只欠东风”的状态。

### Commit（提交阶段）

如果协调者接收到了参与者的失败消息或者超时，则直接给每个参与者都发送回滚消息，否则发送提交消息，参与者根据协调者的指令执行提交或者回滚操作，释放在所有事务处理过程中使用的锁资源。

### 两阶段提交的缺点

- 同步阻塞问题：在执行过程中，所有参与者的任务都是阻塞执行的。
- 单点故障：所有请求都需要经过协调者，在协调者发生故障时，所有参与者都会被阻塞。
- 数据不一致：在二阶段提交的第2 阶段，在协调者向参与者发送Commit（提交）请求后发生了局部网络异常，或者在发送Commit请求过程中协调者发生了故障，导致只有一部分参与者接收到Commit请求，于是整个分布式系统出现了数据不一致的现象，这也被称为脑裂。
- 协调者宕机后事务状态丢失：协调者在发出Commit消息之后宕机，唯一接收到这条消息的参与者也宕机，即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没有人知道事务是否已被提交。

## 5.三阶段提交协议

三阶段提交（Three-Phase Commit），也叫作三阶段提交协议（Three-Phase Commit Protocol），是二阶段提交（2PC）的改进版本。具体改进如下。

- 引入超时机制：在协调者和参与者中引入超时机制，如果协调者长时间接收不到参与者的反馈，则认为参与者执行失败。
- 在第1 阶段和第2 阶段都加入一个预准备阶段，以保证在最后的任务提交之前各参与节点的状态是一致的。也就是说，除了引入超时机制，三阶段提交协议（3PC）把两阶段提交协议（2PC）的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。

### CanCommit阶段

协调者向参与者发送Commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。

### PreCommit阶段

协调者根据参与者的反应来决定是否继续进行，有以下两种可能。

- 假如协调者从所有参与者那里获得的反馈都是Yes响应，就预执行事务。
- 假如有任意参与者向协调者发送了No响应，或者在等待超时之后协调者都没有接收到参与者的响应，则执行事务的中断。

### DoCommit阶段

该阶段进行真正的事务提交，主要包括：协调者发送提交请求，参与者提交事务，参与者响应反馈（在事务提交完之后向协调者发送Ack响应），协调者确定完成事务。

## 6.柔性事务

在电商领域等互联网场景下，传统的事务在数据库性能和处理能力上都暴露出了瓶颈。在分布式领域基于CAP理论以及BASE理论，有人就提出了柔性事务的概念。CAP（一致性、可用性、分区容忍性）理论大家都理解很多次了，这里不再叙述。说一下BASE理论，它是在CAP理论的基础之上的延伸。包括基本可用（Basically Available）、柔性状态（Soft State）、最终一致性（Eventual Consistency）。

通常所说的柔性事务分为：两阶段型、补偿型、异步确保型、最大努力通知型几种

### 两阶段型

1、就是分布式事务两阶段提交，对应技术上的XA、JTA/JTS。这是分布式环境下事务处理的典型模式。

### 补偿型

2、TCC型事务（Try/Confirm/Cancel）可以归为补偿型。

WS-BusinessActivity提供了一种基于补偿的long-running的事务处理模型。服务器A发起事务，服务器B参与事务，服务器A的事务如果执行顺利，那么事务A就先行提交，如果事务B也执行顺利，则事务B也提交，整个事务就算完成。但是如果事务B执行失败，事务B本身回滚，这时事务A已经被提交，所以需要执行一个补偿操作，将已经提交的事务A执行的操作作反操作，恢复到未执行前事务A的状态。这样的SAGA事务模型，是牺牲了一定的隔离性和一致性的，但是提高了long-running事务的可用性。

### 异步确保型

3、通过将一系列同步的事务操作变为基于消息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响。

### 最大努力通知型（多次尝试）

4、这是分布式事务中要求最低的一种, 也可以通过消息中间件实现, 与前面异步确保型操作不同的一点是, 在消息由MQ Server投递到消费者之后,允许在达到最大重试次数之后正常结束事务。

## 7.如何解决分布式事务问题

分布式事务的实现主要有以下 6 种方案：

- XA 方案
- TCC 方案
- SAGA 方案
- 本地消息表
- 可靠消息最终一致性方案
- 最大努力通知方案

两阶段提交方案/XA 方案

所谓的 XA 方案，即：两阶段提交，有一个**事务管理器**的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先问问各个数据库你准备好了吗？如果每个数据库都回复 ok，那么就正式提交事务，在各个数据库上执行操作；如果任何其中一个数据库回答不 ok，那么就回滚事务。

这种分布式事务方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。

这个方案很少用，一般来说**某个系统内部如果出现跨多个库**的这么一个操作，是**不合规**的。我可以给大家介绍一下， 现在微服务，一个大的系统分成几十个甚至几百个服务。一般来说，我们的规定和规范，是要求**每个服务只能操作自己对应的一个数据库**。

如果你要操作别的服务对应的库，不允许直连别的服务的库，违反微服务架构的规范，你随便交叉胡乱访问，几百个服务的话，全体乱套，这样的一套服务是没法管理的，没法治理的，可能会出现数据被别人改错，自己的库被别人写挂等情况。

如果你要操作别人的服务的库，你必须是通过**调用别的服务的接口**来实现，绝对不允许交叉访问别人的数据库。

TCC 方案

TCC 的全称是： `Try` 、 `Confirm` 、 `Cancel` 。

- Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行**锁定或者预留**。
- Confirm 阶段：这个阶段说的是在各个服务中**执行实际的操作**。
- Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要**进行补偿**，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）

这种方案很少人使用，因为这个**事务回滚**实际上是**严重依赖于你自己写代码来回滚和补偿**了，会造成补偿代码巨大。

一般来说跟**钱**相关的，跟钱打交道的，**支付**、**交易**相关的场景，我们会用 TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，保证在资金上不会出现问题。

而且最好是你的各个业务执行的时间都比较短。

Saga 方案

业务流程中每个参与者都提交本地事务，若某一个参与者失败，则补偿前面已经成功的参与者。当执行到 T3 时发生了错误，则开始执行右边的事务补偿流程，反向执行 T3、T2、T1 的补偿服务 C3、C2、C1，将 T3、T2、T1 已经修改的数据补偿掉。

对于一致性要求高、短流程、并发高 的场景，如：金融核心系统，会优先考虑 TCC 方案。而在另外一些场景下，我们并不需要这么强的一致性，只需要保证最终一致性即可。

适用场景是：

- 业务流程长、业务流程多；
- 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口。

优势

- 一阶段提交本地事务，无锁，高性能；
- 参与者可异步执行，高吞吐；
- 补偿服务易于实现，因为一个更新操作的反向操作是比较容易理解的。

缺点

- 不保证事务的隔离性。

本地消息表

大概意思是这样的：

1. A 系统在自己本地一个事务里操作同时，插入一条数据到消息表；
2. 接着 A 系统将这个消息发送到 MQ 中去；
3. B 系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样**保证不会重复处理消息**；
4. B 系统执行成功之后，就会更新自己本地消息表的状态以及 A 系统消息表的状态；
5. 如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理；
6. 这个方案保证了最终一致性，哪怕 B 事务失败了，但是 A 会不断重发消息，直到 B 那边成功为止。

最大的问题就在于**严重依赖于数据库的消息表来管理事务**啥的，如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用。

可靠消息最终一致性方案

这个的意思，就是干脆不要用本地的消息表了，直接基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。

大概的意思就是：

1. A 系统先发送一个 prepared 消息到 mq，如果这个 prepared 消息发送失败那么就直接取消操作别执行了；
2. 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息；
3. 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；
4. mq 会自动**定时轮询**所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。
5. 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。
6. 这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你就用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。

最大努力通知方案

这个方案的大致意思就是：

1. 系统 A 本地事务执行完之后，发送个消息到 MQ；
2. 这里会有个专门消费 MQ 的**最大努力通知服务**，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口；
3. 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。

你们是如何处理分布式事务的？

根据业务来说，严格资金要求绝对不能错的场景，你可以说你是用的 TCC 方案；如果是一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么的敏感，可以用可靠消息最终一致性方案。

## 8.基于MQ的异步调用，如何保证各个服务间的分布式事务呢？

希望的是基于MQ实现异步调用的多个服务的业务逻辑，要么一起成功，要么一起失败。这个时候，就要用上可靠消息最终一致性方案，来实现分布式事务。

（1）上游服务投递消息

首先，上游服务需要发送一条消息给可靠消息服务。这条消息说白了，你可以认为是对下游服务一个接口的调用，里面包含了对应的一些请求参数。然后，可靠消息服务就得把这条消息存储到自己的数据库里去，状态为“待确认”。 接着，上游服务就可以执行自己本地的数据库操作，根据自己的执行结果，再次调用可靠消息服务的接口。 如果本地数据库操作执行成功了，那么就找可靠消息服务确认那条消息。如果本地数据库操作失败了，那么就找可靠消息服务删除那条消息。 此时如果是确认消息，那么可靠消息服务就把数据库里的消息状态更新为“已发送”，同时将消息发送给MQ。 这里有一个很关键的点，就是更新数据库里的消息状态和投递消息到MQ。这俩操作，你得放在一个方法里，而且得开启本地事务。 如果数据库里更新消息的状态失败了，那么就抛异常退出了，就别投递到MQ；如果投递MQ失败报错了，那么就要抛异常让本地数据库事务回滚。这俩操作必须得一起成功，或者一起失败。 如果上游服务是通知删除消息，那么可靠消息服务就得删除这条消息。

（2）下游服务接收消息

下游服务就一直等着从MQ消费消息好了，如果消费到了消息，那么就操作自己本地数据库。 如果操作成功了，就反过来通知可靠消息服务，说自己处理成功了，然后可靠消息服务就会把消息的状态设置为“已完成”。

（3）如何上游服务对消息的100%可靠投递？

如果上游服务给可靠消息服务发送待确认消息的过程出错了，那没关系，上游服务可以感知到调用异常的，就不用执行下面的流程了，这是没问题的。 如果上游服务操作完本地数据库之后，通知可靠消息服务确认消息或者删除消息的时候，出现了问题。比如：没通知成功，或者没执行成功，或者是可靠消息服务没成功的投递消息到MQ。这一系列步骤出了问题怎么办？ 其实也没关系，因为在这些情况下，那条消息在可靠消息服务的数据库里的状态会一直是“待确认”。此时，我们在可靠消息服务里开发一个后台定时运行的线程，不停的检查各个消息的状态。如果一直是“待确认”状态，就认为这个消息出了点什么问题。 此时的话，就可以回调上游服务提供的一个接口，问问说，兄弟，这个消息对应的数据库操作，你执行成功了没啊？如果上游服务答复说，我执行成功了，那么可靠消息服务将消息状态修改为“已发送”，同时投递消息到MQ。如果上游服务答复说，没执行成功，那么可靠消息服务将数据库中的消息删除即可。通过这套机制，就可以保证，可靠消息服务一定会尝试完成消息到MQ的投递。

（4）如何保证下游服务对消息的100%可靠接收？

那如果下游服务消费消息出了问题，没消费到？或者是下游服务对消息的处理失败了，怎么办？ 其实也没关系，在可靠消息服务里开发一个后台线程，不断的检查消息状态。 如果消息状态一直是“已发送”，始终没有变成“已完成”，那么就说明下游服务始终没有处理成功。此时可靠消息服务就可以再次尝试重新投递消息到MQ，让下游服务来再次处理。只要下游服务的接口逻辑实现幂等性，保证多次处理一个消息，不会插入重复数据即可。

（5）如何基于RocketMQ来实现可靠消息最终一致性方案？

在上面的通用方案设计里，完全依赖可靠消息服务的各种自检机制来确保： 如果上游服务的数据库操作没成功，下游服务是不会收到任何通知 如果上游服务的数据库操作成功了，可靠消息服务死活都会确保将一个调用消息投递给下游服务，而且一定会确保下游服务务必成功处理这条消息。 通过这套机制，保证了基于MQ的异步调用/通知的服务间的分布式事务保障。

## 9.可靠消息最终一致性方案的高可用保障

### 基于KV存储的队列支持的高可用降级方案

（1）自行封装MQ客户端组件与故障感知

首先第一点，你要做到自动感知MQ的故障接着自动完成降级，那么必须动手对MQ客户端进行封装，发布到公司Nexus私服上去。 然后公司需要支持MQ降级的业务服务都使用这个自己封装的组件来发送消息到MQ，以及从MQ消费消息。 在你自己封装的MQ客户端组件里，你可以根据写入MQ的情况来判断MQ是否故障。 比如说，如果连续10次重试尝试投递消息到MQ都发现异常报错，网络无法联通等问题，说明MQ故障，此时就可以自动感知以及自动触发降级开关。

（2）基于kv存储中队列的降级方案

如果MQ挂掉之后，要是希望继续投递消息，那么就必须得找一个MQ的替代品。 举个例子，比如我那位朋友的公司是没有高并发场景的，消息的量很少，只不过可用性要求高。此时就可以类似redis的kv存储中的队列来进行替代。 由于redis本身就支持队列的功能，还有类似队列的各种数据结构，所以你可以将消息写入kv存储格式的队列数据结构中去。 这里有几个大坑，一定要注意一下。 第一个，任何kv存储的集合类数据结构，建议不要往里面写入数据量过大，否则会导致大value的情况发生，引发严重的后果。因此绝不能在redis里搞一个key，就拼命往这个数据结构中一直写入消息，这是肯定不行的。 第二个，绝对不能往少数key对应的数据结构中持续写入数据，那样会导致热key的产生，也就是某几个key特别热。 大家要知道，一般kv集群，都是根据key来hash分配到各个机器上的，你要是老写少数几个key，会导致kv集群中的某台机器访问过高，负载过大。 设计的方案： 根据他们每天的消息量，在kv存储中固定划分上百个队列，有上百个key对应。 这样保证每个key对应的数据结构中不会写入过多的消息，而且不会频繁的写少数几个key。 一旦发生了MQ故障，可靠消息服务可以对每个消息通过hash算法，均匀的写入固定好的上百个key对应的kv存储的队列中。 同时此时需要通过zk触发一个降级开关，整个系统在MQ这块的读和写全部立马降级。

（3）下游服务消费MQ的降级感知

下游服务消费MQ也是通过自行封装的组件来做的，此时那个组件如果从zk感知到降级开关打开了，首先会判断自己是否还能继续从MQ消费到数据？ 如果不能了，就开启多个线程，并发的从kv存储的各个预设好的上百个队列中不断的获取数据。每次获取到一条数据，就交给下游服务的业务逻辑来执行。通过这套机制，就实现了MQ故障时候的自动故障感知，以及自动降级。如果系统的负载和并发不是很高的话，用这套方案大致是没没问题的。因为在生产落地的过程中，包括大量的容灾演练以及生产实际故障发生时的表现来看，都是可以有效的保证MQ故障时，业务流程继续自动运行的。

（4）故障的自动恢复

如果降级开关打开之后，自行封装的组件需要开启一个线程，每隔一段时间尝试给MQ投递一个消息看看是否恢复了。 如果MQ已经恢复可以正常投递消息了，此时就可以通过zk关闭降级开关，然后可靠消息服务继续投递消息到MQ，下游服务在确认kv存储的各个队列中已经没有数据之后，就可以重新切换为从MQ消费消息。

### 10.分布式事物方案

2PC 的流程

第一阶段（提交请求阶段）：

1. 协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应。
2. 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。
3. 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个"同意"消息；如果参与者节 点的事务操作实际执行失败，则它返回一个"中止"消息。

第二阶段 (提交执行阶段)： 成功，当协调者节点从所有参与者节点获得的相应消息都为"同意"时： 1.协调者节点向所有参与者节点发出"正式提交"的请求。 2.参与者节点正式完成操作，并释放在整个事务期间内占用的资源。 3.参与者节点向协调者节点发送"完成"消息。 4.协调者节点收到所有参与者节点反馈的"完成"消息后，完成事务。 失败，如果任一参与者节点在第一阶段返回的响应消息为"终止"，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节 点的响应消息时： 1.协调者节点向所有参与者节点发出"回滚操作"的请求。 2.参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。 3.参与者节点向协调者节点发送"回滚完成"消息。 4.协调者节点收到所有参与者节点反馈的"回滚完成"消息后，取消事务。 有时候，第二阶段也被称作完成阶段，因为无论结果怎样，协调者都必须在此阶段结束当前事务。

我们以创建订单下单过程和 后面出库 的流程为例来讲述上面的图。 在下单逻辑里面（Producer 端），我们先生成一个订单的数据，比如订单号，数量等关键的信息，先包装成一条消息，并把消息的状 态置为 init ,然后发送到 独立消息服务中，并且入库。 接下来继续处理 下单的其他本地的逻辑。 处理完成后，走到确认发送消息这一步，说明我的订单是能够下成功的。那么我们再向消息服务里面发送一条confirm 的消息，消息 服务里面就可以把这个订单的消息状态修改为 send 并且，发送到消息队列里面。 接下来，消费者端去消费这条消息。处理自己这边的逻辑，处理完成以后，然后反馈消息处理结果到独立消息服务，独立消息服务把 消息状态置为 end 状态 ,表示结束。但是得注意保证接口的幂等性，避免重复消费带来的问题。 这里面可能出现的问题，以及各个步骤怎么解决的： 1.比如在 prepare 阶段就发生异常，那么这里订单这块都不会下成功。但是我们说，我们这里是基于可靠消息，得保证我们的消息服 务是正常的。 2.在 comfirm 出现异常，此时发送确认失败，但是我们的单已经下成功了。这种情况，我们就可以在独立消息服务中起一个定时任 务，定时去查询 消息状态为 init 的数据，去反向查询 订单系统中的单号是否存在，如果存在，那么我们就把消息置为 send 状态，然 后发送到 消息队列里面，如果查询到不存在的订单，那么就直接抛弃掉这条消息。所以这里我们的订单系统得提供批量查询订单的接 口，还有下游的消费系统得保证幂等。保证重复消费的一致性。 3.消息队列丢消息或者下游系统一直处理失败，导致没有消息反馈过来，出现一直是 send 状态的消息。此时独立消息我们还需要一 个定时任务，就是处理这种 send 状态的消息，我们可以进行重发，直到后面系统消费成功为止。 4.最后消费者这端，我们在消费的时候，如果出现消费异常，或者是系统bug 导致异常的情况。那么这里我们还可以去记录日志，如 果不是系统代码问题，是网络抖动导致的，那么在上面第三种情况，消息系统会重新发送消息，我们再处理就是。如果是一直失败， 你就要考虑是不是你的代码真的有问题，有bug 了吧。 5.最后的保底方案，记录日志，出现问题人肉处理数据。现在我们系统出现错误，以目前的技术手段是没办法做到都靠机器去解决 的，都得靠我们人。据我了解，现在很多大厂都会有这样的人，专门处理这种类型的问题，手动去修改数据库的方式。我们之前待的 小厂，基本上都是靠我们自己去写 sql 去修改数据的，想想，是不是？

基于 RocketMQ实现

针对这里的 可靠消息最终一致性方案 来说，我们说的 可靠 是指保证消息一定能发送到消息中间件里面去，保证这里可靠。 对于下游的系统来说，消费不成功，一般来说就是采取失败重试，重试多次不成功，那么就记录日志，后续人工介入来进行处理。所 以这里得强调一下，后面的系统，一定要处理 幂等，重试，日志 这几个东西。 如果是对于资金类的业务，后续系统回滚了以后，得想办法去通知前面的系统也进行回滚，或者是发送报警由人工来手工回滚和补 偿。

TCC 方案

TCC 的全程分为三个阶段，分别是 Try、Confirm、Cancel： 1.Try阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留 2.Confirm阶段：这个阶段说的是在各个服务中执行实际的操作 3.Cancel阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作

1.Try 阶段：先把A 银行账户先冻结 1 块，B银行账户中的资金给预加 1 块。 2.Confirm 阶段：执行实际的转账操作，A银行账户的资金扣减 1块，B 银行账户的资金增加 1 块。 3.Cancel 阶段：如果任何一个银行的操作执行失败，那么就需要回滚进行补偿，就是比如A银行账户如果已经扣减了，但是B银行账 户资金增加失败了，那么就得把A银行账户资金给加回去。

### 10.BASE理论

BASE 理论是 Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。 1.基本可用（Basically Available）：指分布式系统在出现不可预知故障的时候，允许损失部分可用性。 2.软状态（ Soft State）：指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在 不同节点的数据副本之间进行数据同步的过程存在延时。 3.最终一致（ Eventual Consistency）：强调的是所有的数据更新操作，在经过一段时间的同步之后，最终都能够达到一个一致的状 态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 其核心思想是： 即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致 性（Eventual consistency）

### 82.什么是2PC（二阶段提交）？

**分布式一致性**

一个分布式系统如果其中某一个系统在执行过程中失败了，或者由于网络原因没有收到请求，那么，整个系统可能就有不一致的现象了，即：付了钱，扣了红包，但是库存没有扣减。

这就是所谓的分布式系统的数据一致性问题。

**二阶段提交**

引入一个协调者负责协调所有参与者的工作，这个在分布式系统中其实就是X/Open组织定义的分布式事务处理模型，而二阶段提交就是根据这一模型衍生出来的。

在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。

当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有参与者的操作结果并最终指示这些节点是否要把操作结果进行真正的提交。

因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。

所谓的两个阶段是指：第一阶段：**准备阶段(投票阶段)**和第二阶段：**提交阶段（执行阶段）**

**准备阶段**

事务协调者给每个参与者发送Prepare消息，每个参与者要么直接返回失败，要么在本地执行事务，但不提交。

可以进一步将准备阶段分为以下三个步骤：

- 1）协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应。（询问是否可以一起玩游戏）
- 2）参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（登录王者荣耀游戏）
- 3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；（告知组织者自己已经登录成功）如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。（告知组织者自己暂时无法一起玩游戏，如自己的账号被限制无法打排位）

**提交阶段**

如果协调者收到了参与者的失败消息或者超时（有人不能一起玩游戏，或者一直没有回复），直接给每个参与者发送回滚消息（告知其他人，暂时取消游戏）；否则，发送提交消息（邀请大家进入游戏房间）；参与者根据协调者的指令执行提交或者回滚操作（进入房间一起玩游戏或者退出游戏去做别的事情）。

接下来分两种情况分别讨论提交阶段的过程。

当协调者节点从所有参与者节点获得的相应消息都为”同意”时:

- 1）协调者节点向所有参与者节点发出”正式提交”的请求（要求所有已登录的朋友加入游戏房间）。
- 2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源（接受邀请，进入房间）。
- 3）参与者节点向协调者节点发送”完成”消息（点击"准备"，进入准备状态）。
- 4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务（进入王者峡谷）。

如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：

- 1）协调者节点向所有参与者节点发出”回滚操作”的请求（告知所有人取消游戏）。
- 2）参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源（退出游戏，去做自己的事情）。
- 3）参与者节点向协调者节点发送”回滚完成”消息（告诉组织者自己知道了，后面有机会再玩）。
- 4）协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务（取消本次游戏活动）。

2PC的缺点

以上过程其实是有一些缺点的，如

1、当参与者收到组织者的消息之后，需要登录游戏，在游戏中等待组织者的再次邀请，这个过程比较浪费时间。

2、如果在这个过程中，组织者突然有什么事情被打断了，那么那些已经进入游戏的参与者就可能一直等下去。

3、在所有人都登录游戏之后，组织者通过邀请要求所有人加入他的房间，这时候如果有一些网络异常、或者参与者没在手机前面等情况，可能会有一部分用户加入了房间，有一部分没加入。

4、如果组织者在游戏中开始邀请所有参与者的时候，他邀请了第一个人之后，他和这个被他邀请的人都掉线了。这时候另外三个人就不知道到底应该怎么办了。

以上问题，分布式系统的2PC阶段一样存在，分别对应以下问题：

1、**同步阻塞问题**。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。

2、**单点故障**。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）

3、**数据不一致**。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。

4、二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

总结一下，就是说2PC并不是完美的，他存在着同步阻塞问题、单点故障问题、无法100%保证数据一致性等问题。

### 85.什么是3PC？

三阶段提交

在二阶段提交（2PC）存在诸多问题的情况下，人们提出了三阶段提交（3PC），主要用来解决2PC存在的一些问题（但是这里提一句，3PC并没彻底解决2PC存在的所有问题）。

和2PC相比，3PC多了一个步骤，就是提前询问所以参与者是否都能参与，并且所有人都同意后再次通知大家登录游戏。

所谓3PC，就是把2PC的准备阶段再次一分为二，组成了三阶段。

在第一阶段，只是询问所有参与者是否可以执行事务操作，并不在本阶段执行事务操作。当协调者收到所有的参与者都返回YES时，在第二阶段才执行事务操作，然后在第三阶段在执行commit或者rollback。

这样三阶段提交就有CanCommit（事务询问）、PreCommit（事务执行）、DoCommit（事务提交）三个阶段。

**3PC的处理过程**

和二阶段提交对比，三阶段提交主要是在2PC的第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。

**CanCommit**

3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。

1、**事务询问**：协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。

2、**响应反馈**：参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回YES响应，并进入预备状态。否则反馈NO

**PreCommit阶段**

协调者根据CanCommit阶段参与者的反应情况来决定是否可以进行事务的PreCommit操作。

假如协调者从所有的参与者获得的反馈都是YES响应，那么就会执行事务的预执行：

1、**发送预提交请求**：协调者向参与者发送PreCommit请求，并进入Prepared阶段。

2、**事务预提交**：参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。

3、**响应反馈**：如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。

假如有任何一个参与者向协调者发送了NO响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。

1、**发送中断请求**：协调者向所有参与者发送abort请求。

2、**中断事务**：参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。

**doCommit阶段**

该阶段进行真正的事务提交，也可以分为以下两种情况。

如果协调证收到所有参与者的事务执行后的ACK响应，则发生如下事情：

1、**发送提交请求**：协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。

2、**事务提交**：参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。

3、**响应反馈**：事务提交完之后，向协调者发送Ack响应。

4、**完成事务**：协调者接收到所有参与者的ack响应之后，完成事务。

如果协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。

1、**发送中断请求**：协调者向所有参与者发送abort请求

2、**事务回滚**：参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。

3、**反馈结果**：参与者完成事务回滚之后，向协调者发送ACK消息

4、**中断事务**：协调者接收到参与者反馈的ACK消息之后，执行事务的中断。

还有一种情况，如果参与者无法及时接收到来自协调者的doCommit或者abort请求时，会在等待超时之后，会继续进行事务的提交。

3PC比2PC好在哪？

**1、降低同步阻塞**。

在3PC中，第一阶段并没有让参与者直接执行事务，而是在第二阶段才会让参与者进行事务的执行。大大降低了阻塞的概率和时长。并且，在3PC中，如果参与者未收到协调者的消息，那么他会在等待一段时间后自动执行事务的commit，而不是一直阻塞。

**2、提升了数据一致性**

2PC中有一种情况会导致数据不一致，如在2PC的阶段二中，当协调者向参与者发送commit请求之后，发生了网络异常，只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象。

这种情况在3PC的场景中得到了很好的解决，因为在3PC中，如果参与者没有收到协调者的消息时，他不会一直阻塞，过一段时间之后，他会自动执行事务。这就解决了那种协调者发出commit之后。

另外，2PC还有个问题无法解决。那就是协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

这种情况在3PC中是有办法解决的，因为在3PC中，选出新的协调者之后，他可以咨询所有参与者的状态，如果有某一个处于commit状态或者prepare-commit状态，那么他就可以通知所有参与者执行commit，否则就通知大家rollback。因为3PC的第三阶段一旦有机器执行了commit，那必然第一阶段大家都是同意commit的，所以可以放心执行commit。

3PC无法解决的问题

在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者abort请求时，会在等待超时之后，会继续进行事务的提交。

所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。

所以，我们可以认为，无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题。

# 分布式锁

## 1.基于zookeeper 做分布式锁

对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zookeeper 分布式锁，一个机器接收到了请求之后先获取 zookeeper 上的一把分布式锁，就是可以去创建一个 znode，接着执行操作；然后另外一个机器也**尝试去创建**那个 znode，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。

## 2.Redis 分布式锁

官方叫做 `RedLock` 算法，是 Redis 官方支持的分布式锁算法。

这个分布式锁有 3 个重要的考量点：

- 互斥（只能有一个客户端获取锁）
- 不能死锁
- 容错（只要大部分 Redis 节点创建了这把锁就可以）

Redis 最普通的分布式锁

第一个最普通的实现方式，就是在 Redis 里使用 `SET key value [EX seconds] [PX milliseconds] NX` 创建一个 key，这样就算加锁。其中：

- `NX`：表示只有 `key` 不存在的时候才会设置成功，如果此时 redis 中存在这个 `key`，那么设置失败，返回 `nil`。
- `EX seconds`：设置 `key` 的过期时间，精确到秒级。意思是 `seconds` 秒后锁自动释放，别人创建的时候如果发现已经有了就不能加锁了。
- `PX milliseconds`：同样是设置 `key` 的过期时间，精确到毫秒级。

比如执行以下命令：

```html
SET resource_name my_random_value PX 30000 NX
```

释放锁就是删除 key ，但是一般可以用 `lua` 脚本删除，判断 value 一样才删除。

为啥要用 `random_value` 随机值呢？因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，所以得用随机值加上面的 `lua` 脚本来释放锁。

但是这样是肯定不行的。因为如果是普通的 Redis 单实例，那就是单点故障。或者是 Redis 普通主从，那 Redis 主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。

RedLock 算法

这个场景是假设有一个 Redis cluster，有 5 个 Redis master 实例。然后执行如下步骤获取一把锁：

1. 获取当前时间戳，单位是毫秒；
2. 跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；
3. 尝试在**大多数节点**上建立一个锁，比如 5 个节点就要求是 3 个节点 `n / 2 + 1` ；
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，你就得**不断轮询去尝试获取锁**。

## 3.zk 分布式锁

zk 分布式锁，其实可以做的比较简单，就是某个节点尝试创建临时 znode，此时创建成功了就获取了这个锁；这个时候别的客户端来创建锁会失败，只能**注册个监听器**监听这个锁。释放锁就是删除这个 znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以再次重新加锁。

也可以采用另一种方式，创建临时顺序节点：

如果有一把锁，被多个人给竞争，此时多个人会排队，第一个拿到锁的人会执行，然后释放锁；后面的每个人都会去监听**排在自己前面**的那个人创建的 node 上，一旦某个人释放了锁，排在自己后面的人就会被 ZooKeeper 给通知，一旦被通知了之后，就 ok 了，自己就获取到了锁，就可以执行代码了。

## 4.redis 分布式锁和 zk 分布式锁的对比

- redis 分布式锁，其实**需要自己不断去尝试获取锁**，比较消耗性能。
- zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。

另外一点就是，如果是 Redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁；而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。

Redis 分布式锁大家没发现好麻烦吗？遍历上锁，计算时间等等......zk 的分布式锁语义清晰实现简单。

## 5.分布式锁

什么是分布式锁，分布式锁就是在分布式环境下用来解决多实例对数据访问一致性的一种技术方案。

分布式锁的特性

1. 在分布式环境下同一时刻只能被单个线程获取；
2. 可重入，意思是已经获得锁的线程在执行的过程中不需要再次获得锁；
3. 异常或者超时自动删除，避免死锁；
4. 高性能，分布式环境下必须要性能好；

实现方式

分布式锁的实现方式流行的主要有三种，分别是基于缓存 Redis 的实现方式，基于 ZK 临时顺序节点的实现以及基于数据库行锁的实现。

基于 Redis 缓存的实现

首先我们来看下基于 Redis 缓存实现的分布式锁，Redis 支持SETNX 命令，表示设置一个key 的值当且进度Key 不存在的时候才能设置成功。例如执行如下命令： set ziyou 18 NX PX 10000 表示将名叫ziyou 的 key 的值设置为 18，当且仅当不存在名为ziyou的 key 的时候才能设置成功，并且过期时间设置为 10 秒钟。 setnx 命令是 Redis 实现分布式锁的核心，这个命令操作是原子操作的，千万不能分两步先用set 再用expire ，这样分开操作不是原子性的，无法实现效果。 然后 Redis 分布式锁在网上有开源实现 Redission，具体的实现可以参考。

优点：

1. 实现简单；
2. 理解逻辑简单；
3. 性能好，毕竟是缓存。

缺点：

1. Redis 容易单点故障，集群部署；
2. key 的过期时间设置多少不明确，只能根据实际情况调整。

基于 ZK 的实现

对于 ZK 来说，实现分布式锁的核心是临时顺序节点。

临时表示在客户端创建某节点后，如果客户端经过一段时间跟服务端之间失去了心跳，说明客户端已经掉线了，那么这个节点就会被自动删除(这一点跟 Redis key 的过期时间类似)；顺序的意思是在一个 node 下面生成的子节点是按顺序的，每个子节点都有一个唯一编号，并且这个编号是按顺序自增的。 临时顺序节点再加上 ZK 的监听机制就可以实现分布式锁了，Curator 是一个 ZK 的开源客户端，也提供了分布式锁的实现。

优点：

1. ZK 本身就是集群部署，避免单机故障；
2. 顺序节点所以不用考虑过期时间设置问题；

缺点：

1. 实现较为复杂；
2. 非缓存机制，大量频繁创建删除节点会影响 ZK 集群性能；

基于数据库的实现

基于数据库的分布式锁个人觉得性能不是很好，在高并发的情况下对数据库服务器的压力过大，会影响业务，不建议使用。

基于数据库的分布式锁的实现大致有两种方式，这里的数据库我们以 MySQL 为例。两种方案的实现都需要一个额外的表，并且要有一个唯一索引字段。

1. 阻塞式语句 select xxx for update
2. 非阻塞试 `insert into xxx ; delete from`

第一种方案在实施的时候，需要关闭事务的自动提交，然后执行 SQL 去获得锁，如果获得锁成功，执行下面的业务逻辑，如果这里没有获取到锁，则会阻塞，一直等待。业务执行结束后，手动提交事务。这里如果程序在执行提交事务失败，异常或者服务宕机后，数据库会自动释放锁，从而导致死锁。但是这里有个问题就是如果在高并发的情况下，很多线程都没有获得到锁，都在阻塞等待，这样会导致数据库的服务器压力过大，会影响数据库的服务。这个是要注意的，这也是我不建议的地方，容易出现瓶颈，毕竟没有缓存高效。 第二种方案跟第一种类似，不一样的地方是这里通过第一步向指定的表中插入一条唯一索引的数据，插入成功则表示获得锁，插入失败则未获得到锁，成功获得的锁后就可以执行业务逻辑，在执行完业务逻辑后就可以删除执行的记录。如果插入失败就需要重新触发获取锁的动作。但是这种方案存在的问题是无法设置锁的失效时间，需要其他手段来清理超时数据，而且为了支持可重入，需要将主机和服务的信息一起保存。

优点

1. 容易理解和实现，但是细节要注意；

缺点：

1. 高并发的情况下性能不好，阻塞式的情况下很多链接不释放会拖垮数据库服务；
2. 需要定时清理超时数据，麻烦；
3. 数据库的行锁会因为 MySQL 的查询优化而失效

## 6.Redis分布式锁

redis中使用分布式锁很简单，只要使用setnx指令对某个key上锁就行

当某个key没有被占用的时候，setnx指令会返回1，否则返回0，这就是Redis中分布式锁的使用原理。

还可以在上锁之后使用expire指令给锁设置过期时间。

分布式锁在Redis集群中遇到的麻烦

假设我们在redis的主节点上添加了一把分布式锁，不幸的是主节点挂掉了，而且主节点上的锁还没有同步到 从节点上，如果此时有客户端来请求获得同一把锁，那么它将顺利地获得锁，之前那把锁会被无情地忽视掉，这就是分布式锁在 Redis集群中遇到的麻烦。

Redis的作者为了解决这个问题提出了一个叫Redlock的算法，它的原理是这样的：当上锁的时候，把set指令发送给过半的节点，只要 过半的锁set成功，就认为这次加锁成功；当解锁的时候，会向所有的节点发送del指令。 从这个算法的原理可以看出，由于Redlock需要同时对多个节点进行读写，因此使用Redlock加分布式锁的性能要比单机Redis低很 多。因为主从复制出纰漏的概率极低，所以如果对分布式加锁过程有一定的容错率的话，可以考虑直接使用set指令；如果追求高可 用性，可以考虑使用Redlock算法。

在公司的项目中，虽然Redis是以集群的方式部署的，但还是使用最基本的set指令获取分布式锁，因为这种方式的性能远远高于 Redlock算法，也高于zk，数据库等分布式锁实现方式。

虽然在高性能与低概率的错误中选择了高性能，但项目中还是做了其他工作对错误情况进行兜底的，比如在公司的项目中对主从复制 时的错误情况会抛出异常，然后根据异常会进行一些重试的操作。

## 7.分布式锁

1、在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行

2、高可用的获取锁与释放锁

3、高性能的获取锁与释放锁

4、具备可重入特性（可理解为重新进入，由多于一个任务并发使用，而不必担心数据错误）

5、具备锁失效机制，防止死锁

6、具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败

### 8.分布式锁的实现

基本原理理：⽤用⼀一个状态值表示锁，对锁的占⽤用和释放通过状态值来标识。

Zookeeper

基于zookeeper瞬时有序节点实现的分布式锁。大致思想即为： 每个客户端对某个功能加锁时，在zookeeper上的与该功能对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。

优点：锁安全性高，zk可持久化，且能实时监听获取锁的客户端状态。一旦客户端宕机，则瞬时节点随之消失，zk因而能第一时间释放锁。这也省去了了用分布式缓存实现锁的过程中需要加入超时时间判断的这一逻辑。

缺点：性能开销比较高。因为其需要动态产生、销毁瞬时节点来实现锁功能。所以不太适合直接提供给高并发的场景使用。

实现：可以直接采用zookeeper第三方库curator即可方便地实现分布式锁。 适用场景：对可靠性要求非常高，且并发程度不高的场景下使用。如核心数据的定时全量/增量同步等。

memcached

memcached带有add函数，利用add函数的特性即可实现分布式锁。add和set的区别在于：如果多线程并发set，则每个set都会成功，但最后存储的值以最后的set的线程为准。而add的话则相反，add会添加第一个到达的值，并返回true，后续的添加则都会返回false。利用该点即可很轻松地实现分布式锁。 优点：并发高效 缺点：memcached采用列入LRU置换策略，所以如果内存不够，可能导致缓存中的锁信息丢失。memcached无法持久化，一旦重启，将导致信息丢失。 使用场景：高并发场景。需要 1)加上超时时间避免死锁; 2)提供足够支撑锁服务的内存空间; 3)稳定的集群化管理。

redis

redis分布式锁即可以结合zk分布式锁高度安全和memcached并发场景下效率很好的优点，其实现方式和memcached类似，采用setnx即可实现。需要注意的是，这里的redis也需要设置超时时间。以避免死锁。可以利用jedis客户端实现。

```html
ICacheKey cacheKey = new ConcurrentCacheKey(key, type);
return RedisDao.setnx(cacheKey, "1");
```

数据库死锁机制和解决方案： 1、死锁：死锁是指两个或者两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。 2、处理机制：解决死锁最有用最简单的方法是不要有等待，将任何等待都转化为回滚，并且事务重新开始。但是有可能影响并发性能。 1、超时回滚，innodb_lock_wait_time设置超时时间； 2、wait-for-graph方法：跟超时回滚比起来，这是一种更加主动的死锁检测方式。InnoDB引擎也采用这种方式。

# 分布式限流

### 1.常见的限流算法

计数器

计数器法

限流算法中最简单粗暴的一种算法，例如，某一个接口1分钟内的请求不超过60次，我们可以在开始时设置一个计数器，每次请求时，这个计数器的值加1，如果这个这个计数器的值大于60并且与第一次请求的时间间隔在1分钟之内，那么说明请求过多；如果该请求与第一次请求的时间间隔大于1分钟，并且该计数器的值还在限流范围内，那么重置该计数器。 使用计数器还可以用来限制一定时间内的总并发数，比如数据库连接池、线程池、秒杀的并发数；计数器限流只要一定时间内的总请求数超过设定的阀值则进行限流，是一种简单粗暴的总数量限流，而不是平均速率限流。

这个方法有一个致命问题：临界问题——当遇到恶意请求，在0:59时，瞬间请求100次，并且在1:00请求100次，那么这个用户在1秒内请求了200次，用户可以在重置节点突发请求，而瞬间超过我们设置的速率限制，用户可能通过算法漏洞击垮我们的应用。

这个问题我们可以使用滑动窗口解决。

滑动窗口

一个时间窗口就是1分钟，然后我们将时间窗口进行划分，如上图我们把滑动窗口划分为6格，所以每一格代表10秒，每超过10秒，我们的时间窗口就会向右滑动一格，每一格都有自己独立的计数器，例如：一个请求在0:35到达， 那么0:30到0:39的计数器会+1，那么滑动窗口是怎么解决临界点的问题呢？如上图，0:59到达的100个请求会在灰色区域格子中，而1：00到达的请求会在红色格子中，窗口会向右滑动一格，那么此时间窗口内的总请求数共200个，超过了限定的100，所以此时能够检测出来触发了限流。回头看看计数器算法，会发现，其实计数器算法就是窗口滑动算法，只不过计数器算法没有对时间窗口进行划分，所以是一格。 由此可见，当滑动窗口的格子划分越多，限流的统计就会越精确。

漏桶算法

算法的思路就是水（请求）先进入到漏桶里面，漏桶以恒定的速度流出，当水流的速度过大就会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。

漏桶算法不支持突发流量。

令牌桶算法

1. 限速10r/s，则按照100毫秒固定速率填充令牌，填满了则丢弃令牌
2. 请求，请求的速率可以突发，而且令牌桶允许这种突发
3. 获取令牌
4. 处理请求
5. 令牌不足则拒绝请求

令牌算法有点复杂，桶里存放着令牌token。桶一开始是空的，token以固定的速率r往桶里面填充，直到达到桶的容量，多余的token会被丢弃。每当一个请求过来时，就会尝试着移除一个token，如果没有token，请求无法通过。 令牌桶算法支持突发流量。

### 2.分布式限流

Redis+Lua脚本实现分布式限流思路

```html
local key = KEYS[1] --限流KEY(一秒一个)
local limit = tonumber(ARGV[1]) --限流大小
local current = tonumber(redis.call('get', key) or "0")
if current + 1 > limit then --如果超出限流大小
return 0
else --请求数+1，并设置2秒过期
redis.call("INCRBY", key, "1")
redis.call("expire", key "2")
return 1
end
```

（1）在Lua脚本中，有两个全局变量，用来接收Redis应用端传递的键和其他参数，分别为：KEYS、ARGV； （2）在应用端传递KEYS时是一个数组列表，在Lua脚本中通过索引下标方式获取数组内的值。 （3）在应用端传递ARGV时参数比较灵活，可以是一个或多个独立的参数，但对应到Lua脚本中统一用ARGV这个数组接收，获取方式也是通过数组下标获取。 （4）以上操作是在一个Lua脚本中，又因为我当前使用的是Redis 5.0版本（Redis 6.0支持多线程），执行的请求是单线程的，因此，Redis+Lua的处理方式是线程安全的，并且具有原子性。

接下来，我们可以使用如下Java代码来判断是否需要限流。

```html
//List设置Lua的KEYS[1]
String key = "ip:" + System.currentTimeMillis() / 1000;
List<String> keyList = Lists.newArrayList(key);
//List设置Lua的ARGV[1]
List<String> argvList = Lists.newArrayList(String.valueOf(value));
//调用Lua脚本并执行
List result = stringRedisTemplate.execute(redisScript, keyList, argvList)
```

# 分布式session

浏览器有个 cookie，在⼀段时间内这个 cookie 都存在，然后每次发请求过来都带上⼀个特殊的 jsessionid cookie，就根据这个东西，在服务端可以维护⼀个对应的 session 域，⾥⾯可以放点数据。

### 1.分布式session ，如何保持一致

1、Session粘滞

1、将用户的每次请求都通过某种方法强制分发到某一个Web服务器上，只要这个Web服务器上存储了对应Session数据，就可以实现会话跟踪。 2、优点：使用简单，没有额外开销。 3、缺点：一旦某个Web服务器重启或宕机，相对应的Session数据将会丢失，而且需要依赖负载均衡机制。 4、适用场景：对稳定性要求不是很高的业务情景。

2、Session集中管理

1、在单独的服务器或服务器集群上使用缓存技术，如Redis存储Session数据，集中管理所有的Session，所有的Web服务器都从这个存储介质中存取对应的Session，实现Session共享。 2、优点：可靠性高，减少Web服务器的资源开销。 3、缺点：实现上有些复杂，配置较多。 4、适用场景：Web服务器较多、要求高可用性的情况。 5、可用方案：开源方案Spring Session，也可以自己实现，主要是重写HttpServletRequestWrapper中的getSession方法

3、基于Cookie管理理

1、这种方式每次发起请求的时候都需要将Session数据放到Cookie中传递给服务端。 2、优点：不需要依赖额外外部存储，不需要额外配置。 3、缺点：不安全，易被盗取或篡改；Cookie数量和长度有限制，需要消耗更多网络带宽。 4、适用场景：数据不重要、不敏感且数据量小的情况。 总结 这四种方式，相对来说，Session集中管理更加可靠，使用也是最多的。

# 分布式幂等性

### 1.分布式服务接口的幂等性如何设计（比如不能重复扣款）？

所谓幂等性，就是说一个接口，多次发起同一个请求，你这个接口得保证结果是准确的，比如不能多扣款，不能多插入一条数据，不能将统计值多加了1。

其实保证幂等性主要是三点：

（1）对于每个请求必须有一个唯一的标识，举个例子：订单支付请求，肯定得包含订单id，一个订单id最多支付一次，对吧

（2）每次处理完请求之后，必须有一个记录标识这个请求处理过了，比如说常见的方案是在mysql中记录个状态啥的，比如支付之前记录一条这个订单的支付流水，而且支付流水

（3）每次接收请求需要进行判断之前是否处理过的逻辑处理，比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。

（4）上面只是给大家举个例子，实际运作过程中，你要结合自己的业务来，比如说用redis用orderId作为唯一键。只有成功插入这个支付流水，才可以执行实际的支付扣款。

### 2.保证分布式系统的接口幂等性的几种常见方案

**1、业务表内唯一索引**

好比说电商系统里面，不是说有那个销售出库单表，wms中心

如果你要对创建销售出库单的接口保证幂等性，也就是说人家网络超时，重复调用的时候，保证一个订单只能有一个对应的销售出库单

销售出库单表里面，其实都是有这个unique key唯一索引的，比如说可以针对销售出库单的表的订单id，创建一个唯一索引，你如果接口被重试，同一个订单创建一个销售出库单的话，一定会违反唯一索引，那么此时会报错

保证说你在数据库里，一个订单只能有一个销售出单

常见于插入操作，创建一些关键的数据的时候，而且这个数据在库里只能有一条的时候

**2、业务表内状态机**

修改订单状态，比如说将订单状态修改为待发货的时候

update order set status = “待发货” where status = “待付款” and id = 1，订单的状态其实就变为了“待发货”。假如说id = 1的订单接口重复调用，又要执行一次这个操作的话，就不会生效了，就不会再次修改了

在订单模块里，我们不是用了状态模式，在进行状态流转的时候，其实都会去判断一下的，当前是否处于某个状态，然后才能流转到下一个状态。

**3、基于版本号的更新**

id name age version

1 张三 20 1

如果要调用人家的这个接口，更新他的这个年龄，先得查一下他的版本号是多少

version = 1

调用人家的接口修改他的年龄，要changeAge(1, 21, 1)

在你的接口里为了保证分布式接口的幂等性

update user set age=21, version=version+1 where id=1 and version=1

如果这条SQL执行成功过后

id name age version

1 张三 21 2

如果changeAge(1, 21, 1)，被重复调用了，此时会如何？

update user set age=21, version=version+1 where id=1 and version=1

我们一般不常用，对于接口调用方来说，要多做一些事情，他要先查出来数举的version，调用修改接口的时候，传过去这个version

**4、基于mysql的去重表 / 基于redis的去重**

就是说这个方案是很常见的一个方案

比如说你的接口的入参，参数，是changeAge(1, 21, 1)

将所有的参数拼接成一个字符串，或者是从这些入参里选择一些参数，可以唯一标识这一次请求的一些参数id和version，id和version每次请求都不一样的，应该是可以唯一的标识这一次请求

1_21_1，这样的一个字符串

如果基于mysql，单独搞一个表出来，就一个字段，建一个唯一索引，插入这个1_21_1到表里去。如果这个接口被重复调用的话，1_21_1，再次插入一个表的话，唯一索引会报一个冲突出来，这次插入就会失败

这个方案还是不错的，尤其是并发不是特别高的话，接口被调用的并发不是特别高的话，每秒的并发请求量在1000左右，1000以内的话，用mysql的去重表也没什么问题

但是如果接口调用量很大，并发很高，一秒请求量达到了几十万，选择使用redis，拼接一个串出来，直接set设置到redis里去，如果下一次人家请求再过来了，此时会发现这个key已经存在了，那么这个时候就不能执行了，因为已经出现重复调用了

## 分布式id

### 1、数据库自增主键

1024表，不是依赖每一张表的自增主键，不同的表都从1开始累加id

专门搞一个库，搞一个表，专门用于生成全局唯一id，insert into插入一条数据，他会返回给你一个全局唯一id，然后你把这个id设置给数据，插入分表后的1024张表里去，全局唯一的

优点：超简单，落实起来非常方便，公司有一个统一的库和表，专门用于生成id；或者你自己的系统的库里你专门弄一张表，用来生成id

缺点：单库单表，并发抗不住，一旦达到每秒几千的高并发；不停的在表里插入数据获取id，表数据会越来越多，还得定期清理，很麻烦

适用场景：分库分表是因为数据量大，但是低并发低负载，而且数据库单机有高可用问题，必须上高可用方案，另外是单表数据一直增长也是个问题，一般不会直接投入生产，投入生产环境的时候会用下面说的flickr的数据库唯一id生成方案

### 2、UUID

JDK自带的一个UUID的API就可以生成一个唯一id，字符串，很长

优点：本地生成，没有所谓的并发压力

缺点：太长了！作为主键绝对是不靠谱的！数据库频繁页分裂问题！

适用场景：除数据库主键之外的其他唯一键场景，都适合，生成一个订单编号，或者是别的什么ID，不是数据库的唯一id主键，这个方案一般不考虑在分布式唯一ID生成里，在我们的主题里，其实可以忽略

### 3、Twitter开源的Snowflake方案

核心思想：64个bit位，最高位1个bit是0，41位放时间戳（到毫秒单位，最多使用69年），10位放机器标识（最多把snowflake程序部署在1024台机器上），12位放序号（每毫秒，每台机器，可以顺序生成4096个ID）

64个bit位，通过时间戳+机器id+序号 -> long类型的唯一id

snowflake程序分布式部署在多台机器上，每台机器生成的每个ID，都是这一毫秒、机器id、序号，每台机器每毫秒最多4096个ID，绝对够用了，分布式方案可以抗高并发，大不了加机器，最多1024台机器，纯基于内存生成，性能很高

优点：高性能，高并发，集群化，可伸缩，最多扩展1024台机器，ID绝对够用，高可用

缺点：光是开源算法还不用，还得考虑时钟回拨等一系列问题，如果要解决那堆问题，需要开发很多机制，开发完了还得独立部署，有独立部署和维护的成本

适用场景：中大型公司，有高并发生成唯一ID场景，基于snowflake算法自研，加入时钟回拨解决方案，多机房方案，等等，各种生产方案，有人力去维护，有少数大厂采用了这个方案，可以作为生产级方案，但是需要解决很多问题

### 4、Redis自增机制

核心思想：Redis单线程，绝对有序自增，incrby；集群部署，比如5台机器，那么每台机器的初始值依次为1、2、3、4、5，每台机器的自增步长是5，第1台机器就是1、6、11、16、21，第2台机器就是2、7、12、17、22，以此类推，直到第5台机器就是5、10、15、20、25

优点：不用额外开发，一般公司都提供redis集群，直接用就行，高性能，高并发，集群化，高可用，都可以实现，全局唯一

缺点：客户端需要自己封装，基于Jedis去封装，客户端里需要写死Redis机器数量，每次获取1个ID，都是找到一台机器，然后按步长去incrby，接着返回给系统；而且扩容麻烦，如果5台机器抗不住并发了怎么办？扩容的时候加机器，客户端需要修改代码，或者基于动态感知，这其实也有开发成本，另外扩容的时候，步长就会改变，那之前的ID怎么办？都得重新洗掉，全部从头开始计算，极为麻烦

适用场景：鉴于他的缺点，一般不用redis集群玩自增主键生成；分库分表了，然后每秒在万左右的高并发，但是可预见的不会达到几万以及十万级的并发，那么此时可以用Redis单机去生成自增主键，避免redis集群扩容的步长改变问题；但是还得部署Redis主从同步+哨兵高可用，可是主从同步是异步的，有id重复问题，所以最终生产一般不用

主节点：1 -> 6

从节点：1 -> 6

### 5、时间戳+业务id

时间戳 + 起点编号 + 车牌号，有可能会重复，两个人，在同一毫秒，同一个起点，打车

核心思想：比如打车软件，可以用时间戳+起点编号+车牌号作为一个id，业务组合上是不会有重复的，订单id、订单编号；比如电商订单，可以用时间戳+用户id，一个用户在1毫秒内一般最多就下一个订单，一般不会重复，除非用户基于程序刷单，否则手点的情况下，这个组合id一般没问题，还可以加个下单渠道、第一个商品id等其他业务id组合起来

优点：实现简单，没额外成本，没并发之类的扩容问题

缺点：有的业务场景（比如订单之类的），还可以用这种方案，但是有的业务场景可能根本没法通过业务来组合，而且始终担心有重复问题

适用场景：很多大厂都用这个方案，做订单编号这些，但是分库分表不光是订单，还有什么用户、账号以及各种其他的业务场景，所以部分适用于生产，推荐第一优先级先考虑这个方案

### 6、flickr（雅虎旗下的图片分享平台）公司的方案

```html
CREATE TABLE `uid_sequence` (  
  `id` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default '',  
  PRIMARY KEY  (`id`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;

REPLACE INTO uid_sequence (stub) VALUES ('test');  
SELECT LAST_INSERT_ID();  
```

replace into语法替代insert into，避免表行数过大，一张表就一行数据，然后再select获取这个表的最新id，last_insert_id()函数是connection级别的，就你这个连接的最近insert生成的id，多个客户端之间没影响

当然，其实也可以优化成这样，就是每次你一台机器要申请一个唯一id，你就REPLACE INTO uid_sequence (stub) VALUES ('192.168.31.226')，用你自己机器的ip地址去replace into，那么就你自己机器会有id不停自增，完了用select id from table where stub=机器地址，就可以了

最多如果你要考虑到多线程并发问题，那么就在机器地址后加入线程编号，这样一台机器的不同线程，都是对自己的id在自增

这个方案本质跟第一个方案没区别，唯一优化就是用replace into替代了insert into，避免表数据量过大，缺点也在于数据库并发能力不高，所以适用场景，就是分库分表的时候，低并发，用这个方案生成唯一id，低并发场景下可以用于生产

而且一般会部署数据库高可用方案，两个库设置不同的起始位置和步长，分别是1、3、5，以及2、4、6

### 7、基于flickr方案的高并发优化

有一种变种方案，是基于flickr方案的高并发优化，他核心问题在于每一次生成id都得找数据库，所以这就是并发瓶颈，所以这里可以把数据库优化为号段，而不是id号，什么意思呢？一起来看看

两台数据库，起始offset不同，步长一样，高可用性，先通过其中一台库来执行递增操作，replace into，select获取，客户端很重要

每台机器都引入一个自己封装的客户端，只要一旦服务启动，客户端就直接有一个线程采用flickr方案获取一个id，但是他仅仅代表的是一个号段，什么意思呢？比如说，一个服务启动，通过flickr方案的replace into拿到一个id，假设是1吧

写死，每个号段是10000个id号

此时你的号段可以配置为一个号段是10000个id号，那么此时你这个号段的起始id就是1 * 10000，然后可以把起始id设置到AtomicLong里去，还可以用volatile保存一下号段的最大id，也就是（n + 1） * 10000，就是2 * 10000，20000

volatile AtomicLong idGenerator = new AtomicLong(10000)

volatile long maxId = 20000

所以这个号段的id就是[10000, 20000，20000是不包含在内的

接着服务里如果要获取唯一id，直接找你封装的客户端，IdGenerator.next()，每次拿一个id，就是AtomicLong.incrementAndGet()，直接原子递增，这样你大部分的id获取，都是在内存里通过号段内递增实现的

高并发问题，解决了！！数据库仅仅用于维护号段罢了

高可用 -> 两台数据库（不同起始offset，相同步长）+ 故障自动转移

表数据量不会太大

支持多业务

高并发 + 高性能 -> 不需要伸缩和扩容

如果拿到了号段里最大id，此时对获取id的请求得阻塞住，只要拿到的id大于等于了最大id，请求全部自己陷入阻塞，比如大家都去while循环阻塞，过一会儿再次获取id，跟最大id比较

```html
volatile boolean needRefresh = false;

while(next() >= maxId) {
    needRefresh = true;
    sleep(10ms)
}

15

AtomicLong(150000)
maxId = 160000
```

发号器客户端的线程，定时轮询，needRefresh = true，此时一旦发现这个问题，此时就重新利用flickr方案获取一个新的号段，再次设置AtomicLong里的初始id以及更新最大id，在这个过程中别的任何一个线程来获取id都会发现AtomicLong自增值比最大id是大的

即使是发号器客户端线程，刚刚设置了AtomicLong的值，然后还没设置volatile的最大id值，此时别的线程在while循环过程中获取了id，AotmicLong自增值一定大于之前的最大id值，也会继续陷入阻塞的

只有 当发号器客户端线程更新了volatile最大id值之后，其他线程才会在while循环之后，发现AtomicLong自增值是小于最大id值的，此时就可以继续工作了，这种情况通常是很少的，所以大部分情况下，各个服务都是基于本地的号段在内存里获取id，而且全局上还是唯一的，没有高并发问题，数据库的并发也是很低的

这个方案的唯一缺点就是，每次重启服务，就会浪费一个号段里还没自增到的大量id，重启后又是新的号段了，但是如果要优化，可以在spring销毁事件里，发号器内部设置一个volatile标识，不允许获取id了，接着 把AtomicLong的值持久化到本地磁盘，下次服务重启后直接从本地磁盘里读取，就不会浪费了

高可用 -> 两台数据库（不同起始offset，相同步长）+ 故障自动转移

表数据量不会太大

支持多业务

高并发 + 高性能 -> 不需要伸缩和扩容

号段自动更新 + 号段本地磁盘持久化

其实这个优化以后的方案，就可以投入生产了，确实也有个别大厂是这么做的，也运行的很好。如果一定要说这个方案有什么弊端，那就是，归根结底，还是有一个数据库这么个外部依赖，其实如果方案真做好了，你还得考虑数据库的高可用方案这些东西，就是牵扯到了外部依赖，就容易做的很重

另外一个问题，就是对于这个方案，你还得去做步长的配置，那么到底允许多长的步长呢？是否允许用户自己配置呢？如果不允许，你固定一个步长，那个步长会不会在一些特殊高并发场景下，比如你1000作为步长，1000个号瞬间被秒光，一个服务每秒都得请求一次数据库获取新的号段，此时你有上千个服务实例，数据库不还是抗不住？

所以，这个方案适合一些没有特殊超高并发的场景，而且扩展性和灵活性不是很强，总是让人担心他的号段步长会出一些问题，但是在一些普通场景下，其实一般可能也没什么问题，所以有普通高并发场景的生产环境，还是可用的

基于数据库的方案就是flickr方案以及flickr高并发优化方案，但是没有snowflake生产级方案那么具备普适性，snowflake方案不涉及什么号段问题，也不会额外依赖数据库，不需要考虑数据库高可用之类的，他自己就是peer-to-peer的一个集群架构，随时可以扩容

时间戳+业务id，相当好用，推荐第一选择是他，能用时间戳+业务id的，就别搞分布式id生成，如果不行的，再考虑flickr方案或者snowflake方案

### 8.Snowflake生产方案：基于ZK来维护集群机器ID

flickr公布的基于数据库的一个方案，以及他的一个高并发变种方案（阿里开源了一个数据库中间件，TDDL，唯一ID生成方案，思想，号段思想），始终还是强依赖数据库去生成ID的，太重了

核心思想：64个bit位，最高位1个bit是0，41位放时间戳（到毫秒单位，最多使用69年），10位放机器标识（最多把snowflake程序部署在1024台机器上），12位放序号（每毫秒，每台机器，可以顺序生成4096个ID）

64位的long类型的ID里，就会包含上机房ID的概念，一个机房一台机器的每一毫秒可以生成4096个唯一ID

5个bit位放机房ID，5个bit位放机器ID

机器id从哪儿来？少量的机器可以硬编码直接在磁盘文件里写，但是这样非常的不灵活，意味着扩容缩容，都有很多手工成本

所以这块可以采用zk的持久化顺序节点来实现，每台机器启动都去zk指定目录下创建持久化的顺序节点，拿回来自己的顺序号，就是自己的机器id了，直接写入本地磁盘文件，下次就直接用了，不需要每次都访问zk，这就完美解决了，扩容的时候他会自动从zk里获取到自己的顺序号作为机器id

集群部署的注册、心跳与健康检查

两套方案，第一种，用Nginx负载均衡，服务可以跟nginx做心跳，请求都到nginx去，暴露出去的是http接口，但是不太喜欢这种；第二种，基于微服务架构，比如eureka、nacos，都可以，做个服务注册，保持心跳，然后调用的人引入依赖，直接服务发现，定时刷新服务列表，故障自动感知，接着请求就可以了

如果要做多机房，启动的时候，得zk的指定机房下去创建顺序节点获取序号，需要给每个机房里的机器都维护一个机房id，写死也是没问题的，一般给公司没几个机房，然后10个bit位的机器ID，拆分一下，5个bit位给机房ID，5个bit位给机器ID，这就可以了

阶段一，工程结构，maven profile的概念，多机房部署，针对prod profile，可以做两个，双机房部署的，机房A的prod profile，机房B的prod profile，不同的机房的prod profile的配置文件里会有一个自定义的配置，机房ID

然后不同机房一般都会部署独立的服务注册中心，你不同机房的业务系统都会访问机房内的snowflake集群，有机房ID作为标识，保证ID不会重复

### 9.Snowflake生产方案：时钟回拨问题解决思路

核心思想：64个bit位，最高位1个bit是0，41位放时间戳（到毫秒单位，最多使用69年），10位放机器标识（最多把snowflake程序部署在1024台机器上），12位放序号（每毫秒，每台机器，可以顺序生成4096个ID）

ID里必须包含时间戳，可是有个问题，那是依赖机器时间的，机器是有一个时钟回拨问题的，就是可能机器时间会往回拨，比如说假设你要是在做时钟同步，让每台服务器都跟一个时钟服务器进行时钟同步，那么就可能会出现时钟回拨，

此时肯呢个会出现重复时间，重复时间之后，就绝对有可能会出现重复ID

这实际上也是snowflake方案最大的生产问题

第一种办法，就是关闭时钟同步，避免产生时钟同步问题，不过这个不太现实，因为强依赖时间的系统，一般都得做时钟同步，避免时间严重错误，在虚拟机上部署一些东西，玩儿虚拟机，休眠，再次恢复之后往往虚拟机里的时间和宿主机的时间是不同步的

导致一些大数据的分布式系统会崩溃掉，节点之间通信会依赖时间戳进行比对，心跳过慢，就会导致节点挂掉

第二种办法，记录下来上一次生成ID的时间，如果发现本次生成ID的时候，时间戳小于上次的时间戳，说明时钟回拨了，此时就这个时间内不允许生成ID，一直等，等待到当前时间追上上一次生成时间，问题在于，万一回拨的时间太多了呢？可能要等很久，影响了系统的可用性，所以也不是特别好的办法

内存里可以存上一次生成唯一ID的时间戳，时钟回拨了，把当前时间戳会回拨到上次时间戳 之前，请求过来，要生成唯一ID，你不要直接就返回一个ID给他，你先做一个比较，如果你发现当前时间戳跟上一次生成唯一ID的时间戳想比，比他小

判定，时钟回拨，只要你生成ID，就有可能会发生ID的重复

可用性这么差的话，人家业务服务万一此时是要生成一个账单数据，申请一个ID，此时你好不容易等待了几百毫秒之后，你还告诉他你内部异常，没法获取到唯一ID，反复的重试，你会影响他的业务服务的运行

第三种办法，针对第二种办法的优化，如果发现时钟回拨太狠了，比如超过了1分钟，此时直接就报警，同时不再对外提供服务，把自己从集群里摘了，比如你要是基于微服务注册中心进行注册的，就得主动做一个下线

当你发现当前时间戳比上一次生成ID的时间戳要小，发现时钟回拨了，判断一下，回拨了多少毫秒/秒，比如说回拨时间在500ms以内，此时可以hang住请求，等待500ms，等到500ms之后，当前时间戳比上一次生成ID的时间戳要大了

此时就可以正常生成唯一ID返回给业务方了，对于业务方而言，仅仅是在个别少数的时钟回拨的情况之下，请求平时只要50ms，500ms，还在接受范围之内，所以说还是可以的，只不过请求慢了一些

如果你要是发现你当前时间戳和上一次生成唯一ID的时间戳想比，你一比较，就发现超过了500ms了，超过了500ms了，但是在5s之内，此时你可以返回一个异常状态+异常持续时间给客户端，不要说有问题，可以通知他自行进行重试

重试机制，最好不要让业务方自己去做，你完全可以去封装一个你的唯一ID生成服务的客户端，基于RPC请求你的接口，但是你在自己的客户端里封装一个自动重试的机制，他一旦发现某台服务器返回的响应说自己短时间内没法提供服务，他自动就去请求其他机器上的服务获取唯一ID了

如果要解决时钟回拨，一般是第二种和第三种结合在一起来用，但是被动等待甚至主动下线，总是影响系统可用性的，都不是特别好

服务端的时钟回拨检测机制 + 客户端自己封装

1s以内：阻塞请求等待，客户端的超时时间，应该也是1s，暴露1s内每一毫秒生成过的唯一ID最大的序号，根据当前时间戳的毫秒，定位到之前生成过ID的这一毫秒的最大ID序号，此时继续生成ID，直接在之前生成过的这一毫秒的最大ID序号基础上递增就可以了，优化之后，就可以保证不需要阻塞等待

1s~10s之间：返回异常码和异常持续时间，客户端在指定时间内不请求这台机器

10s以上：返回故障码，请求服务注册中心让自己下线，客户端收到故障码之后，就直接把这个机器从服务机器列表里剔除掉，不请求他了，后续等到那台机器部署的ID服务他发现自己的时间可能过了几秒钟，缓过来了，恢复了，可用了，就可以再次进行服务注册，你客户端刷新服务注册列表的时候，就会发现他，此时可以再次去请求他

第四种办法，要在内存里维护最近几秒内生成的ID值，一般时钟回拨都是几十毫秒到几百毫秒，很少会超过秒的，所以保存最近几秒的就行了，然后如果发生了时钟回拨，此时就看看回拨到了哪一毫秒，因为时间戳是毫秒级的，接着就看那一毫秒

从那一毫秒生产过的ID序号往后继续生成就可以了，后续每一毫秒都是依次类推，这样就可以完美避免重复问题，还不用等待

但是这里也得做一个兜底机制，就是比如你保留最近10s内每一毫秒生成的ID，那么万一时钟回拨碰巧超过了10s呢？此时这种概率很低，你可以跟二三两个方案结合，设置几个阈值，比如说，你保留最近10s的ID，回拨10s内都可以保证不重复，不停顿；如果超过10s，在60s内，可以有一个等待的过程，让他时间前进到你之前保留过的10s范围内去；如果回拨超过了60s，直接下线

上一次生成唯一ID的时间戳也没了，最近1s内每一毫秒的最大ID序号也没了，重启之后，出现了时间回拨，发现不了时间回拨问题，其次也没有办法继续按照之前的思路去生成不重复的唯一ID了

# 分布式算法

### 1.一致性Hash算法

一致性哈希算法(Consistent Hashing Algorithm)是一种分布式算法，常用于负载均衡。Memcached client 也选择这种算法，解决将key-value 均匀分配到众多Memcached server 上的问题。它可以取代传统的取模操作，解决了取模操作无法应对增删Memcached Server 的问题(增删server 会导致同一个key,在get 操作时分配不到数据真正存储的server，命中率会急剧下降)。

一致性 Hash 特性

- 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。
- 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。容易看到，上面的简单求余算法hash(object)%N 难以满足单调性要求。
- 平滑性(Smoothness)：平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。

一致性Hash的原理

一致性Hash 的原理是将整个Hash 空间虚拟成一个0 ～ 232-1 的Hash 环，然后将数据和服务器分别映射到Hash 环上来实现数据在各个服务器上的Hash 分布。。

具体过程如下

( 1 ）构建环形Hash空间：一致性Hash 将整个Has h 空间组成一个0 ～ 232-1 的虚拟圆环。

( 2 ）将服务器节点映射到Hash环：使用Hash函数将服务器映射到虚拟的Hash环（空间）上，一般可以使用服务器节点机器的IP地址或者机器名作为Hash函数的计算值。

( 3 ）将数据映射到Hash环：使用相同的Hash函数计算需要存储的数据的Hash值，并将数据映射到Hash环上。

( 4 ）将对象映射到服务节点：首先找到对象的Hash值在Hash环上的位置；然后从该位置开始沿Hash环顺时针寻找，遇到的第一台服务器就是该对象的存储节点服务器；最后将该对象映射到该服务器上。

移除 cache：考虑假设 cache B 挂掉了，根据上面讲到的映射方法，这时受影响的将仅是那些沿 cache B 逆时针遍历直到下一个 cache （ cache C ）之间的对象。

添加 cache：再考虑添加一台新的 cache D 的情况，这时受影响的将仅是那些沿 cacheD 逆时针遍历直到下一个 cache 之间的对象，将这些对象重新映射到 cache D 上即可。

一致性Hash的节点变动

传统的通过计算Hash值然后除以服务器个数求余的方法带来的最大问题在于不能满足单调性，即当Server有变动（增加节点或移除节点）时，整个系统的Hash值都会失效（因为服务器个数发生了变化，即被除数发生了变化），从而需要重新计算Hash值，并进行Hash映射和数据分布。而一致性Hash在服务器发生变动时，由于对象的数据分布只与顺时针方向的下一个服务器相关，因此只会影响变化节点的下一个节点的数据分布。

( 1 ）移除节点：假设其中某台服务器宕机，受影响的对象仅仅是那些原本映射到服务器上的对象，根据一致性Hash顺时针数据映射的原则，只需要将原本映射到该服务器上的对象重新映射到下一个正常的服务器即可。

( 2 ）添加节点：在添加节点时，受影响的数据将仅是那些沿着逆时针方向从新加入的节点到上一个服务器之间的对象，将这些对象重新映射到新加入的节点即可。

虚拟节点（down机多节点托管）

一致Hash算法不能保证数据的绝对平衡，在集群对象数据较少的情况下，对象并不能被均匀地映射到各个Server上。为了解决数据分布不均的问题，一致性Hash引入了“虚拟节点”的概念。虚拟节点（VirtualNode）是实际节点在Hash空间的副本，一个实际节点对应若干虚拟节点，对应个数也被称为副本个数，虚拟节点在Hash空间中以Hash值排列。

在引入虚拟节点后，映射关系就从对象到节点转换为从对象到虚拟节点。

一致性Hash的特点

( 1 ）平衡性（Balance）：平衡性指Hash后的结果能够将数据尽可能平均地分配到每一个节点上。

( 2 ）单调性（Monotonicity）：单调性指如果有新的节点加入，不会影响其他节点上原有数据的分配。简单求余算法hash(object)%N难以满足单调性的要求。

( 3 ）平滑性（Smoothness）：平滑性指节点数的平滑改变和缓存对象的平滑改变保持步调一致。

### 2.Paxos

Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。zookeeper 使用的zab 算法是该算法的一个实现。 在Paxos 算法中，有三种角色：Proposer，Acceptor，Learners

Paxos 三种角色:Proposer,Acceptor,Learners

Proposer

只要Proposer 发的提案被半数以上Acceptor 接受，Proposer 就认为该提案里的value 被选定了。

Acceptor

只要Acceptor 接受了某个提案，Acceptor 就认为该提案里的value 被选定了。

Learner

Acceptor 告诉Learner 哪个value 被选定，Learner 就认为那个value 被选定。

Paxos 算法

具体分为两个阶段，具体如下：

阶段一（准leader 确定）

(a) Proposer 选择一个提案编号N，然后向半数以上的Acceptor 发送编号为N的Prepare 请求。 (b) 如果一个Acceptor 收到一个编号为N 的Prepare 请求，且N 大于该Acceptor 已经响应过的所有Prepare 请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor 承诺不再接受任何编号小于N 的提案。

阶段二（leader 确认）

(a) 如果Proposer 收到半数以上Acceptor 对其发出的编号为N 的Prepare 请求的响应，那么它就会发送一个针对[N,V]提案的Accept 请求给半数以上的Acceptor。注意：V 就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V 就由Proposer 自己决定。 (b) 如果Acceptor 收到一个针对编号为N 的提案的Accept 请求，只要该Acceptor 没有对编号大于N 的Prepare 请求做出过响应，它就接受该提案。

### 3.Raft

与Paxos 不同Raft 强调的是易懂（Understandability），Raft 和Paxos 一样只要保证n/2+1 节点正常就能够提供服务；raft 把算法流程分为三个子问题：选举（Leader election）、日志复制（Log replication）、安全性（Safety）三个子问题。

角色

Raft 把集群中的节点分为三种状态：Leader、 Follower 、Candidate，理所当然每种状态负责的任务也是不一样的，Raft 运行时提供服务的时候只存在Leader 与Follower 两种状态；

Leader（领导者-日志管理）

负责日志的同步管理，处理来自客户端的请求，与Follower 保持这heartBeat 的联系；

Follower（追随者-日志同步）

刚启动时所有节点为Follower 状态，响应Leader 的日志同步请求，响应Candidate 的请求，把请求到Follower 的事务转发给Leader；

Candidate（候选者-负责投票）

负责选举投票，Raft 刚启动时由一个节点从Follower 转为Candidate 发起选举，选举出Leader 后从Candidate 转为Leader 状态；

Term（任期）

在Raft 中使用了一个可以理解为周期（第几届、任期）的概念，用Term 作为一个周期，每个Term 都是一个连续递增的编号，每一轮选举都是一个Term 周期，在一个Term 中只能产生一个Leader；当某节点收到的请求中Term 比当前Term 小时则拒绝该请求。

选举（Election）

选举定时器

Raft 的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为Follower 某个节点定时器触发选举后Term 递增，状态由Follower 转为Candidate，向其他节点发起RequestVote RPC 请求，这时候有三种可能的情况发生： 1：该RequestVote 请求接收到n/2+1（过半数）个节点的投票，从Candidate 转为Leader，向其他节点发送heartBeat 以保持Leader 的正常运转。 2：在此期间如果收到其他节点发送过来的AppendEntries RPC 请求，如该节点的Term 大则当前节点转为Follower，否则保持Candidate 拒绝该请求。 3：Election timeout 发生则Term 递增，重新发起选举

在一个Term 期间每个节点只能投票一次，所以当有多个Candidate 存在时就会出现每个Candidate 发起的选举都存在接收到的投票数都不过半的问题，这时每个Candidate 都将Term递增、重启定时器并重新发起选举，由于每个节点中定时器的时间都是随机的，所以就不会多次存在有多个Candidate 同时发起投票的问题。 在Raft 中当接收到客户端的日志（事务请求）后先把该日志追加到本地的Log 中，然后通过heartbeat 把该Entry 同步给其他Follower，Follower 接收到日志后记录日志然后向Leader 发送ACK，当Leader 收到大多数（n/2+1）Follower 的ACK 信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个heartbeat 中Leader 将通知所有的Follower 将该日志存储在自己的本地磁盘中。

### 4.raft 协议和 zab 协议区别

相同点

- 采用quorum 来确定整个系统的一致性,这个quorum 一般实现是集群中半数以上的服务器,
- zookeeper 里还提供了带权重的quorum 实现.
- 都由leader 来发起写操作.
- 都采用心跳检测存活性
- leader election 都采用先到先得的投票方式

不同点

- zab 用的是epoch 和count 的组合来唯一表示一个值, 而raft 用的是term 和index
- zab 的follower 在投票给一个leader 之前必须和leader 的日志达成一致,而raft 的follower则简单地说是谁的term 高就投票给谁
- raft 协议的心跳是从leader 到follower, 而zab 协议则相反
- raft 协议数据只有单向地从leader 到follower(成为leader 的条件之一就是拥有最新的log),而zab 协议在discovery 阶段, 一个prospective leader 需要将自己的log 更新为quorum 里面最新的log,然后才好在synchronization 阶段将quorum 里的其他机器的log 都同步到一致.

# 缓存

## 一、缓存特征

### 命中率

当某个请求能够通过访问缓存而得到响应时，称为缓存命中。

缓存命中率越高，缓存的利用率也就越高。

### 最大空间

缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。

当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。

### 淘汰策略

- FIFO（First In First Out）：先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。
- LRU（Least Recently Used）：最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。
- LFU（Least Frequently Used）：最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。

## 二、缓存位置

### 浏览器

当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。

### ISP

网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。

### 反向代理

反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。

### 本地缓存

使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。

### 分布式缓存

使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。

相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。

### 数据库缓存

MySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。

### Java 内部的缓存

Java 为了优化空间，提高字符串、基本数据类型包装类的创建效率，设计了字符串常量池及 Byte、Short、Character、Integer、Long、Boolean 这六种包装类缓冲池。

### CPU 多级缓存

CPU 为了解决运算速度与主存 IO 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。

## 三、CDN

内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。

CDN 主要有以下优点：

- 更快地将数据分发给用户；
- 通过部署多台服务器，从而提高系统整体的带宽性能；
- 多台服务器可以看成是一种冗余机制，从而具有高可用性。

## 四、缓存问题

### 缓存穿透

指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。

解决方案：

- 对这些不存在的数据缓存一个空数据；
- 对这类请求进行过滤。

### 缓存雪崩

指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。

在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。

解决方案：

- 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现；
- 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。
- 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。

### 缓存一致性

缓存一致性要求数据更新的同时缓存数据也能够实时更新。

解决方案：

- 在数据更新的同时立即去更新缓存；
- 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。

要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。

### 缓存 “无底洞” 现象

指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。

产生原因：缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。

解决方案：

- 优化批量数据操作命令；
- 减少网络通信次数；
- 降低接入成本，使用长连接 / 连接池，NIO 等。

## 五、数据分布

### 哈希分布

哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。

传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。

### 顺序分布

将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如 User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，...，6001 ~ 7000。

顺序分布相比于哈希分布的主要优点如下：

- 能保持数据原有的顺序；
- 并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。

## 六、一致性哈希

Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。

### 基本原理

将哈希空间 [0, 2n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。

一致性哈希在增加或者删除节点时只会影响到哈希环中相邻的节点，例如下图中新增节点 X，只需要将它前一个节点 C 上的数据重新进行分布即可，对于节点 A、B、D 都没有影响。

### 虚拟节点

上面描述的一致性哈希存在数据分布不均匀的问题，节点存储的数据量有可能会存在很大的不同。

数据不均匀主要是因为节点在哈希环上分布的不均匀，这种情况在节点数量很少的情况下尤其明显。

解决方式是通过增加虚拟节点，然后将虚拟节点映射到真实节点上。虚拟节点的数量比真实节点来得多，那么虚拟节点在哈希环上分布的均匀性就会比原来的真实节点好，从而使得数据分布也更加均匀。

## 七、LRU

以下是基于 双向链表 + HashMap 的 LRU 算法实现，对算法的解释如下：

- 访问某个节点时，将其从原来的位置删除，并重新插入到链表头部。这样就能保证链表尾部存储的就是最近最久未使用的节点，当节点数量大于缓存最大空间时就淘汰链表尾部的节点。
- 为了使删除操作时间复杂度为 O(1)，就不能采用遍历的方式找到某个节点。HashMap 存储着 Key 到节点的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从双向队列中删除。
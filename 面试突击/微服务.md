# 微服务

## 1.技术栈

### 微服务开发

作用：快速开发服务。

- Spring
- Spring MVC
- Spring Boot

[Spring](https://spring.io/) 目前是 JavaWeb 开发人员必不可少的一个框架，SpringBoot 简化了 Spring 开发的配置目前也是业内主流开发框架。

### 微服务注册发现

作用：发现服务，注册服务，集中管理服务。

Eureka

- Eureka Server : 提供服务注册服务, 各个节点启动后，会在 Eureka Server 中进行注册。
- Eureka Client : 简化与 Eureka Server 的交互操作。

Zookeeper

[Zookeeper](https://github.com/apache/zookeeper) 是一个集中的服务, 用于维护配置信息、命名、提供分布式同步和提供组服务。

Zookeeper 和 Eureka 区别

Zookeeper 保证 CP，Eureka 保证 AP：

- C：数据一致性；
- A：服务可用性；
- P：服务对网络分区故障的容错性，这三个特性在任何分布式系统中不能同时满足，最多同时满足两个。

### 微服务配置管理

作用：统一管理一个或多个服务的配置信息, 集中管理。

[Disconf](https://github.com/knightliao/disconf)

Distributed Configuration Management Platform(分布式配置管理平台) , 它是专注于各种分布式系统配置管理 的通用组件/通用平台, 提供统一的配置管理服务, 是一套完整的基于 zookeeper 的分布式配置统一解决方案。

[SpringCloudConfig](https://github.com/spring-cloud/spring-cloud-config)

[Apollo](https://github.com/ctripcorp/apollo)

Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，用于微服务配置管理场景。

### 权限认证

作用：根据系统设置的安全规则或者安全策略, 用户可以访问而且只能访问自己被授权的资源，不多不少。

[Spring Security](https://spring.io/projects/spring-security)

Apache Shiro

### 批处理

作用: 批量处理同类型数据或事物

[Spring Batch](https://spring.io/projects/spring-batch)

### 定时任务

> 作用: 定时做什么。

Quartz

### 微服务调用 (协议)

> 通讯协议

Rest

- 通过 HTTP/HTTPS 发送 Rest 请求进行数据交互

RPC

- Remote Procedure Call
- 它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC 不依赖于具体的网络传输协议，tcp、udp 等都可以。

[gRPC](https://www.grpc.io/)

> A high-performance, open-source universal RPC framework

所谓 RPC(remote procedure call 远程过程调用) 框架实际是提供了一套机制，使得应用程序之间可以进行通信，而且也遵从 server/client 模型。使用的时候客户端调用 server 端提供的接口就像是调用本地的函数一样。

RMI

- Remote Method Invocation
- 纯 Java 调用

### 服务接口调用

> 作用：多个服务之间的通讯

[Feign(HTTP)](https://github.com/OpenFeign/feign)

Spring Cloud Netflix 的微服务都是以 HTTP 接口的形式暴露的，所以可以用 Apache 的 HttpClient 或 Spring 的 RestTemplate 去调用，而 Feign 是一个使用起来更加方便的 HTTP 客戶端，使用起来就像是调用自身工程的方法，而感觉不到是调用远程方法。

### 服务熔断

> 作用: 当请求到达一定阈值时不让请求继续.

[Hystrix](https://github.com/Netflix/Hystrix)

[Sentinel](https://github.com/alibaba/Sentinel)

### 服务的负载均衡

> 作用：降低服务压力, 增加吞吐量

[Ribbon](https://github.com/Netflix/ribbon)

> Spring Cloud Ribbon 是一个基于 HTTP 和 TCP 的客户端负载均衡工具, 它基于 Netflix Ribbon 实现

[Nginx](https://github.com/nginx/nginx)

Nginx (engine x) 是一个高性能的 HTTP 和反向代理 web 服务器, 同时也提供了 IMAP/POP3/SMTP 服务

Nginx 与 Ribbon 区别

Nginx 属于服务端负载均衡，Ribbon 属于客户端负载均衡。Nginx 作用与 Tomcat，Ribbon 作用与各个服务之间的调用 (RPC)。

### 消息队列

> 作用: 解耦业务, 异步化处理数据

[Kafka](http://kafka.apache.org/)

[RabbitMQ](https://www.rabbitmq.com/)

[RocketMQ](http://rocketmq.apache.org/)

activeMQ

### 日志采集 (elk)

> 作用: 收集各服务日志提供日志分析、用户画像等

[Elasticsearch](https://github.com/elastic/elasticsearch)

[Logstash](https://github.com/elastic/logstash)

Kibana

### API 网关

> 作用: 外部请求通过 API 网关进行拦截处理, 再转发到真正的服务

[Zuul](https://github.com/Netflix/zuul)

> Zuul is a gateway service that provides dynamic routing, monitoring, resiliency, security, and more.

### 服务监控

> 作用: 以可视化或非可视化的形式展示出各个服务的运行情况 (CPU、内存、访问量等)

[Zabbix](https://github.com/jjmartres/Zabbix)

[Nagios](https://www.nagios.org/)

[Metrics](https://metrics.dropwizard.io/)

### 服务链路追踪

> 作用: 明确服务之间的调用关系

[Zipkin](https://github.com/openzipkin/zipkin)

Brave

数据存储

> 作用: 存储数据

### 关系型数据库

[MySql](https://www.mysql.com/)

[Oracle](https://www.oracle.com/index.html)

[MsSQL](https://docs.microsoft.com/zh-cn/sql/?view=sql-server-ver15)

[PostgreSql](https://www.postgresql.org/)

非关系型数据库

[Mongodb](https://www.mongodb.com/)

Elasticsearch

### 缓存

> 作用: 存储数据

[redis](https://redis.io/)

### 分库分表

> 作用: 数据库分库分表方案.

[ShardingSphere](http://shardingsphere.apache.org/)

[Mycat](http://www.mycat.io/)

### 服务部署

> 作用: 将项目快速部署、上线、持续集成.

[Docker](http://www.docker.com/)

[Jenkins](https://jenkins.io/zh/)

[Kubernetes(K8s)](https://kubernetes.io/)

Mesos

## 2.微服务治理策略

服务的注册和发现

解决问题：集中管理服务

解决方法：

- Eureka
- Zookeeper

负载均衡

解决问题：降低服务器硬件压力

解决方法：

- Nginx
- Ribbon

通讯

解决问题：各个服务之间的沟通桥梁

解决方法：

- REST（同步）
- RPC（同步）
- MQ（异步）

配置管理

解决问题：随着服务的增加配置也在增加，如何管理各个服务的配置。

解决方法：

- Nacos
- Spring Cloud Config
- Apollo

容错和服务降级

解决问题：在微服务当中，一个请求经常会涉及到调用几个服务，如果其中某个服务不可以，没有做服务容错的话，极有可能会造成一连串的服务不可用，这就是雪崩效应。

解决方法：

- Hystrix

服务依赖关系

解决问题：多个服务之间来回依赖，启动关系的不明确。

解决方法：应用分层。

服务文档

解决问题：降低沟通成本

解决方法：

- Swagger
- Java doc

服务安全问题

解决问题：敏感数据的安全性

解决方法：

- Oauth
- Shiro
- Spring Security

流量控制

解决问题：避免一个服务上的流量过大拖垮整个服务体系

解决方法：

- Hystrix

自动化测试

解决问题：提前预知异常，确定服务是否可用

解决方法：

- junit

服务上线，下线的流程

解决问题：避免服务随意的上线下线

解决方法：新服务上线需要经过管理人员审核，服务下线需要告知各个调用方进行修改，直到没有调用该服务才可以进行下线。

兼容性

解决问题：服务开发持续进行如何做到兼容。

解决方法：通过版本号的形式进行管理，修改完成进行回归测试。

服务编排

解决问题：解决服务依赖问题的一种方式

解决方法：

- Docker
- K8s

资源调度

解决问题：每个服务的资源占用量不同，如何分配

解决方法：

- JVM 隔离
- Classload 隔离
- 硬件隔离

容量规划

解决问题：随着时间增长，调用逐步增加，什么时候追加机器。

解决方法：统计每日调用量和响应时间，根据机器情况设置阈值，超过阈值就可以追加机器。

## 3.微服务的优点缺点?说下开发项目中遇到的坑?

优点: 1.每个服务直接足够内聚，代码容易理解 2.开发效率高，一个服务只做一件事，适合小团队开发 3.松耦合，有功能意义的服务。 4.可以用不同语言开发，面向接口编程。 5.易于第三方集成 6.微服务只是业务逻辑的代码，不会和HTML,CSS或其他界面结合. 7.可以灵活搭配，连接公共库/连接独立库 缺点: 1.分布式系统的责任性 2.多服务运维难度加大。 3.系统部署依赖，服务间通信成本，数据一致性，系统集成测试，性能监控。

## 4.微服务之间是如何独立通讯的?

1.远程调用，比如feign调用，直接通过远程过程调用来访问别的service。 2.消息中间件

## 5.微服务架构有哪些优势？

􀀀 独立开发 – 所有微服务都可以根据各自的功能轻松开发 􀀀 独立部署 – 基于其服务，可以在任何应用程序中单独部署它们 􀀀 故障隔离 – 即使应用程序的一项服务不起作用，系统仍可继续运行 􀀀 混合技术堆栈 – 可以使用不同的语言和技术来构建同一应用程序的不同服务 􀀀 粒度缩放 – 单个组件可根据需要进行缩放，无需将所有组件缩放在一起

## 6.微服务有哪些特点？

􀀀 解耦 – 系统内的服务很大程度上是分离的。因此，整个应用程序可以轻松构建，更改和扩展 􀀀 组件化 – 微服务被视为可以轻松更换和升级的独立组件 􀀀 业务能力 – 微服务非常简单，专注于单一功能 􀀀 自治 – 开发人员和团队可以彼此独立工作，从而提高速度 􀀀 持续交付 – 通过软件创建，测试和批准的系统自动化，允许频繁发布软件 􀀀 责任 – 微服务不关注应用程序作为项目。相反，他们将应用程序视为他们负责的产品 􀀀 分散治理 – 重点是使用正确的工具来做正确的工作。这意味着没有标准化模式或任何技术模式。开发人员可以自由选择最有用的工具来解决他们的问题 􀀀 敏捷 – 微服务支持敏捷开发。任何新功能都可以快速开发并再次丢弃

## 7.微服务架构如何运作？

􀀀 客户端 – 来自不同设备的不同用户发送请求。 􀀀 身份提供商 – 验证用户或客户身份并颁发安全令牌。 􀀀 API 网关 – 处理客户端请求。 􀀀 静态内容 – 容纳系统的所有内容。 􀀀 管理 – 在节点上平衡服务并识别故障。 􀀀 服务发现 – 查找微服务之间通信路径的指南。 􀀀 内容交付网络 – 代理服务器及其数据中心的分布式网络。 􀀀 远程服务 – 启用驻留在 IT 设备网络上的远程访问信息。

## 8.在使用微服务架构时，您面临哪些挑战？

􀀀 自动化组件：难以自动化，因为有许多较小的组件。因此，对于每个组件，我们必须遵循 Build，Deploy 和 Monitor 的各个阶段。 􀀀 易感性：将大量组件维护在一起变得难以部署，维护，监控和识别问题。它需要在所有组件周围具有很好的感知能力。 􀀀 配置管理：有时在各种环境中维护组件的配置变得困难。 􀀀 调试：很难找到错误的每一项服务。维护集中式日志记录和仪表板以调试问题至关重要。

## 9.什么是不同类型的微服务测试？

在使用微服务时，由于有多个微服务协同工作，测试变得非常复杂。因此，测试分为不同的级别。 􀀀 在底层，我们有面向技术的测试，如单元测试和性能测试。这些是完全自动化的。 􀀀 在中间层面，我们进行了诸如压力测试和可用性测试之类的探索性测试。 􀀀 在顶层， 我们的 验收测试数量很少。这些验收测试有助于利益相关者理解和验证软件功能。

## 10.架构师在微服务架构中的角色是什么？

微服务架构中的架构师扮演以下角色： 􀀀 决定整个软件系统的布局。 􀀀 帮助确定组件的分区。因此，他们确保组件相互粘合，但不紧密耦合。 􀀀 与开发人员共同编写代码，了解日常生活中面临的挑战。 􀀀 为开发微服务的团队提供某些工具和技术的建议。 􀀀 提供技术治理，以便技术开发团队遵循微服务原则。

### 11.SOA架构和微服务架构的区别

SOA架构和微服务架构的区别

首先SOA和微服务架构一个层面的东西，而对于ESB和微服务网关是一个层面的东西，一个谈到是架构风格和方法，一个谈的是实现工具或组件。

1.**SOA（Service Oriented Architecture）“面向服务的架构”:** 他是一种设计方法，其中包含多个服务， 服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在与操作系统进程中。各个服务之间 通过网络调用。

2.**微服务架构:** 其实和 SOA 架构类似,微服务是在 SOA 上做的升华，微服务架构强调的一个重点是“业务需要彻底的组件化和服务化”，原有的单个业务系统会拆分为多个可以独立开发、设计、运行的小应用。这些小应用之间通过服务完成交互和集成。

**微服务架构 = 80%的SOA服务架构思想 + 100%的组件化架构思想 + 80%的领域建模思想**

ESB和微服务API网关

**1.ESB（企业服务总线）：** 简单 来说 ESB 就是一根管道，用来连接各个服务节点。为了集 成不同系统，不同协议的服务，ESB 做了消息的转化解释和路由工作，让不同的服务互联互通；

**2.API网关:** API网关是一个服务器，是系统的唯一入口。从面向对象设计的角度看，它与外观模式类似。API网关封装了系统内部架构，为每个客户端提供一个定制的API。它可能还具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。

API网关方式的核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。通常，网关也是提供REST/HTTP的访问API。服务端通过API-GW注册和管理服务。

SOA架构特点

**系统集成：** 站在系统的角度，解决企业系统间的通信问 题，把原先散乱、无规划的系统间的网状结构，梳理成 规整、可治理的系统间星形结构，这一步往往需要引入 一些产品，比如 ESB、以及技术规范、服务管理规范；这一步解决的核心问题是【有序】

**系统的服务化：** 站在功能的角度，把业务逻辑抽象成 可复用、可组装的服务，通过服务的编排实现业务的 快速再生，目的：把原先固有的业务功能转变为通用 的业务服务，实现业务逻辑的快速复用；这一步解决 的核心问题是【复用】

**业务的服务化：** 站在企业的角度，把企业职能抽象成 可复用、可组装的服务；把原先职能化的企业架构转变为服务化的企业架构，进一步提升企业的对外服务能力；“前面两步都是从技术层面来解决系统调用、系统功能复用的问题”。第三步，则是以业务驱动把一个业务单元封装成一项服务。这一步解决的核心问题是【高效】

微服务架构特点：

1.通过服务实现组件化

开发者不再需要协调其它服务部署对本服务的影响。

2.按业务能力来划分服务和开发团队

开发者可以自由选择开发技术，提供 API 服务

3.去中心化

- 每个微服务有自己私有的数据库持久化业务数据
- 每个微服务只能访问自己的数据库，而不能访问其它服务的数据库
- 某些业务场景下，需要在一个事务中更新多个数据库。这种情况也不能直接访问其它微服务的数据库，而是通过对于微服务进行操作。
- 数据的去中心化，进一步降低了微服务之间的耦合度，不同服务可以采用不同的数据库技术（SQL、NoSQL等）。在复杂的业务场景下，如果包含多个微服务，通常在客户端或者中间层（网关）处理。

4.基础设施自动化（devops、自动化部署）

Java EE部署架构，通过展现层打包WARs，业务层划分到JARs最后部署为EAR一个大包，而微服务则打开了这个黑盒子，把应用拆分成为一个一个的单个服务，应用Docker技术，不依赖任何服务器和数据模型，是一个全栈应用，可以通过自动化方式独立部署，每个服务运行在自己的进程中，通过轻量的通讯机制联系，经常是基于HTTP资源API，这些服务基于业务能力构建，能实现集中化管理（因为服务太多啦，不集中管理就无法DevOps啦）。

# 系统设计基础

## 一、性能

### 性能指标

\1. 响应时间

指某个请求从发出到接收到响应消耗的时间。

在对响应时间进行测试时，通常采用重复请求的方式，然后计算平均响应时间。

\2. 吞吐量

指系统在单位时间内可以处理的请求数量，通常使用每秒的请求数来衡量。

\3. 并发用户数

指系统能同时处理的并发用户请求数量。

在没有并发存在的系统中，请求被顺序执行，此时响应时间为吞吐量的倒数。例如系统支持的吞吐量为 100 req/s，那么平均响应时间应该为 0.01s。

目前的大型系统都支持多线程来处理并发请求，多线程能够提高吞吐量以及缩短响应时间，主要有两个原因：

- 多 CPU
- IO 等待时间

使用 IO 多路复用等方式，系统在等待一个 IO 操作完成的这段时间内不需要被阻塞，可以去处理其它请求。通过将这个等待时间利用起来，使得 CPU 利用率大大提高。

并发用户数不是越高越好，因为如果并发用户数太高，系统来不及处理这么多的请求，会使得过多的请求需要等待，那么响应时间就会大大提高。

### 性能优化

\1. 集群

将多台服务器组成集群，使用负载均衡将请求转发到集群中，避免单一服务器的负载压力过大导致性能降低。

\2. 缓存

缓存能够提高性能的原因如下：

- 缓存数据通常位于内存等介质中，这种介质对于读操作特别快；
- 缓存数据可以位于靠近用户的地理位置上；
- 可以将计算结果进行缓存，从而避免重复计算。

\3. 异步

某些流程可以将操作转换为消息，将消息发送到消息队列之后立即返回，之后这个操作会被异步处理。

## 二、伸缩性

指不断向集群中添加服务器来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。

### 伸缩性与性能

如果系统存在性能问题，那么单个用户的请求总是很慢的；

如果系统存在伸缩性问题，那么单个用户的请求可能会很快，但是在并发数很高的情况下系统会很慢。

### 实现伸缩性

应用服务器只要不具有状态，那么就可以很容易地通过负载均衡器向集群中添加新的服务器。

关系型数据库的伸缩性通过 Sharding 来实现，将数据按一定的规则分布到不同的节点上，从而解决单台存储服务器的存储空间限制。

对于非关系型数据库，它们天生就是为海量数据而诞生，对伸缩性的支持特别好。

## 三、扩展性

指的是添加新功能时对现有系统的其它应用无影响，这就要求不同应用具备低耦合的特点。

实现可扩展主要有两种方式：

- 使用消息队列进行解耦，应用之间通过消息传递进行通信；
- 使用分布式服务将业务和可复用的服务分离开来，业务使用分布式服务框架调用可复用的服务。新增的产品可以通过调用可复用的服务来实现业务逻辑，对其它产品没有影响。

## 四、可用性

### 冗余

保证高可用的主要手段是使用冗余，当某个服务器故障时就请求其它服务器。

应用服务器的冗余比较容易实现，只要保证应用服务器不具有状态，那么某个应用服务器故障时，负载均衡器将该应用服务器原先的用户请求转发到另一个应用服务器上，不会对用户有任何影响。

存储服务器的冗余需要使用主从复制来实现，当主服务器故障时，需要提升从服务器为主服务器，这个过程称为切换。

### 监控

对 CPU、内存、磁盘、网络等系统负载信息进行监控，当某个信息达到一定阈值时通知运维人员，从而在系统发生故障之前及时发现问题。

### 服务降级

服务降级是系统为了应对大量的请求，主动关闭部分功能，从而保证核心功能可用。

## 五、安全性

要求系统在应对各种攻击手段时能够有可靠的应对措施。

# 集群

## 一、负载均衡

集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。

负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。

负载均衡器可以用来实现高可用以及伸缩性：

- 高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用；
- 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。

负载均衡器运行过程包含两个部分：

1. 根据负载均衡算法得到转发的节点；
2. 进行转发。

### 负载均衡算法

\1. 轮询（Round Robin）

轮询算法把每个请求轮流发送到每个服务器上。

下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请求按 (1, 2, 3, 4, 5, 6) 的顺序发送。(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。

该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载

\2. 加权轮询（Weighted Round Robbin）

加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。

例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1，(6) 请求会被发送到服务器 2。

\3. 最少连接（least Connections）

由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。

例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开，此时 (6, 4) 请求连接服务器 2。该系统继续运行时，服务器 2 会承担过大的负载。

最少连接算法就是将请求发送给当前最少连接数的服务器上。

例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。

\4. 加权最少连接（Weighted Least Connection）

在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。

\5. 随机算法（Random）

把请求随机发送到服务器上。

和轮询算法类似，该算法比较适合服务器性能差不多的场景。

\6. 源地址哈希法 (IP Hash)

源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。

可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）

### 转发实现

\1. HTTP 重定向

HTTP 重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。

缺点：

- 需要两次请求，因此访问延迟比较高；
- HTTP 负载均衡器处理能力有限，会限制集群的规模。

该负载均衡转发的缺点比较明显，实际场景中很少使用它。

\2. DNS 域名解析

在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。

优点：

- DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。

缺点：

- 由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。

大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址。

\3. 反向代理服务器

反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。

在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。

优点：

- 与其它功能集成在一起，部署简单。

缺点：

- 所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。

\4. 网络层

在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的 IP 地址，并修改请求数据包的目的 IP 地址，最后进行转发。

源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。

优点：

- 在内核进程中进行处理，性能比较高。

缺点：

- 和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。

\5. 链路层

在链路层根据负载均衡算法计算源服务器的 MAC 地址，并修改请求数据包的目的 MAC 地址，并进行转发。

通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，从而不需要修改 IP 地址就可以进行转发。也正因为 IP 地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。

这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。

这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux Virtual Server）。

## 二、集群下的 Session 管理

一个用户的 Session 信息如果存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器，由于服务器没有用户的 Session 信息，那么该用户就需要重新进行登录等操作。

### Sticky Session

需要配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的 Session 存放在该服务器中。

缺点：

- 当服务器宕机时，将丢失该服务器上的所有 Session。

### Session Replication

在服务器之间进行 Session 同步操作，每个服务器都有所有用户的 Session 信息，因此用户可以向任何一个服务器进行请求。

缺点：

- 占用过多内存；
- 同步过程占用网络带宽以及服务器处理器时间。

### Session Server

使用一个单独的服务器存储 Session 数据，可以使用传统的 MySQL，也使用 Redis 或者 Memcached 这种内存型数据库。

优点：

- 为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。

缺点：

- 需要去实现存取 Session 的代码。



### 68.**服务降级**

**服务降级：当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。**

识别哪些功能是核心功能、哪些功能是非核心功能，然后对非核心功能采取不通的降级方案制定的过程叫做**降级预案**。

**降级的方式**

**延迟服务**

比如发表了评论，重要服务，比如在文章中显示正常，但是延迟给用户增加积分，只是放到一个缓存中，等服务平稳之后再执行。

**在粒度范围内关闭服务（片段降级或服务功能降级**）

比如关闭相关文章的推荐，直接关闭推荐区

**页面异步请求降级**

比如商品详情页上有推荐信息/配送至等异步加载的请求，如果这些信息响应慢或者后端服务有问题，可以进行降级； **页面跳转（页面降级）**

比如可以有相关文章推荐，但是更多的页面则直接跳转到某一个地址。

**写降级**

比如秒杀抢购，我们可以只进行Cache的更新，然后异步同步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。

**读降级**

比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景；

**降级的介入方式**

按照是不是可以自动化降级，降级共有两种介入方式，分别是：**自动开关降级**和**人工开关降级**。

**自动开关降级**

自动开关降级的方式一般是当系统达到某些设定的条件（系统负载、资源使用情况、SLA等指标）之后，自动执行一些策略。

常见的可以作为自动降级条件的指标有以下几个：

**服务超时**

当访问的数据库/http服务/远程调用响应慢或者长时间响应慢，且该服务不是核心服务的话可以在超时后自动降级；

比如前面提到的详情页上有推荐和收藏功能，即使出现问题也不会影响用户的正常下单。如果是调用别人的远程服务，和对方定义一个服务响应最大时间，如果超时了则可以自动降级。

**失败次数**

调用外部服务的时候，除了超时意外，最常见的异常情况就是调用失败。比如详情页中的库存信息，如果是某一次查询请求失败了，那么可以那么就可以通过读取缓存数据等方式直接降级掉。

但是，这种降级可能存在一个问题，就是虽然一次请求展示了缓存，但是其他用户访问的时候还是会查询库存信息，这对于库存系统来说就是雪上加霜。因为他可能已经有问题了，但是上游系统还是在不断的对他发送请求。

所以，可以针对这个查询库存的接口做统一的降级。设定一个失败次数的阈值，一旦整体失败次数达到这个阈值了，就对后续一段时间内的改查询接口做降级。直到其功能恢复。

**发生故障**

上面提到的失败可能是服务不稳定造成的，过一段时间可以自动恢复的。还有一种情况可能是依赖的服务彻底跪了、或者网络不通了等等。这种情况就可以直接降级了。

当HTTP请求返回固定的错误码、或者一个RPC请求的时候底层服务抛了异常以后，就认为有故障发生，对其进行降级即可。

**限流降级**

还有种电商网站常见的策略，那就是限流降级。对于某些功能，设定一个流量阈值，一旦流量达到阈值的话，就进行降级。

比如秒杀功能，如果一瞬间流量太大，就可以进行限流降级。对于后续访问的用户直接提示已售空、跳转错误页、或者让他输入验证码重试等。

人工开关降级

还有一种降级方式，那就是人工开关降级。

人工开关降级的方式是指当系统维护人员在发现系统异常之后，通过人工修改参数、关闭服务等方式进行降级的方法。

这种方式的好处是比较灵活，能够根据异常情况灵活应对；但弊端是对人的要求比较高，一来需要维护人员对系统有足够的了解，另外要求维护人员在系统异常时能够在第一时间进行处置。

还有一种情况，可能也会人工介入，那就是在大促之前，预估到流量会十分巨大，提早的识别出风险，为了节省资源保证主流程的可用，开发人员可以手动将某个功能降级掉。

这里说的人工开关降级，并不一定是一定要人工操作，也可能是人工通过一个定时任务进行定时触发的。

**降级工具**

目前市面上，针对流量控制，限流降级主要有以下两种选择：Netflix Hystrix 和 Alibaba Sentinal。

**Hystrix**

Hystrix是一个库，它提供了服务与服务之间的容错功能，主要体现在延迟容错和容错，从而做到控制分布式系统中的联动故障。Hystrix通过隔离服务的访问点，阻止联动故障，并提供故障的解决方案，从而提高了这个分布式系统的弹性。

Hystrix 的关注点在于以 隔离 和 熔断 为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。

**Sentinel**

Sentinel 是阿里中间件团队开源的，面向分布式服务架构的轻量级高可用流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户保护服务的稳定性。

Sentinel 的侧重点在于：多样化的流量控制、熔断降级、系统负载保护、实时监控和控制台等

### 69.什么是RPC

**RPC 是Remote Procedure Call的缩写，译为远程过程调用。是一个计算机通信协议。**

到底什么是远程过程调用

RPC 是指计算机 A 上的进程，调用另外一台计算机 B 上的进程，其中 A 上的调用进程被挂起，而 B 上的被调用进程开始执行，当值返回给 A 时，A 进程继续执行。调用方可以通过使用参数将信息传送给被调用方，而后可以通过传回的结果得到信息。而这一过程，对于开发人员来说是透明的。

由于各服务部署在不同机器上，要想在服务间进行远程调用免不了网络通信过程，服务消费方每调用一个服务都要写一坨网络通信相关的代码，不仅复杂而且极易出错。

如果有一种方式能让我们像调用本地服务一样调用远程服务，而让调用者对网络通信这些细节透明，那么将大大提高生产力，比如服务消费方在执行`orderService.buy("HHKB键盘")`时，实质上调用的是远端的服务。这种方式其实就是RPC。而提供了这种功能的工具我们称之为RPC框架。

在RPC框架中主要有三个角色：Provider、Consumer和Registry。

Server: 暴露服务的服务提供方。 Client: 调用远程服务的服务消费方。 Registry: 服务注册与发现的注册中心。

服务提供者启动后主动向注册中心注册机器ip、port以及提供的服务列表； 服务消费者启动时向注册中心获取服务提供方地址列表，可实现软负载均衡和Failover；

**实现RPC需要用到的技术**

**动态代理**

生成 client stub和server stub需要用到Java 动态代理技术，我们可以使用JDK原生的动态代理机制，可以使用一些开源字节码工具框架 如：CgLib、Javassist等。

**序列化**

为了能在网络上传输和接收 Java对象，我们需要对它进行序列化和反序列化操作。

可以使用Java原生的序列化机制，但是效率非常低，推荐使用一些开源的、成熟的序列化技术，例如：protobuf、Thrift、hessian、Kryo、Msgpack

**NIO**

当前很多RPC框架都直接基于netty这一IO通信框架，比如阿里巴巴的HSF、dubbo，Hadoop Avro，推荐使用Netty 作为底层通信框架。

**服务注册中心**

可选技术： Redis、Zookeeper、Consul、Etcd

**开源RPC框架**

**Dubbo**

Dubbo 是阿里巴巴公司开源的一个Java高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。目前已经进入Apache孵化器。

**Motan**

Motan是新浪微博开源的一个Java RPC框架。2016年5月开源。Motan 在微博平台中已经广泛应用，每天为数百个服务完成近千亿次的调用。

**gRPC**

gRPC是Google开发的高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。本身它不是分布式的，所以要实现上面的框架的功能需要进一步的开发。

**thrift**

thrift是Apache的一个跨语言的高性能的服务框架，也得到了广泛的应用。

### 70.什么是负载均衡

**Load balancing，即负载均衡，是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。**

**为什么需要负载均衡**

当用户集中访问网站的时候，如果没有任何机制来疏导用户的话，完全随机或者就近原则的话，那么就会导致某些服务器的流量很大，而另外一个服务器的[qps](http://mp.weixin.qq.com/s?__biz=MzU3OTYxOTU4NA==&mid=2247484216&idx=1&sn=868714084330bae9f68f0e556249aeec&chksm=fd621d57ca1594419e56b30776349a40ef2c881009b6366a5f73c3872093498a94c8206a3744&scene=21#wechat_redirect)很小。这不仅严重的浪费了资源，而且还会导致拉长用户访问网站的[RT](http://mp.weixin.qq.com/s?__biz=MzU3OTYxOTU4NA==&mid=2247484216&idx=1&sn=868714084330bae9f68f0e556249aeec&chksm=fd621d57ca1594419e56b30776349a40ef2c881009b6366a5f73c3872093498a94c8206a3744&scene=21#wechat_redirect)，影响用户的体验。更严重的可能直接拖垮那些流量大的服务器。

这时候，就需要一个协调者，来均衡的分配这些用户的请求，可以让用户的可以均匀的分派到不同的服务器上。

**什么是负载均衡**

为了提升网站的各方面能力，我们一般会把多台机器组成一个集群对外提供服务。然而，我们的网站对外提供的访问入口都是一个的，比如[www.taobao.com](www.taobao.com)。那么当用户在浏览器输入[www.taobao.com](www.taobao.com)的时候如何将用户的请求分发到集群中不同的机器上呢，这就是负载均衡在做的事情。

**负载均衡（Load Balance），意思是将负载（工作任务，访问请求）进行平衡、分摊到多个操作单元（服务器，组件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。**

**OSI**

**OSI是一个开放性的通信系统互连参考模型，他是一个定义得非常好的协议规范。**

OSI模型有7层结构，每层都可以有几个子层。 OSI的7层从上到下分别是 7、应用层；6、表示层；5、会话层；4、传输层；3、网络层；2、数据链路层；1、物理层；

其中高层（即7、6、5、4层）定义了应用程序的功能，下面3层（即3、2、1层）主要面向通过网络的端到端的数据流。

在这七层模型种，高层次都是依赖于低层次的。层次越高，使用起来越方便。

我们经常听到的一些和计算机网络有关的概念中：

> telnet、HTTP、FTP、NFS、SMTP、DNS等属于第七层应用层的概念。
>
> TCP、UDP、SPX等属于第四层传输层的概念。
>
> IP、IPX等属于第三层网络层的概念。
>
> ATM、FDDI等属于第二层数据链路层的概念。

负载均衡分类

了解了网络协议的七层模型以后，再来看看负载均衡。我们可以很明确的一点是，**负载均衡是要在网络传输中做文章的**。而要在网络传输过程搞事情，那么这七层模型就势必躲不开。

所以，根据负载均衡技术实现在OSI七层模型的不同层次，是可以给负载均衡分类的。

常见的实现方式中，主要可以在应用层、传输层、网络层和数据传输层做文章。所以，工作在应用层的负载均衡，我们通常称之为七层负载均衡、工作在传输层的我们称之为四层负载均衡。

大致可以分为以下几种，其中最常用的是四层和七层负载均衡：

**二层负载均衡**

负载均衡服务器对外依然提供一个VIP（虚IP），集群中不同的机器采用相同IP地址，但是机器的MAC地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的目标MAC地址的方式将请求转发到目标机器实现负载均衡。

**三层负载均衡**

和二层负载均衡类似，负载均衡服务器对外依然提供一个VIP（虚IP），但是集群中不同的机器采用不同的IP地址。当负载均衡服务器接受到请求之后，根据不同的负载均衡算法，通过IP将请求转发至不同的真实服务器。

**四层负载均衡**

四层负载均衡工作在OSI模型的传输层，由于在传输层，只有TCP/UDP协议，这两种协议中除了包含源IP、目标IP以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器。

**七层负载均衡**

七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用http、radius、dns等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个Web服务器的负载均衡，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。

**负载均衡工具**

市面上有很多开源的负载均衡的工具或软件，基本都是基于前面提到的方案实现的，大多数是工作在第七层和第四层的。Nginx/LVS/HAProxy是目前使用最广泛的三种负载均衡软件。

**LVS**

LVS（Linux Virtual Server），也就是Linux虚拟服务器, 是一个由章文嵩博士发起的自由软件项目。使用LVS技术要达到的目标是：通过LVS提供的负载均衡技术和Linux操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。

**LVS主要用来做四层负载均衡。**

**Nginx**

Nginx（发音同engine x）是一个网页服务器，它能反向代理HTTP, HTTPS, SMTP, POP3, IMAP的协议链接，以及一个负载均衡器和一个HTTP缓存。

**Nginx主要用来做七层负载均衡。**

**HAProxy**

HAProxy是一个使用C语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于TCP和HTTP的应用程序代理。

**HAProxy主要用来做七层负载均衡。**

负载均衡算法

负载均衡服务器在决定将请求转发到具体哪台真实服务器的时候，是通过负载均衡算法来实现的。负载均衡算法，是一个负载均衡服务器的核心。

负载均衡算法可以分为两类：静态负载均衡算法和动态负载均衡算法。

静态负载均衡算法包括：轮询，比率，优先权

动态负载均衡算法包括: 最少连接数,最快响应速度，观察方法，预测法，动态性能分配，动态服务器补充，服务质量，服务类型，规则模式。

- 轮询（Round Robin）：顺序循环将请求一次顺序循环地连接每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。
- 比率（Ratio）：给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。
- 优先权（Priority）：给所有服务器分组,给每个组定义优先权，BIG-IP 用户的请求，分配给优先级最高的服务器组（在同一组内，采用轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器出现故障，BIG-IP 才将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。
- 最少的连接方式（Least Connection）：传递新的连接给那些进行最少连接处理的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配, 直到其恢复正常。
- 最快模式（Fastest）：传递连接给那些响应最快的服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP 就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
- 观察模式（Observed）：连接数目和响应时间以这两项的最佳平衡为依据为新的请求选择服务器。当其中某个服务器发生第二到第7 层的故障，BIG-IP就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
- 预测模式（Predictive）：BIG-IP利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。(被BIG-IP 进行检测)
- 动态性能分配(Dynamic Ratio-APM):BIG-IP 收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。
- 动态服务器补充(Dynamic Server Act.):当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。
- 服务质量(QoS）:按不同的优先级对数据流进行分配。
- 服务类型(ToS): 按不同的服务类型（在Type of Field中标识）负载均衡对数据流进行分配。
- 规则模式：针对不同的数据流设置导向规则，用户可自行。

### 72.什么是反向代理？

**反向代理（reverse proxy）：是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。**

**正向代理**

正向代理（forward proxy）：是一个位于客户端和目标服务器之间的服务器(代理服务器)，为了从目标服务器取得内容，客户端向代理服务器发送一个请求并指定目标，然后代理服务器向目标服务器转交请求并将获得的内容返回给客户端。

有时候，用户想要访问某国外网站，该网站无法在国内直接访问，但是我们可以访问到一个代理服务器，这个代理服务器可以访问到这个国外网站。这样呢，用户对该国外网站的访问就需要通过代理服务器来转发请求，并且该代理服务器也会将请求的响应再返回给用户。这个上网的过程就是用到了正向代理。

**所以，正向代理，其实是"代理服务器"代理了"客户端"，去和"目标服务器"进行交互。**

通过正向代理服务器访问目标服务器，目标服务器是不知道真正的客户端是谁的，甚至不知道访问自己的是一个代理（有时候中介也直接冒充租客）。

**正向代理的用途**

**突破访问限制**

通过代理服务器，可以突破自身IP访问限制，访问国外网站，教育网等。

即，租客可以通过中介，来解决无法联系上房东的问题。

**提高访问速度**

通常代理服务器都设置一个较大的硬盘缓冲区，会将部分请求的响应保存到缓冲区中，当其他用户再访问相同的信息时， 则直接由缓冲区中取出信息，传给用户，以提高访问速度。

即，中介手里留存了很多房源信息和钥匙，可以直接带租客去看房。

**隐藏客户端真实IP**

上网者也可以通过这种方法隐藏自己的IP，免受攻击。

即，房东并不知道租客的真实身份。PS：但是中介知道了，可能骚扰更多….

**反向代理**

反向代理（reverse proxy）：是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。

我们在租房子的过程中，除了有些房源需要通过中介以外，还有一些是可以直接通过房东来租的。用户直接找到房东租房的这种情况就是我们不使用代理直接访问国内的网站的情况。

还有一种情况，就是我们以为我们接触的是房东，其实有时候也有可能并非房主本人，有可能是他的亲戚、朋友，甚至是二房东。但是我们并不知道和我们沟通的并不是真正的房东。这种帮助真正的房主租房的二房东其实就是反向代理服务器。这个过程就是反向代理。

对于常用的场景，就是我们在Web开发中用到的负载均衡服务器（二房东），客户端（租客）发送请求到负载均衡服务器（二房东）上，负载均衡服务器（二房东）再把请求转发给一台真正的服务器（房东）来执行，再把执行结果返回给客户端（租客）。

**所以，反向代理，其实是"代理服务器"代理了"目标服务器"，去和"客户端"进行交互。**

通过反向代理服务器访问目标服务器时，客户端是不知道真正的目标服务器是谁的，甚至不知道自己访问的是一个代理。

**反向代理的用途**

**隐藏服务器真实IP**

使用反向代理，可以对客户端隐藏服务器的IP地址。

即，租客并不房东知道的真实身份。

**负载均衡**

反向代理服务器可以做负载均衡，根据所有真实服务器的负载情况，将客户端请求分发到不同的真实服务器上。

即，二房东发现房主本人很忙，于是找到房主的妻子帮忙处理租房事宜。

**提高访问速度**

反向代理服务器可以对于静态内容及短时间内有大量访问请求的动态内容提供缓存服务，提高访问速度。

即，二房东同样有房屋信息和钥匙。

**提供安全保障**

反向代理服务器可以作为应用层防火墙，为网站提供对基于Web的攻击行为（例如DoS/DDoS）的防护，更容易排查恶意软件等。还可以为后端服务器统一提供加密和SSL加速（如SSL终端代理），提供HTTP访问认证等。

即，二房东可以有效的保护房东的安全。

**正向代理和反向代理的区别**

虽然正向代理服务器和反向代理服务器所处的位置都是客户端和真实服务器之间，所做的事情也都是把客户端的请求转发给服务器，再把服务器的响应转发给客户端，但是二者之间还是有一定的差异的。

1、**正向代理其实是客户端的代理**，帮助客户端访问其无法访问的服务器资源。**反向代理则是服务器的代理**，帮助服务器做负载均衡，安全防护等。

2、**正向代理一般是客户端架设的**，比如在自己的机器上安装一个代理软件。而**反向代理一般是服务器架设的**，比如在自己的机器集群中部署一个反向代理服务器。

3、**正向代理中，服务器不知道真正的客户端到底是谁**，以为访问自己的就是真实的客户端。而在**反向代理中，客户端不知道真正的服务器是谁**，以为自己访问的就是真实的服务器。

4、正向代理和反向代理的作用和目的不同。**正向代理主要是用来解决访问限制问题。而反向代理则是提供负载均衡、安全防护等作用。二者均能提高访问速度。**

### 73.什么是系统可用性？

**系统可用性**

系统的可用性，英文名字为System Usability，即系统服务不中断运行时间占实际运行时间的比例。所以，可用性其实是一个百分比，如99.9%。

我们通常会听说一个词：高可用，其实指的就是高可用性。高可用指的就是系统服务不中断运行时间占实际运行时间的占比更大。

要了解可用性，躲不开的三个体现系统可用性的重要指标：MTTR、MTTF、MTBF

MTTF 即 Mean Time To Failure，中文为：平均无故障时间。指系统无故障运行的平均时间，取所有从系统开始正常运行到发生故障之间的时间段的平均值。

MTTR 即 Mean Time To Repair，中文为：平均修复时间，指系统从发生故障到维修结束之间的时间段的平均值。

MTBF 即 Mean Time Between Failure，中文为：平均失效间隔，指系统两次故障发生时间之间的时间段的平均值。

```html
MTBF = MTTF + MTTR
```

按照以上概念，那么系统的可用性指的其实就是： `MTTF / MTBR * 100%` 即 `MTTF / ( MTTF + MTTR ) * 100%`

可用性的衡量

衡量系统的高可用性，一般通过SLA，全称Service Level Agrement，也就是有几个9的高可用性。我们经常可以看到很多公司会宣称自己的系统可以达到99.99%、99.999%等。

工业界通常通过统计故障发生到恢复的时间的方法来测量SLA。一般以年度为单位，统计一年内的系统不可用总时长。

对于 SLA 指标来说，9 的数字越多可用性越高，宕机时间越少，系统就可以在给定的时刻内高比例地正常工作。然而对系统的挑战就越大，投入的成本也会越高。 比如 5 个 9 要求系统每年只宕机 5 分钟左右，而 4 个 9 要求每年宕机时间不超过一个小时。这就使得系统需要在设计、基础设施、数据备份等不同层面采取多种方式，甚至增加基础设施投资来保证可用性。

可用性的保障

影响可用性的因素有很多，包括系统故障、基础设施故障、数据故障、安全攻击、系统压力等等。

可用性的保障涉及到很多层面，其中包括但不限于了：

- 软件的设计、编码、测试、上线和软件配置管理的水平
- 工程师的人员技能水平
- 运维的管理和技术水平
- 数据中心的运营管理水平
- 依赖于第三方服务的管理水平
- 对待技术的态度
- 一个公司的工程文化
- 领导者对工程的尊重

### 79.**大数据**

大数据，Big Data，是指无法在一定时间内用常规软件工具对其内容进行抓取、管理和处理的数据集合。大数据具有4个基本特征：

- 数据体量巨大。百度资料表明，其新首页导航每天需要提供的数据超过1.5PB（1PB=1024TB），这些数据如果打印出来将超过5千亿张A4纸。有资料证实，到目前为止，人类生产的所有印刷材料的数据量仅为200PB。
- 数据类型多样。现在的数据类型不仅是文本形式，更多的是图片、视频、音频、地理位置信息等多类型的数据，个性化数据占绝对多数。
- 处理速度快。数据处理遵循“1秒定律”，可从各种类型的数据中快速获得高价值的信息。
- 价值密度低。以视频为例，一小时的视频，在不间断的监控过程中，可能有用的数据仅仅只有一两秒。

**大数据的处理**

**大数据处理的主要流程：包括数据收集、数据预处理、数据存储、数据处理与分析、数据展示/数据可视化、数据应用等环节。**

整个处理流程也可以精简概括为四步，分别是数据采集存储、数据预处理、数据统计分析，最后是数据挖掘。

**数据采集存储**

数据的采集是指利用多个数据库来接收发自客户端的数据，并且用户可以通过这些数据库来进行简单的查询和处理工作。比如，电商会使用传统的关系型数据库MySQL和Oracle等来存储每一笔事务数据，除此之外，Redis和MongoDB这样的NoSQL数据库也常用于数据的采集。

**数据预处理**

虽然采集端本身会有很多数据库，但是如果要对这些海量数据进行有效的分析，还是应该将这些来自前端的数据导入到一个集中的大型分布式数据库，或者分布式存储集群，并且可以在导入基础上做一些简单的清洗和预处理工作。

**数据统计分析**

统计与分析主要利用分布式数据库，或者分布式计算集群来对存储于其内的海量数据进行普通的分析和分类汇总等，以满足大多数常见的分析需求。

**数据挖掘**

与前面统计和分析过程不同的是，数据挖掘一般没有什么预先设定好的主题，主要是在现有数据上面进行基于各种算法的计算，从而起到预测（Predict）的效果，从而实现一些高级别数据分析的需求。

大数据处理相关技术

大数据技术的体系庞大且复杂，基础的技术包含数据的采集、数据预处理、分布式存储、NoSQL数据库、数据仓库、机器学习、并行计算、可视化等各种技术范畴和不同的技术层面

文件存储：Hadoop HDFS、Tachyon、KFS

离线计算：Hadoop MapReduce、Spark

流式、实时计算：Storm、Spark Streaming、S4、Heron

K-V、NOSQL数据库：HBase、Redis、MongoDB

资源管理：YARN、Mesos

日志收集：Flume、Scribe、Logstash、Kibana

消息系统：Kafka、StormMQ、ZeroMQ、RabbitMQ

查询分析：Hive、Impala、Pig、Presto、Phoenix、SparkSQL、Drill、Flink、Kylin、Druid

分布式协调服务：Zookeeper

集群管理与监控：Ambari、Ganglia、Nagios、Cloudera Manager

数据挖掘、机器学习：Mahout、Spark MLLib

数据同步：Sqoop任务调度：Oozie

### 80.什么是CDN？

什么是CDN

CDN的全称是Content Delivery Network，即内容分发网络。

我们在浏览网络的时候，我们访问一个页面的时候，会向服务器请求很多网络资源，包括各种图片、声音、影片、文字等信息。这和我们要购买的多种货物一样。

就像猫超会把货物提前存储在菜鸟建设在全国各地的本地仓库来减少物流时间一样，网站也可以预先把内容分发至全国各地的加速节点。这样用户就可以就近获取所需内容，避免网络拥堵、地域、运营商等因素带来的访问延迟问题，有效提升下载速度、降低响应时间，提供流畅的用户体验。

所以，"内容分发网络"就像前面提到的"全国仓配网络"一样，解决了因分布、带宽、服务器性能带来的访问延迟问题，适用于站点加速、点播、直播等场景。使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度和成功率。

有了仓配网络之后，除了可以提升货物的配送效率，还有很多其他的好处：

1、首先通过预先做好了货物分发，使得最终货品从出仓到消费者手中的过程是比较短的，那么同城范围内可选择的配送公司就有很多选择，除了比较大的四通一达、顺丰以外，还可以选用一些小的物流公司、甚至菜鸟直接调用饿了么的蜂鸟配送也不是不可能。

> CDN技术消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量

2、对于仓配系统来说，最大的灾难可能就是仓库发生火灾、水灾等自然灾害。如果把原来的一个集中式的大仓库打散成多个分布式的小仓库，分别部署在不同地区，就可以有效的减小自然灾害带来的影响。

> 广泛分布的CDN节点加上节点之间的智能冗余机制，可以有效地预防黑客入侵以及降低各种DDoS攻击对网站的影响，同时保证较好的服务质量

CDN的基本工作过程

传统快递企业采用的配送模式，通过"商家→网点→分拨→分拨→网点→客户"的环节进行配送。这个过程会有一些问题，如环节多、时效慢、易破损等。

上面这个过程和传统网站的请求响应过程类似，一般经历以下步骤：

- 用户在自己的浏览器中输入要访问的网站域名。
- 浏览器向本地DNS服务器请求对该域名的解析。
- 本地DNS服务器中如果缓存有这个域名的解析结果，则直接响应用户的解析请求。
- 本地DNS服务器中如果没有关于这个域名的解析结果的缓存，则以迭代方式向整个DNS系统请求解析，获得应答后将结果反馈给浏览器。
- 浏览器得到域名解析结果，就是该域名相应的服务设备的IP地址 。
- 浏览器获取IP地址之后，经过标准的TCP握手流程，建立TCP连接。
- 浏览器向服务器发起HTTP请求。
- 服务器将用户请求内容传送给浏览器。
- 经过标准的TCP挥手流程，断开TCP连接。

电商自建物流之后，配送模式有所变化：提前备货将异地件转化成同城件，省去干线环节提升时效，仓储高自动化分拣保证快速出库的同时也保证了分拣破损率较低。

对于用户来说，购物过程并没有变化，唯一的感受就是物流好像是比以前快了。所以，引入CDN之后，用户访问网站一般经历以下步骤：

- 当用户点击网站页面上的内容URL，先经过本地DNS系统解析，如果本地DNS服务器没有相应域名的缓存，则本地DNS系统会将域名的解析权交给CNAME指向的CDN专用DNS服务器。
- CDN的DNS服务器将CDN的全局负载均衡设备IP地址返回给用户。
- 用户向CDN的全局负载均衡设备发起URL访问请求。
- CDN全局负载均衡设备根据用户IP地址，以及用户请求的URL，选择一台用户所属区域的区域负载均衡设备，并将请求转发到此设备上。
- 基于以下这些条件的综合分析之后，区域负载均衡设备会选择一个最优的缓存服务器节点，并从缓存服务器节点处得到缓存服务器的IP地址，最终将得到的IP地址返回给全局负载均衡设备：
- 根据用户IP地址，判断哪一个边缘节点距用户最近；
- 根据用户所请求的URL中携带的内容名称，判断哪一个边缘节点上有用户所需内容；
- 查询各个边缘节点当前的负载情况，判断哪一个边缘节点尚有服务能力。
- 全局负载均衡设备把服务器的IP地址返回给用户。
- 用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。

CDN全局负载均衡设备与CDN区域负载均衡设备根据用户IP地址，将域名解析成相应节点中缓存服务器的IP地址，实现用户就近访问，从而提高服务端响应内容的速度。

**CDN的组成**

一个仓配网络是由多个仓库组成的，同理，内容分发网络（CDN）是由多个节点组成的。一般来讲，CDN网络主要由中心节点、边缘节点两部分构成。

**中心节点**

中心节点包括CDN网管中心和全局负载均衡DNS重定向解析系统，负责整个CDN网络的分发及管理。

**边缘节点**

CDN边缘节点主要指异地分发节点，由负载均衡设备、高速缓存服务器两部分组成。

负载均衡设备负责每个节点中各个Cache的负载均衡，保证节点的工作效率；同时还负责收集节点与周围环境的信息，保持与全局负载均衡DNS的通信，实现整个系统的负载均衡。

高速缓存服务器（Cache）负责存储客户网站的大量信息，就像一个靠近用户的网站服务器一样响应本地用户的访问请求。通过全局负载均衡DNS的控制，用户的请求被透明地指向离他最近的节点，节点中Cache服务器就像网站的原始服务器一样，响应终端用户的请求。因其距离用户更近，故其响应时间才更快。

**中心节点就像仓配网络中负责货物调配的总仓，而边缘节点就是负责存储货物的各个城市的本地仓库。**

CDN相关技术

首先我们想一下，要想建设一个庞大的仓配网络都需要考虑哪些问题，需要哪些技术手段呢？

笔者认为主要是四个重要关注的点，分别是：

1、如何妥善的将货物分发到各个城市的本地仓。

2、如何妥善的各个本地仓存储货物。

3、如何根据用户的收货地址，智能的匹配出应该优先从哪个仓库发货，选用哪种物流方式等。

4、对于整个仓配系统如何进行管理，如整体货物分发的精确度、仓配的时效性、发货地的匹配度等。

这其实和CDN中最重要的四大技术不谋而合，那就是内容发布、内容存储、内容路由以及内容管理等。

**内容发布**

它借助于建立索引、缓存、流分裂、组播（Multicast）等技术，将内容发布或投递到距离用户最近的远程服务点（POP）处。

**内容存储**

对于CDN系统而言，需要考虑两个方面的内容存储问题。一个是内容源的存储，一个是内容在 Cache节点中的存储。

**内容路由**

它是整体性的网络负载均衡技术，通过内容路由器中的重定向（DNS）机制，在多个远程POP上均衡用户的请求，以使用户请求得到最近内容源的响应。

**内容管理**

它通过内部和外部监控系统，获取网络部件的状况信息，测量内容发布的端到端性能（如包丢失、延时、平均带宽、启动时间、帧速率等），保证网络处于最佳的运行状态。

### 83.什么是云计算？

**什么是云计算**

因为企业各自搭建服务耗费巨大，于是就出有人想到能不能通过租用的方式，把自己的数据存储和计算在供应商提供远端的服务器上进行呢，事实证明是可行的。**而这种在远端提供的基础设施我们就称之为“云”**。

“云”中的资源在用户看来是可以无限扩展的，并且可以随时获取，按需使用，随时扩展，按使用付费。

理解了“云”之后，**云计算就容易理解了，就是一种把计算服务与数据存储作为一种商品进行售卖或者租赁，购买后可以在云端提供服务。**

**云计算的特点**

云计算的可贵之处在于高灵活性、可扩展性和高性比等，与传统的网络应用模式相比，其具有如下优势与特点：

**虚拟化技术**

在计算机中，虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以更好的应用这些资源。这些资源的新虚拟部分是不受现有资源的架设方式，地域或物理组态所限制。

一般需要进行虚拟化的资源正是云计算中的计算能力和存储服务。在云计算的应用中，主要包含硬件虚拟化、平台虚拟化、应用程序虚拟化等、

**动态可扩展**

云计算具有高效的运算能力，在原有服务器基础上增加云计算功能能够使计算速度迅速提高，最终实现动态扩展虚拟化的层次达到对应用进行扩展的目的。

**按需部署**

计算机包含了许多应用、程序软件等，不同的应用对应的数据资源库不同，云计算平台能够根据用户的需求快速配备计算能力及资源。

**灵活性高**

目前市场上大多数IT资源、软、硬件都支持虚拟化，比如存储网络、操作系统和开发软、硬件等。虚拟化要素统一放在云系统资源虚拟池当中进行管理，可见云计算的兼容性非常强，不仅可以兼容低配置机器、不同厂商的硬件产品，还能够外设获得更高性能计算。

**可靠性高**

倘若服务器故障也不影响计算与应用的正常运行。因为单点服务器出现故障可以通过虚拟化技术将分布在不同物理服务器上面的应用进行恢复或利用动态扩展功能部署新的服务器进行计算。

**性价比高**

将资源放在虚拟资源池中统一管理在一定程度上优化了物理资源，用户不再需要昂贵、存储空间大的主机，可以选择相对廉价的PC组成云，一方面减少费用，另一方面计算性能不逊于大型主机

**可扩展性**

用户可以利用应用软件的快速部署条件来更为简单快捷的将自身所需的已有业务以及新业务进行扩展。

**云计算服务类型**

根据服务类型的不同，云计算可以分为三类，即基础设施即服务(IaaS)、平台即服务(PaaS)和软件即服务(SaaS)。这3种云计算服务有时称为云计算堆栈，因为它们构建堆栈，它们位于彼此之上。

**基础设施即服务（IaaS)**

基础设施即服务是主要的服务类别之一，它向云计算提供商的个人或组织提供虚拟化计算资源，如虚拟机、存储、网络和操作系统。

**平台即服务(PaaS)**

平台即服务是一种服务类别，为开发人员提供通过全球互联网构建应用程序和服务的平台。Paas为开发、测试和管理软件应用程序提供按需开发环境。

**软件即服务(SaaS)**

软件即服务也是其服务的一类，通过互联网提供按需软件付费应用程序，云计算提供商托管和管理软件应用程序，并允许其用户连接到应用程序并通过全球互联网访问应用程序。

### 86.什么是熔断？

很多软件系统为了保证即使在出现并发用户数>最佳线程数时，也不至于导致整个万网站崩溃，都会采用一些技术手段来避免发生系统性灾难。这些技术中比较典型的就是限流、降级和熔断。

**为什么需要熔断**

服务调用链，如果其中某一个服务由于自身原因导致响应很慢，那么就可能导致上游的服务影响也很慢，这样循环往复，就会导致整个系统全线崩溃，这就是**服务雪崩**。

其实，在分布式系统中，为了保证整体服务可用性和一致性，很多系统都会引入重试机制，在有些情况下，重试其实是可以解决问题的，比如网络问题等，都可以通过重试来解决。

但是，有些情况下，重试并不能解决问题，返而会加剧问题的严重性，比如下游系统因为请求量太大，导致CPU已经被打满，说着数据库连接池被占满，这时候上游系统调不通就会不断进行重试，这种重试请求，对于下游系统来说，无疑是雪上加霜，给下游系统造成二次伤害。

而分布式系统，大多数的服务雪崩也都是因为不断重试导致的，这种重试有可能是框架级别的自动重试、有可能是代码级别的重试逻辑、还有可能是用户的主动重试。

**熔断器模式**

熔断器模式（Circuit Breaker Pattern），是一个现代软件开发的设计模式。用以侦测错误，并避免不断地触发相同的错误（如维护时服务不可用、暂时性的系统问题或是未知的系统错误）。

假设有个应用程序每秒会与数据库沟通数百次，此时数据库突然发生了错误，程序员并不会希望在错误时还不断地访问数据库。因此会想办法直接处理这个错误，并进入正常的结束程序。简单来说，

熔断器会侦测错误并且“预防”应用程序不断地重试调用一个近乎毫无回应的服务（除非该服务已经安全到可重试连线了）。

熔断器模式是方志微服务系统雪崩的一种重要手段。

一个比较完善的熔断器，一般包含三种状态：

- 关闭
- - 熔断器在默认情况下下是呈现关闭的状态，而熔断器本身带有计数功能，每当错误发生一次，计数器也就会进行“累加”的动作，到了一定的错误发生次数断路器就会被“开启”，这个时候亦会在内部启用一个计时器，一旦时间到了就会切换成半开启的状态。
- 开启
- - 在开启的状态下任何请求都会“直接”被拒绝并且抛出异常讯息。
- 半开启
- - 在此状态下断路器会允许部分的请求，如果这些请求都能成功通过，那么就意味着错误已经不存在，则会被切换回关闭状态并重置计数。倘若请求中有“任一”的错误发生，则会回复到“开启”状态，并且重新计时，给予系统一段休息时间。

如果在微服务系统的调用过程中，引入熔断器，那么整个系统将天然具备以下能力：

- **快速失败**：当因为调用远程服务失败次数过多，熔断器开启时，上游服务对于下游服务的调用就会快速失败，这样可以避免上游服务被拖垮。
- **无缝恢复**：因为熔断器可以定期检查下游系统是否恢复，一旦恢复就可以重新回到关闭状态，所有请求便可以正常请求到下游服务。使得系统不需要认为干预。

**熔断工具**

熔断器为了实现快速失败和无缝恢复，就需要进行服务调用次数统计、服务调用切断等操作，如果想要自己实现一个熔断器其实也是可以的。

但是，市面上有一些框架已经帮我们做了这些事情。如Hystrix和Sentinel、resilience4j等。

Hystrix

Hystrix是Netflix开源的一款容错系统，能帮助使用者码出具备强大的容错能力和鲁棒性的程序。提供降级，熔断等功能。

resilience4j

Hystrix停更之后，Netflix官方推荐使用resilience4j，它是一个轻量、易用、可组装的高可用框架，支持熔断、高频控制、隔离、限流、限时、重试等多种高可用机制。

与Hystrix相比，它有以下一些主要的区别：

- Hystrix调用必须被封装到HystrixCommand里，而resilience4j以装饰器的方式提供对函数式接口、lambda表达式等的嵌套装饰，因此你可以用简洁的方式组合多种高可用机制。
- Hystrix的频次统计采用滑动窗口的方式，而resilience4j采用环状缓冲区的方式。
- 关于熔断器在半开状态时的状态转换，Hystrix仅使用一次执行判定是否进行状态转换，而resilience4j则采用可配置的执行次数与阈值，来决定是否进行状态转换，这种方式提高了熔断机制的稳定性。
- 关于隔离机制，Hystrix提供基于线程池和信号量的隔离，而resilience4j只提供基于信号量的隔离。

Sentinel

Sentinel是阿里中间件团队开源的，面向分布式服务架构的轻量级高可用流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户保护服务的稳定性。

Hystrix 的关注点在于以隔离和熔断为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。

而 Sentinel 的侧重点在于：

- 多样化的流量控制
- 熔断降级
- 系统负载保护
- 实时监控和控制台

### 87.什么是撞库、脱库和洗库？

**撞库**

”撞库”是黑客通过收集互联网已泄露的用户和密码信息，生成对应的字典表，尝试批量登陆其他网站后，得到一系列可以登录的用户。

很多用户在不同网站使用的是相同的帐号密码，因此黑客可以通过获取用户在A网站的账户从而尝试登录B网址，这就可以理解为撞库攻击。

**漏水**

"漏水"是指某些企业自身出现风险导致的数据泄露。

一般是因为企业没有按照统一规范流程搭建业务，比如没有做好关键数据隔离、没有做好权限分层管控、没有做好数据加密存储等而出现的数据安全问题。

**拖库**

拖库本来是数据库领域的术语，指从数据库中导出数据。到了黑客攻击泛滥的今天，它被用来指网站遭到入侵后，黑客窃取其数据库。

黑客通过技术手段窃取数据库的过程叫做拖库。就像小偷偷东西是一样的。

“拖库”的通常步骤为：

- 1、黑客对目标网站进行扫描，查找其存在的漏洞，常见漏洞包括SQL注入、文件上传漏洞等。（`小偷蹲点`）
- 2、通过该漏洞在网站服务器上建立“后门(webshell)”，通过该后门获取服务器操作系统的权限。（`小偷想办法进入室内`）
- 3、利用系统权限直接下载备份数据库，或查找数据库链接，将其导出到本地。（`小偷盗走值钱的东西`）

最常见的网站入侵的方式就是黑客利用网站的漏洞来对网站进行攻击。这里说的网站漏洞包括网站应用自身的漏洞、网站使用的WEB服务器的漏洞、网站使用的开源框架中的漏洞、网站使用的数据库漏洞等。

比如，如果应用自身没有做防SQL注入、存在文件上传漏洞等，就极大可能被黑客入侵。

黑客还有可能会利用系统漏洞，在特定的网站上进行挂马，如果网站管理员在维护系统的时候不小心访问到这些网站，就可能被植入木马，也会引发后续的拖库风险。

**洗库**

“洗库”，属于黑客入侵的一种，就是黑客入侵网站，通过技术手段将有价值的用户数据归纳分析，售卖变现。

说的简单一点，就是一个小偷，入室盗窃后偷到了很多东西，他对这些赃物分类，然后进行销赃的过程。

### 91.什么是公有云、私有云和混合云？

**公有云**

公有云是为广大用户、个人或企业提供的云基础设施。公有云就是第三方的公有云供应商为用户提供可通过互联网访问的虚拟环境中的服务器空间。然后，用户可以通过购买云服务器、数据存储和其他与云相关的服务等公有云服务来访问这些服务器。

在公有云中，所有硬件、软件和其他支持性基础结构均为云提供商所拥有和管理。

在公有云中，你与其他组织或云“租户”共享相同的硬件、存储和网络设备。你可以使用 Web 浏览器访问服务和管理帐户。

公有云部署通常用于提供基于 Web 的电子邮件、网上办公应用、存储以及测试和开发环境。

- 公有云优势：
- - 成本更低 — 无需购买硬件或软件，仅对使用的服务付费。
  - 无需维护 — 维护由服务提供商提供。
  - 近乎无限制的缩放性 — 提供按需资源，可满足业务需求。
  - 高可靠性 — 具备众多服务器，确保免受故障影响。

但是同时，很多人担心公有云的安全性、私密性等问题。于是就有了私有云。

**私有云**

私有云是云计算的另一种形式。它为一个企业或组织提供专用的云环境。私有云可以由企业或组织内部的IT团队在该组织的防火墙后面进行内部操作，因此组织可以更好地控制其计算资源。私有云主要由企业使用，因此它也被视为一种企业云。

私有云可在物理上位于组织的现场数据中心，也可由第三方服务提供商托管。

在私有云中，服务和基础结构始终在私有网络上进行维护，硬件和软件专供组织使用。

私有云可使组织更加方便地自定义资源，从而满足特定的 IT 需求。

- 私有云优势：
- - 灵活性更高 — 组织可自定义云环境以满足特定业务需求。
  - 安全性更高 — 资源不与其他组织共享，从而可实现更高控制性和安全性级别。
  - 缩放性更高 — 私有云仍然具有公有云的缩放性和效率。

但是私有云的费用相对较高， 并且维护成本也不低。于是有的厂商结合了公有云和私有云推出了混合云。

**混合云**

混合云是一种云计算模型，它通过安全连接（如VPN连接或租用线路）组合一个或多个公有云和私有云环境，从而允许在不同云环境之间共享数据和应用程序。当在私有云上运行的应用程序遇到使用高峰时，它们可以自动“突发”到公有云环境以获得额外的按需容量。这被称为“云爆发”。由于额外的需求将在公有云上，因此无需担心提前配置硬件以满足高峰需求。连接公有云和私有云有两种方法：VPN和点对点专用连接。

混合云通常被认为是“两全其美”，它将本地基础架构或私有云与公有云相结合，组织可利用这两者的优势。

在混合云中，数据和应用程序可在私有云和公有云之间移动，从而可提供更大灵活性和更多部署选项。

- 混合云优势：
- - 控制性 — 组织可针对敏感资产维持私有基础结构。
  - 灵活性 — 需要时可利用公有云中的其他资源。
  - 成本效益 — 具备扩展至公有云的能力，因此可仅在需要时支付额外的计算能力。
  - 容易轻松 — 无需费时费力即可转换至云，因为可根据时间按工作负荷逐步迁移。

混合云整合了公有云和公有云的优势。它提供高可扩展性，几乎无限的存储空间，灵活的支付模式，并且与公有云一样具有成本效益。混合云也非常安全；它为您提供了更多的灵活性和对云资源的控制。

**社群云**

社群云，也称社区云，是由几个组织共享的云端基础设施，它们支持特定的社群，有共同的关切事项，例如使命任务、安全需求、策略与法规遵循考量等。管理者可能是组织本身，也能是第三方；管理位置可能在组织内部，也可能在组织外部。

**总结**

这四种云的主要区别就是使用的人群和使用的方式不一样：

- 公有云由公众开放使用
- 私有云由单一组织独占使用
- 混合云则是前述的两种以上模式的混合
- 社群云是由一个特定社区独占使用，该社区由具有共同关切 (如使命、安全要求、政策等) 的多个组织组成

使用场景区别：

- 公有云部署通常用于提供基于 Web 的电子邮件、网上办公应用、存储以及测试和开发环境。
- 私有云的使用对象通常为政府机构、金融机构以及其他具备业务关键性运营且希望对环境拥有更大控制权的中型到大型组织。
- 混合云的使用对象通常由大流量的互联网业务，同时部分业务有合规需求或者需要充分利用现有IT资产的企业或组织
- 社群云的使用对象通常是多个有密切关系的组织一起联合使用。

### 93.什么是IaaS、PaaS和SaaS？

**IaaS**

IaaS（Infrastructure as a Service），即基础设施即服务。指把IT基础设施作为一种服务通过网络对外提供，并根据用户对资源的实际使用量或占用量进行计费的一种服务模式。

有了IaaS服务，用户可以在云服务提供商提供的基础设施上部署和运行任何软件，包括操作系统和应用软件。

用户没有权限管理和访问底层的基础设施，如服务器、交换机、硬盘等，但是有权管理操作系统、存储内容，可以安装管理应用程序，甚至是有权管理网络组件。

简单的说用户使用IaaS，有权管理操作系统之上的一切功能。我们常见的IaaS服务有虚拟机、虚拟网络、以及存储。

PaaS

PaaS（Platform as a Service），是指平台即服务。是一种云计算服务，提供运算平台与解决方案服务。

PaaS给用户提供的能力是使用由云服务提供商支持的编程语言、库、服务以及开发工具来创建、开发应用程序并部署在相关的基础设施上。

用户无需管理底层的基础设施，包括网络、服务器，操作系统或者存储。他们只能控制部署在基础设施中操作系统上的应用程序，配置应用程序所托管的环境的可配置参数。

SaaS

SaaS（Software-as-a-Service），意思为软件即服务，即通过网络提供软件服务。

SaaS平台供应商将应用软件统一部署在自己的服务器上，客户可以根据工作实际需求，通过互联网向厂商定购所需的应用软件服务，按定购的服务多少和时间长短向厂商支付费用，并通过互联网获得Saas平台供应商提供的服务。

SaaS给用户提供的能力是使用在云基础架构上运行的云服务提供商的应用程序。可以通过轻量的客户端接口（诸如web浏览器（例如，基于web的电子邮件））或程序接口从各种客户端设备访问应用程序。

用户无需管理或控制底层云基础架构，包括网络，服务器，操作系统，存储甚至单独的应用程序功能，可能的例外是有限的用户特定应用程序配置设置。

根据SaaS应用是否具有可配置性，高性能，可伸缩性的特性，SaaS成熟度模型被分成四级。每一级都比前一级增加三种特性中的一种：

- 多次开发
- - 这种模型下，软件服务提供商为每个客户定制一套软件，并为其部署。每个客户使用一个独立的数据库实例和应用服务器实例。数据库中的数据结构和应用的代码可能都根据客户需求做过定制化修改。
- 一次开发多次部署
- - 通过不同的配置满足不同客户的需求，而不需要为每个客户进行特定定制，以降低定制开发的成本。
  - 但是，软件的部署架构没有太大的变化，依然为每个客户独立部署一个运行实例。只是每个运行实例运行的是同一份代码，通过配置的不同来满足不同客户的个性化需求。
  - 可配置性的比较通用的实现方式，就是通过MetaData（元数据）来实现。
- 一次开发一次部署
- - 多租户单实例（Multi-Tenant）的应用架构才是通常真正意义上的SaaS应用架构，它可以有效降低SaaS应用的硬件及运行维护成本，最大化地发挥SaaS应用的规模效应。
- 无需开发
- - 将第三级的Multi-Tenant SingleInstance系统扩展为Multi-Tenant MultiInstance。最终用户首先通过接入Tenant Load Balance层，再被分配到不同的Instance上。通过多个Instance来分担大量用户的访问，我们可以让应用实现近似无限的水平扩展。

### 94.什么是Mock

Mock，直译过来的话是虚假的意思，但是在面向对象程序设计中，一般翻译成模拟。如接口mock、mock对象等，通常表示接口模拟、模拟对象等。

在程序开发中，一般在两种场景中会是用到mock技术，第一种是在单元测试的时候，第二种是在接口测试的时候。

**单元测试mock**

mock主要应用在单元测试中，因为单元测试的目的是只想针对自己关注的这个"单元"部分进行测试，所以需要对屏蔽掉一些外部依赖的影响，这时候就可以使用mock技术。

接口mock

如我们的要测试的一个方法，其中依赖了一个RPC远程服务，因为远程服务的返回值可能是各种各样的，我们为了测试我们的接口的鲁棒性，就会针对各种边界情况进行充分测试。

如果把外部接口mock掉，也就是把外部接口的返回值当做一个mock对象，那么我们就可以很方便的模拟各种情况。如外部接口正常返回、异常返回、请求超时等等，都可以很方便的被测试。

### 95.加密

**对称加密**

对称加密，指的是需要对加密和解密使用相同密钥的加密算法。

最简单的对称加密算法就是通过ASCII码的变化进行密码保存，比如把`abcde`转换成`bcdef`，其加密算法就是把ASCII码增加1 。

这种加密算法，有一个特点，就是可以根据加密后得到的密文，再根据密钥还原出明文。

在对称加密算法中常用的算法有：DES、3DES、TDEA、Blowfish、RC2、RC4、RC5、IDEA、SKIPJACK等。

**单向Hash算法**

单向散列算法，又称hash函数，就是把任意长的输入消息串变化成固定长的输出串的一种函数。一般用于产生消息摘要，密钥加密等。

单向Hash算法是一种无法通过计算还原出原始密码，而且实现比较简单的算法。

常见散列函数(Hash函数)有： MD5（Message Digest Algorithm 5）、 SHA（Secure Hash Algorithm）、 MAC（Message Authentication Code）、 CRC（Cyclic Redundancy Check）

**彩虹表**

彩虹表(rainbow table)是一个用于加密散列函数逆运算的预先计算好的表，常用于破解加密过的密码散列。 查找表常常用于包含有限字符固定长度纯文本密码的加密。这是以空间换时间的典型实践，在每一次尝试都计算的暴力破解中使用更少的计算能力和更多的储存空间，但却比简单的每个输入一条散列的翻查表使用更少的储存空间和更多的计算性能。

通常情况下，当字段经过散列处理（如MD5），会生成一段散列值，而散列后的值一般是无法通过特定算法得到原始字段的。但是某些情况，比如一个大型的彩虹表，通过在表中搜索该MD5值，很有可能在极短的时间内找到该散列值对应的真实字段内容。

**加盐Hash算法**

盐（Salt），在密码学中，是指在散列之前将散列内容（例如：密码）的任意固定位置插入特定的字符串。这个在散列中加入字符串的方式称为“加盐”。其作用是让加盐后的散列结果和没有加盐的结果不相同，在不同的应用情景中，这个处理可以增加额外的安全性。

加盐后的散列值，可以极大的降低由于用户数据被盗而带来的密码泄漏风险，即使通过彩虹表寻找到了散列后的数值所对应的原始内容，但是由于经过了加盐，插入的字符串扰乱了真正的密码，使得获得真实密码的概率大大降低。

对于加了“固定盐”的Hash算法，需要保护“盐”不能泄露，这就会遇到“保护对称密钥”一样的问题，一旦“盐”泄露，根据“盐”重新建立彩虹表可以进行破解。

**PBKDF2算法**

PBKDF2算法，即Password-Based Key Derivation Function 2。PBKDF2简单而言就是将加盐Hash进行多次重复计算，这个次数是可选择的。

该算法原理大致相当于在Hash算法基础上增加**随机盐**，并进行**多次Hash运算**，随机盐使得彩虹表的建表难度大幅增加，而多次Hash也使得建表和破解的难度都大幅增加。

如果计算一次所需要的时间是1微秒，那么计算1百万次就需要1秒钟。假如攻击一个密码所需的彩虹表有1千万条，建立所对应的彩虹表所需要的时间就是115天。这个代价足以让大部分的攻击者忘而生畏。

**bcrypt**

bcrypt是专门为密码存储而设计的算法，基于Blowfish加密算法变形而来，由Niels Provos和David Mazières发表于1999年的USENIX。

实现中bcrypt会使用一个加盐的流程以防御彩虹表攻击，同时bcrypt还是适应性函数，它可以借由增加迭代之次数来抵御日益增进的计算机运算能力透过暴力法破解。

由bcrypt加密的文件可在所有支持的操作系统和处理器上进行转移。它的口令必须是8至56个字符，并将在内部被转化为448位的密钥。然而，所提供的所有字符都具有十分重要的意义。密码越强大，您的数据就越安全。

bcrypt经过了很多安全专家的仔细分析，使用在以安全著称的OpenBSD中，一般认为它比PBKDF2更能承受随着计算能力加强而带来的风险。bcrypt也有广泛的函数库支持，因此建议使用这种方式存储密码。

### 96.**DNS**

DNS，是Domain Name System的缩写，翻译成域名系统。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。

**DNS最主要的作用就是将域名翻译成ip地址。**

**IP地址**

IP地址是IP Address的缩写，指互联网协议地址（英语：Internet Protocol Address，又译为网际协议地址）。IP地址是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。

互联网上的每一台计算机，都会分配到一个IP地址。

IP地址被用来给Internet上的电脑一个编号。大家日常见到的情况是每台联网的PC上都需要有IP地址，才能正常通信。

IP地址是一个32位的二进制数，通常被分割为4个“8位二进制数”（也就是4个字节）。IP地址通常用“点分十进制”表示成（a.b.c.d）的形式。如：208.80.152.2

**域名**

域名，这个是很多人都熟悉的概念，我们大多数情况下，在浏览器上访问某个网站的时候，都是通过域名访问的。

域名是由一串用点分隔的字符组成的互联网上某一台计算机或计算机组的名称，用于在数据传输时标识计算机的电子方位。

域名可以说是一个IP地址的代称，目的是为了便于记忆后者。

例如，wikipedia.org是一个域名，和IP地址208.80.152.2相对应。人们可以直接访问wikipedia.org来代替IP地址，然后域名系统（DNS）就会将它转化成便于机器识别的IP地址。

这样，人们只需要记忆wikipedia.org这一串带有特殊含义的字符，而不需要记忆没有含义的数字。

**域名、IP和DNS**

有了DNS，我们不需要记住每一个网站的多个IP地址，我们只需要之道这个网站的域名就可以了。

某些网络运营商为了某些目的，可能会限制某些用户访问某一些特定的网站，而限制手段最常用的就是DNS污染和DNS劫持。

正常情况下，当我们访问某个域名的时候，会跳转到失败页面，但是如果爬到墙外，就可以正常访问。比如所谓的qiang。

还有一种典型场景，当我们的宽带欠费的时候，访问某个网站时，被自动跳转到运营商网站，提示充值。

这都是运营商在DNS上做了手脚。其目的是为了让域名无法解析到正常的IP地址。

127.0.0.1是回送地址，指本地机，一般用来测试使用。

**DNS污染**

网域服务器缓存污染（DNS cache pollution），又称域名服务器缓存投毒（DNS cache poisoning），是指一些刻意制造或无意中制造出来的域名服务器数据包，把域名指往不正确的IP地址。

其工作方式是：由于通常的DNS查询没有任何认证机制，而且DNS查询通常基于的UDP是无连接不可靠的协议，因此DNS的查询非常容易被篡改，通过对UDP端口53上的DNS查询进行入侵检测，一经发现与关键词相匹配的请求则立即伪装成目标域名的解析服务器（NS，Name Server）给查询者返回虚假结果。

DNS污染指的是用户访问一个地址，国内的服务器(非DNS)监控到用户访问的已经被标记地址时，服务器伪装成DNS服务器向用户发回错误的地址的行为。为了减免网络上的交通，一般的域名都会把外间的域名服务器数据暂存起来，待下次有其他机器要求解析域名时，可以立即提供服务。一旦有关网域的局域域名服务器的缓存受到污染，就会把网域内的电脑导引往错误的服务器或服务器的网址。

简单点说，DNS污染是指把自己伪装成DNS服务器，在检查到用户访问某些网站后，使域名解析到错误的IP地址。

**DNS劫持**

DNS劫持又称域名劫持，是指在劫持的网络范围内拦截域名解析的请求，分析请求的域名，把审查范围以外的请求放行，否则返回假的IP地址或者什么都不做使请求失去响应，其效果就是对特定的网络不能访问或访问的是假网址。

简单点说，DNS劫持指的是通过非法手段，获取DNS服务器的权限，然后把DNS配置进行修改，使域名解析到错误的IP地址。

**DNS污染和DNS劫持的区别**

DNS劫持是劫持了DNS服务器，进而修改其解析结果。

DNS污染是国内的某些服务器对DNS查询进行入侵检测，发现与黑名单上匹配的请求，该服务器就伪装成DNS服务器，给查询者返回虚假结果。它利用了UDP协议是无连接不可靠性。

**一个是劫持了DNS服务器，一个是伪装成DNS服务器。造成的结果都是返回错误的IP地址。**

**如何解决DNS污染和劫持**

对于 DNS劫持，可以通过手动更换DNS服务器为第三方公共DNS解决。

> 公共DNS 是一种面向大众的免费的 DNS 互联网基础服务。更换 DNS 服务器地址为 公共DNS 后，可以在一定程度上加快域名解析速度、防止 DNS劫持、加强上网安全，还可以屏蔽大部分运营商的广告。

### 97.**域名**

网域名称（英语：Domain Name，简称：Domain），简称域名、网域，是由一串用点分隔的字符组成的互联网上某一台计算机或计算机组的名称，用于在数据传输时标识计算机的电子方位。

IP地址是因特网主机的作为路由寻址用的数字体标识，但是他不容易记忆，因而产生了域名这一种字符型标识，它比IP地址更容易记忆。这也是**域名的一个重要功能——为数字化的互联网资源提供易于记忆的名称**。

另外，**域名具有唯一性**，在资源更改IP地址时，只需要进行更新IP地址与恒定域名的映射关系就行了，对用户来说是无感知的。使用原来的域名同样可以访问到新的IP地址。

**WWW**

**www，其实是World Wide Web的缩写，中文翻译为万维网**。是一个通过互联网访问的，由许多互相链接的超文本组成的系统。万维网是信息时代发展的核心，也是数十亿人在互联网上进行交互的主要工具。

**万维网和互联网**

这种将计算机网络互相联接在一起的方法可称作“网络互联”，在这基础上发展出覆盖全世界的全球性互联网络称互联网，即是互相连接一起的网络。

**互联网并不等同万维网（WWW）**，**万维网只是一个基于超文本相互链接而成的全球性系统，且是互联网所能提供的服务其中之一**。互联网带有范围广泛的信息资源和服务，除此以外还有文件传输（FTP）、电子邮件（E-mail）、远程登录（Telnet）等。

为了区分互联网中的各种应用，就有了不同的子域名，比如互联网就以www作为子域名，文件传输以ftp作为子域名，电子邮件以mail作为子域名。

**省略www**

域名是可以配置如何解析的，当我们设置www作为域名前缀的时候，那么访问[www.aliyun.com](www.aliyun.com)即可访问网站。当我们设置@作为域名前缀的时候，直接访问aliyun.com就可以访问网站了。

**正是因为万维网是互联网中最重要的一部分，很多域名的最主要用途也是搭建web网站，所以，会有很多公司直接忽略www。**

**顶级域名**

一个域名由多级组成。从后往前看，域名的第一级是顶级域，它包括通用顶级域以及国家和地区顶级域。

**通用顶级域**（英语：Generic top-level domain，缩写为gTLD）是互联网名称与数字地址分配机构（IANA）管理的顶级域（TLD）之一。该机构专门负责互联网的域名系统。

例如：

```html
.com - 供商业机构使用
.edu - 供教育机构使用
.gov - 供政府及其属下机构使用
.mil - 供军事机构使用
.net - 供网络服务供应商使用
.org - 供不属于其他通用顶级域类别的组织使用
```

**国家和地区顶级域名**（Country code top-level domain，英语：ccTLD），简称国家顶级域，是用两字母的国家或地区名缩写代称的顶级域，其域名的指定及分配，政治因素考量凌驾在技术和商业因素之上。这些顶级域均由两个字母组成，大部分使用ISO 3166-1标准。

**所以说，并不是所有的网站都以.com结尾，一般商业机构使用的网站会通常以.com结尾，而教育机构使用的网站通常以.edu结尾。**